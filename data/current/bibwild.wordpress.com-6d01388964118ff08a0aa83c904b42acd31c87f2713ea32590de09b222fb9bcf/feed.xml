<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/" xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/">

<channel>
	<title>ruby – Bibliographic Wilderness</title>
	<atom:link href="https://bibwild.wordpress.com/feed/?tag=ruby" rel="self" type="application/rss+xml"/>
	<link>https://bibwild.wordpress.com</link>
	<description/>
	<lastBuildDate>Mon, 28 Mar 2022 19:51:48 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain="bibwild.wordpress.com" port="80" path="/?rsscloud=notify" registerProcedure="" protocol="http-post"/>
<image>
		<url>https://s0.wp.com/i/buttonw-com.png</url>
		<title>ruby – Bibliographic Wilderness</title>
		<link>https://bibwild.wordpress.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://bibwild.wordpress.com/osd.xml" title="Bibliographic Wilderness"/>
	<atom:link rel="hub" href="https://bibwild.wordpress.com/?pushpress=hub"/>
	<item>
		<title>Rails7 connection.select_all is stricter about it’s arguments in backwards incompat way: TypeError: Can’t Cast Array</title>
		<link>https://bibwild.wordpress.com/2022/03/28/rails7-connection-select_all-is-stricter-about-its-arguments-in-backwards-incompat-way-typeerror-cant-cast-array/</link>
					<comments>https://bibwild.wordpress.com/2022/03/28/rails7-connection-select_all-is-stricter-about-its-arguments-in-backwards-incompat-way-typeerror-cant-cast-array/#comments</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Mon, 28 Mar 2022 19:51:04 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9658</guid>

					<description><![CDATA[I have code that wanted to execute some raw SQL against an ActiveRecord database. It is complicated and weird multi-table SQL (involving a postgres recursive CTE), so none of the specific-model-based API for specifying SQL seemed appropriate. It also needed to take some parameters, that needed to be properly escaped/sanitized. At some point I decided &#8230; <a href="https://bibwild.wordpress.com/2022/03/28/rails7-connection-select_all-is-stricter-about-its-arguments-in-backwards-incompat-way-typeerror-cant-cast-array/" class="more-link">Continue reading <span class="screen-reader-text">Rails7 connection.select_all is stricter about it&#8217;s arguments in backwards incompat way: TypeError: Can&#8217;t Cast&#160;Array</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I have code that wanted to execute some raw SQL against an ActiveRecord database. It is complicated and weird multi-table SQL (involving a <a href="https://www.postgresql.org/docs/13/queries-with.html">postgres recursive CTE</a>), so none of the specific-model-based API for specifying SQL seemed appropriate.  It also needed to take some parameters, that needed to be properly escaped/sanitized. </p>



<p>At some point I decided that the right way to do this was with <code>Model.connection.select_all</code> , which would create a parameterized prepared statement. </p>



<p>Was I right? Is there a better way to do this? The method is <a href="https://guides.rubyonrails.org/active_record_querying.html#select-all">briefly mentioned in the Rails Guide</a> (demonstrating it is public API!), but without many details about the arguments. <a href="https://api.rubyonrails.org/classes/ActiveRecord/ConnectionAdapters/DatabaseStatements.html#method-i-select_all">It has very limited  API docs</a>, just doc&#8217;d as: <code><strong>select_all</strong>(arel, name = nil, binds = [], preparable: nil, async: false)</code>, &#8220;Returns an&nbsp;<a href="https://api.rubyonrails.org/classes/ActiveRecord/Result.html"><code>ActiveRecord::Result</code></a>&nbsp;instance.&#8221; No explanation of the type or semantics of the arguments. </p>



<p>In my code working on Rails previous to 7, the call looked like:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
MyModel.connection.select_all(
  "select complicated_stuff WHERE something = $1",
  "my_complicated_stuff_name",
  &#91;&#91;nil, value_for_dollar_one_sub]],
  preparable: true
)
</pre></div>


<ul><li>yeah that value for the <code>binds</code> is weird, a duple-array within an array, where the first value of the duple-array is just nil? This isn&#8217;t documented anywhere, I probably got that from somewhere&#8230; maybe one of the several StackOverflow answers. </li><li>I honestly don&#8217;t know what <code>preparable: true</code> does, or what difference it makes. </li></ul>



<p>In Rails 7.0, this started failing with the error: <strong>TypeError: can&#8217;t cast Array</strong>.</p>



<p>I couldn&#8217;t find any documentation of that <code>select_all</code> all method at all, or other discussion of this; I couldn&#8217;t find any <code>select_all</code> change mentioned in the <a href="https://github.com/rails/rails/blob/7-0-stable/railties/CHANGELOG.md">Rails Changelog. </a>I tried looking at actual code history but got lost. I&#8217;m guessing &#8220;can&#8217;t cast Array&#8221; referes to that weird <code>binds</code> value&#8230; but what is it supposed to be?</p>



<p>Eventually I thought to look for Rails tests of this method that used the <code>binds</code> argument, and <a href="https://github.com/rails/rails/blob/74ba52ec5c5aa53e2e728d88c179b2d487fff2b4/activerecord/test/cases/adapter_test.rb#L261-L271">managed to eventually find one</a>! </p>



<p>So&#8230; okay, rewrote that with new <code>binds</code> argument like so:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
bind = ActiveRecord::Relation::QueryAttribute.new(
  "something", 
  value_for_dollar_one_sub, 
  ActiveRecord::Type::Value.new
)

MyModel.connection.select_all(
  "select complicated_stuff WHERE something = $1",
  "my_complicated_stuff_name",
  &#91;bind],
  preparable: true
)
</pre></div>


<ul><li>Confirmed this worked not only in Rails 7, but all the way back to Rails 5.2 no problem. </li><li>I guess that way I was doing it previously was some legacy way of passing args that was finally removed in Rails 7?</li><li>I still don&#8217;t really understand what I&#8217;m doing. The first arg to <code>ActiveRecord::Relation::QueryAttribute.new</code>  I made match the SQL column it was going to be compared against, but I don&#8217;t know if it matters or if it&#8217;s used for anything. The third argument appears to be an ActiveRecord Type&#8230; I just left it the generic <code>ActiveRecord::Type::Value.new</code>, which seemed to work fine for both integer or string values, not sure in what cases you&#8217;d want to use a specific type value here, or what it would do. </li><li>In general, I wonder if there&#8217;s a better way for me to be doing what I&#8217;m doing here? It&#8217;s odd to me that nobody else findable on the internet has run into this&#8230; even though there are stackoverflow answers suggesting this approach&#8230; maybe i&#8217;m doing it wrong?</li></ul>



<p>But anyways, since this was pretty hard to debug, hard to find in docs or explanations on google, and I found no mention at all of this changing/breaking in Rails 7&#8230; I figured I&#8217;d write it up so someone else had the chance of hitting on this answer. </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2022/03/28/rails7-connection-select_all-is-stricter-about-its-arguments-in-backwards-incompat-way-typeerror-cant-cast-array/feed/</wfw:commentRss>
			<slash:comments>4</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Finding source install location of a loaded ruby gem at runtime</title>
		<link>https://bibwild.wordpress.com/2022/01/10/finding-source-install-location-of-a-loaded-ruby-gem-at-runtime/</link>
					<comments>https://bibwild.wordpress.com/2022/01/10/finding-source-install-location-of-a-loaded-ruby-gem-at-runtime/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Mon, 10 Jan 2022 19:34:54 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9561</guid>

					<description><![CDATA[Not with a command line, but from within a ruby program, that has gems loaded &#8230; how do you determine the source install location of such a loaded gem? I found it a bit difficult to find docs on this, so documenting for myself now that I&#8217;ve figured it out. Eg:]]></description>
										<content:encoded><![CDATA[
<p> Not with a command line, but from within a ruby program, that has gems loaded &#8230; how do you determine the source install location of such a loaded gem?</p>



<p>I found it a bit difficult to find docs on this, so documenting for myself now that I&#8217;ve figured it out. Eg:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
Gem.loaded_specs&#91;'device_detector'].full_gem_path
# =&gt; &quot;/Users/jrochkind/.gem/ruby/2.7.5/gems/device_detector-1.0.5&quot;
</pre></div>]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2022/01/10/finding-source-install-location-of-a-loaded-ruby-gem-at-runtime/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Github Action setup-ruby needs to quote ‘3.0’ or will end up with ruby 3.1</title>
		<link>https://bibwild.wordpress.com/2021/12/28/github-action-setup-ruby-needs-to-quote-3-0-or-will-end-up-with-ruby-3-1/</link>
					<comments>https://bibwild.wordpress.com/2021/12/28/github-action-setup-ruby-needs-to-quote-3-0-or-will-end-up-with-ruby-3-1/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 29 Dec 2021 03:04:25 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9520</guid>

					<description><![CDATA[You may be running builds in Github Actions using the setup-ruby action to install a chosen version of ruby, looking something like this: A week ago, that would have installed the latest ruby 3.0.x. But as of the christmas release of ruby 3.1, it will install the latest ruby 3.1.x. The workaround and/or correction is &#8230; <a href="https://bibwild.wordpress.com/2021/12/28/github-action-setup-ruby-needs-to-quote-3-0-or-will-end-up-with-ruby-3-1/" class="more-link">Continue reading <span class="screen-reader-text">Github Action setup-ruby needs to quote &#8216;3.0&#8217; or will end up with ruby&#160;3.1</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>You may be running builds in Github Actions using the setup-ruby action to install a chosen version of ruby, looking something like this:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: yaml; title: ; notranslate">
    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: 3.0
</pre></div>


<p>A week ago, that would have installed the latest ruby 3.0.x. But as of the christmas release of ruby 3.1, it will install the latest ruby 3.1.x. </p>



<p>The workaround and/or correction is to quote the ruby version number. If you actually want to get latest ruby 3.0.x, say:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: yaml; title: ; notranslate">
      with:
        ruby-version: '3.0'
</pre></div>


<p>This is reported <a href="https://github.com/ruby/setup-ruby/issues/252">here</a>, with reference to <a href="https://github.com/actions/runner/issues/849">this issue</a> on the Github Actions runner itself. It is not clear to me that this is any kind of a bug in the github actions runner, rather than just an unanticipated consequence of using a numeric value in YAML here.  <code>3.0</code> is of course the same number as <code>3</code>, it&#8217;s not obvious to me it&#8217;s a bug that the YAML parser treats them as such. </p>



<p>Perhaps it&#8217;s a bug or mis-design in the <code>setup-ruby</code> action. But in lieu of any developers deciding it&#8217;s a bug&#8230; quote your <code>3.0</code> version number, or perhaps just quote all ruby version numbers with the setup-ruby task? </p>



<p>If your 3.0 builds started failing and you have no idea why &#8212; this could be it. It can be a bit confusing to diagnose, because I&#8217;m not sure anything in the Github Actions output will normally echo the ruby version in use? I guess there&#8217;s a clue in the &#8220;Installing Bundler&#8221; sub-head of the &#8220;Setup Ruby&#8221; task:</p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png"><img data-attachment-id="9528" data-permalink="https://bibwild.wordpress.com/screen-shot-2021-12-28-at-9-57-27-pm/" data-orig-file="https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png" data-orig-size="1596,452" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2021-12-28-at-9.57.27-pm" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png?w=1024" src="https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png?w=1024" alt="" class="wp-image-9528" srcset="https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png?w=1024 1024w, https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png?w=150 150w, https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png?w=300 300w, https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png?w=768 768w, https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png 1596w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>



<p>Of course it&#8217;s possible your build will succeed anyway on ruby 3.1 even if you meant to run it on ruby 3.0!  Mine failed with <code>LoadError: cannot load such file -- net/smtp</code>, so if yours happened to do the same, maybe you got here from google. :)  (Clearly net/smtp has been moved to a different status of <a href="https://stdgems.org/">standard gem</a> in ruby 3.1, I&#8217;m not dealing with this further becuase I wasn&#8217;t intentionally supporting ruby 3.1 yet). </p>



<p>Note that if you are building with a Github actions matrix for ruby version, the same issue applies. Maybe something like:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: yaml; title: ; notranslate">
matrix:
        include:
          - ruby: '3.0' 
 steps:
    - uses: actions/checkout@v2

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: ${{ matrix.ruby }}
</pre></div>


<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2021/12/28/github-action-setup-ruby-needs-to-quote-3-0-or-will-end-up-with-ruby-3-1/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>

		<media:content url="https://bibwild.files.wordpress.com/2021/12/screen-shot-2021-12-28-at-9.57.27-pm.png?w=1024" medium="image"/>
	</item>
		<item>
		<title>Notes on retrying all jobs with ActiveJob retry_on</title>
		<link>https://bibwild.wordpress.com/2021/08/23/notes-on-retrying-all-jobs-with-activejob-retry_on/</link>
					<comments>https://bibwild.wordpress.com/2021/08/23/notes-on-retrying-all-jobs-with-activejob-retry_on/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Mon, 23 Aug 2021 14:49:24 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9303</guid>

					<description><![CDATA[I would like to configure all my ActiveJobs to retry on failure, and I&#8217;d like to do so with the ActiveJob retry_on method. So I&#8217;m going to configure it in my ApplicationJob class, in order to retry on any error, maybe something like: Why use ActiveJob retry_on for this? Why StandardError? Many people use backend-specific &#8230; <a href="https://bibwild.wordpress.com/2021/08/23/notes-on-retrying-all-jobs-with-activejob-retry_on/" class="more-link">Continue reading <span class="screen-reader-text">Notes on retrying all jobs with ActiveJob&#160;retry_on</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I would like to configure all my ActiveJobs to retry on failure, and I&#8217;d like to do so with the <a href="https://api.rubyonrails.org/classes/ActiveJob/Exceptions/ClassMethods.html#method-i-retry_on">ActiveJob retry_on method. </a></p>



<p>So I&#8217;m going to configure it in my ApplicationJob class, in order to retry on <em>any</em> error, maybe something like: </p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
class ApplicationJob &lt; ActiveJob::Base
  retry_on StandardError # other args to be discussed
end

</pre></div>


<h2>Why use ActiveJob retry_on for this? Why StandardError?</h2>



<p>Many people use backend-specific logic for retries, especially with Sidekiq. That&#8217;s fine!</p>



<p>I like the idea of using the ActiveJob functionality:</p>



<ul><li>I currently use resque (more on challenges with retry here later), but plan to switch to something else at some point medium-term. Maybe sideqkiq, but maybe <a href="https://github.com/collectiveidea/delayed_job">delayed_job</a> or <a href="https://github.com/bensheldon/good_job">good_job. </a> (Just using the DB and not having a redis is attractive to me, as is open source). I like the idea of not having to redo this setup when I switch back-ends, or am trying out different ones.</li><li>In general, I like the promise of ActiveJob as swappable commoditized backends</li><li>I like what I see as good_job&#8217;s philosophy here, why have every back-end reinvent the wheel when a feature can be done at the ActiveJob level? That can help keep the individual back-end smaller, and less &#8220;expensive&#8221; to maintain.  good_job encourages you to use ActiveJob retries I think. </li></ul>



<p>Note, dhh is on <a href="https://github.com/rails/rails/issues/34337#issuecomment-434004236">record from 2018 saying he thinks setting up retries for all StandardError is a bad idea</a>. But I don&#8217;t really understand why! He says &#8220;You should know why you&#8217;d want to retry, and the code should document that knowledge.&#8221; &#8212; but the fact that so many ActiveJob back-ends provide &#8220;retry all jobs&#8221; functionality makes it seem to me an established common need and best practice, and why shouldn&#8217;t you be able to do it with ActiveJob alone? </p>



<p>dhh thinks ActiveJob retry is for specific targetted retries maybe, and the backend retry should be used for generic universal ones? Honestly I don&#8217;t see myself doing much specific targetted retries, making all your jobs idempotent (<strong>important</strong>! Best practice for ActiveJob always!), and just having them all retry on any error seems to me to be the way to go, a more efficient use of developer time and sufficient for at least a relatively simple app. </p>



<p>One situation I have where a retry is crucial, is when I have a fairly long-running job (say it takes more than 60 seconds to run; I have some unavoidably!), and the machine running the jobs needs to restart. It might interrupt the job.  It is convenient if it is just automatically retried &#8212; put back in the queue to be run again by restarted or other job worker hosts!  Otherwise it&#8217;s just sitting there failed, never to run again, requiring manual action. An automatic retry will take care of it almost invisibly. </p>



<h2>Resque and Resque Scheduler</h2>



<p>Resque by default doens&#8217;t supprot future-scheduled jobs. You can add them with the <a href="https://github.com/resque/resque-scheduler">resque-scheduler</a> plugin. But I had a perhaps irrational desire to avoid this &#8212; resque and it&#8217;s ecosystem have at <a href="https://github.com/resque/resque/issues/1759">different times had different amounts of maintenance/abandonment</a>,  and I&#8217;m (perhaps irrationally) reluctant to complexify my resque stack. </p>



<p>And do I need future scheduling for retries? For my most important use cases, it&#8217;s totally fine if I retry just once, immediately, with a <code>wait: 0</code>. Sure, that won&#8217;t take care of all potential use cases, but it&#8217;s a good start. </p>



<p>I thought even without resque supporting future-scheduling, i could get away with:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: plain; title: ; notranslate">
retry_on StandardError, wait: 0
</pre></div>


<p>Alas, this won&#8217;t actually work, it still ends up being converted to a future-schedule call, which gets <a href="https://github.com/rails/rails/blob/c84dec3513581db444b2e055ccf79f54fdff4ecc/activejob/lib/active_job/queue_adapters/resque_adapter.rb#L36-L42">rejected by the resque_adapter bundled with Rails unless you have resque-scheduler installed. </a></p>



<p>But of course, resque <em>can</em> handle wait:0 semantically, if the code was willing to do it by queing an ordinary resque job&#8230;. <em><strong>I don&#8217;t know if it&#8217;s a good idea</strong></em>, but <a href="https://gist.github.com/jrochkind/6be2cd72161fc9bebf3b3f8ec3e3f226">this simple patch to Rails-bundled resque_adapter</a> will make it willing to accept &#8220;scheduled&#8221; jobs when the time to be scheduled is actually &#8220;now&#8221;, just scheduling them normally, while still raising on attempts to future schedule. For me, it makes <code>retry_on.... wait: 0</code> work with just plain resque. </p>



<h2>Note: retry_on <code>attempts</code> count includes first run</h2>



<p>So wanting to retry just once, I tried something like this: </p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: plain; title: ; notranslate">
# Will never actually retry
retry_on StandardError, attempts: 1
</pre></div>


<p>My job was never actually retried this way! It looks like the <code>attempts</code> count includes the first non-error run, the total number of times job will be run, including the very first one before any &#8220;retries&#8221;! So attempts 1 means &#8220;never retry&#8221; and does nothing. Oops. If you actually want to <em>retry</em> only <em>once</em>, in my Rails 6.1 app this is what did it for me:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: plain; title: ; notranslate">
# will actually retry once
retry_on StandardError, attempts: 2
</pre></div>


<p>(I think this means the default, <code>attempts: 5</code> actually means your job can be run a total of 5 times&#8211; one original time and 4 retries. I guess that&#8217;s what was intended?)</p>



<h2>Note: job_id stays the same through retries, hooray</h2>



<p>By the way, I checked, and at least in Rails 6.1, the ActiveJob#job_id stays the same on retries. If the job runs once and is retried twice more, it&#8217;ll have the same job_id each time, you&#8217;ll see three <code>Performing</code> lines in your logs, with the same job_id. </p>



<p>Phew! I think that&#8217;s the right thing to do, so we can easily correlate these as retries of the same jobs in our logs. And if we&#8217;re <a href="https://github.com/inkstak/activejob-status">keeping the job_id somewhere to check back and see if it succeeded or failed</a> or whatever, it stays consistent on retry. </p>



<p>Glad this is what ActiveJob is doing!</p>



<h2>Logging isn&#8217;t great, but can be customized</h2>



<p>Rails will automatically log retries with a line that looks like this:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: plain; title: ; notranslate">
Retrying TestFailureJob in 0 seconds, due to a RuntimeError.
# logged at `info` level
</pre></div>


<p>Eventually when it decides it&#8217;s <code>attempts</code> are exhausted, it&#8217;ll say something like:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: plain; title: ; notranslate">
Stopped retrying TestFailureJob due to a RuntimeError, which reoccurred on 2 attempts.
# logged at `error` level
</pre></div>


<p>This does not include the job-id though, which makes it harder than it should be to correlate with other log lines about this job, and follow the job&#8217;s whole course through your log file. </p>



<p>It&#8217;s also inconsistent with <em>other</em> default ActiveJob log lines, which include:</p>



<ul><li>the Job ID in text</li><li><em>tags</em> (Rails tagged logging system) with the job id and the string <code>"[ActiveJob]"</code>. Because of the way the <a href="https://github.com/rails/rails/blob/v6.1.4/activejob/lib/active_job/logging.rb#L14-L15">Rails code applies these only around perform/enqueue</a>, retry/discard related log lines apparently end up not included. </li><li>The Exception message not just the class when there&#8217;s a class. </li></ul>



<p>You can see all the built-in ActiveJob logging in the nicely compact <a href="https://github.com/rails/rails/blob/v6.1.4/activejob/lib/active_job/log_subscriber.rb">ActiveJob::LogSubscriber</a> class. And you can see how the <a href="https://github.com/rails/rails/blob/v6.1.4/activejob/lib/active_job/log_subscriber.rb#L78">log line for retry</a> is kind of inconsistent with <a href="https://github.com/rails/rails/blob/v6.1.4/activejob/lib/active_job/log_subscriber.rb#L58">eg perform. </a></p>



<p>Maybe this inconsistency has persisted so long in part because few people actually use ActiveJob retry, they&#8217;re all still using their backends backend-specific functionality?  <a href="https://github.com/rails/rails/pull/42990">I did try a PR to Rails</a> for at least consistent formatting (my PR doesn&#8217;t do tagging), not sure if it will go anywhere, I think blind PR&#8217;s to Rails usually do not. </p>



<p>In the meantime, after trying a bunch of different things, I think I figured out the reasonable way to use the ActiveSupport::Notifications/LogSubscriber API to customize logging for the retry-related events while leaving it untouched from Rails for the others?  <a href="https://gist.github.com/jrochkind/f48ffc065bfb3d5164a059e5ff5d077c">See my solution here. </a></p>



<p>(Thanks to <a href="https://www.bigbinary.com/blog/rails-6-adds-hooks-to-activejob-around-retries-and-discards">BigBinary blog</a> for showing up in google and giving me a head start into figuring out how ActiveJob retry logging was working.)</p>



<p>(note: There&#8217;s also this: <a href="https://github.com/armandmgt/lograge_active_job" rel="nofollow">https://github.com/armandmgt/lograge_active_job</a>  But I&#8217;m not sure how working/maintained it is. It seems to only customize activejob exception reports, not retry and other events. It would be an interesting project to make an up-to-date activejob-lograge that applied to ALL ActiveJob logging, expressing every event as key/values and using lograge formatter settings to output. I think we see exactly how we&#8217;d do that, with a custom log subscriber as we&#8217;ve done above!)</p>



<h2>Warning: ApplicationJob configuration won&#8217;t work for emails</h2>



<p>You might think since we configured <code>retry_on</code> on <code>ApplicationJob</code>, <strong><em>all</em></strong> our bg jobs are now set up for retrying. </p>



<p>Oops! Not <code>deliver_later</code> emails. </p>



<p><a href="https://github.com/bensheldon/good_job#actionmailer-retries">Good_job README explains that ActiveJob mailers don&#8217;t descend from ApplicationMailer.</a> (I am curious if there&#8217;s any good reason for this, it seems like it would be nice if they did!)</p>



<p>The good_job README provides one way to configure the built-in Rails mailer superclass for retries. </p>



<p>You could maybe also try setting <code>delivery_job</code> on that mailer superclass to use a custom delivery job (<a href="https://www.bigbinary.com/blog/rails-5-2-allows-mailers-to-use-custom-active-job-class">thanks again BigBinary for the pointer</a>)&#8230; maybe one that subclasses the default class to deliver emails as normal, but let you set some custom options like retry_on?  Not sure if this would be preferable in any way. </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2021/08/23/notes-on-retrying-all-jobs-with-activejob-retry_on/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>logging URI query params with lograge</title>
		<link>https://bibwild.wordpress.com/2021/08/04/logging-uri-query-params-with-lograge/</link>
					<comments>https://bibwild.wordpress.com/2021/08/04/logging-uri-query-params-with-lograge/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 04 Aug 2021 19:35:57 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9280</guid>

					<description><![CDATA[The lograge gem for taming Rails logs by default will lot the path component of the URI, but leave out the query string/query params. For instance, perhaps you have a URL to your app /search?q=libraries. lograge will log something like: method=GET path=/search format=html&#8230; The q=libraries part is completely left out of the log. I kinda &#8230; <a href="https://bibwild.wordpress.com/2021/08/04/logging-uri-query-params-with-lograge/" class="more-link">Continue reading <span class="screen-reader-text">logging URI query params with&#160;lograge</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>The <a href="https://github.com/roidrage/lograge">lograge</a> gem for taming Rails logs by default will lot the <code>path</code> component of the URI, but leave out the query string/query params. </p>



<p>For instance, perhaps you have a URL to your app <code>/search?q=libraries</code>. </p>



<p>lograge will log something like:</p>



<p><code>method=GET path=/search format=html</code>&#8230;</p>



<p>The <code>q=libraries</code> part is completely left out of the log. I kinda want that part, it&#8217;s important. </p>



<p>The lograge README <a href="https://github.com/roidrage/lograge#what-it-doesnt-do">provides instructions for &#8220;logging request parameters&#8221;</a>, by way of the params hash. </p>



<p>I&#8217;m going to modify them a bit slightly to: </p>



<ul><li>use the more recent <code>custom_payload</code> config instead of <code>custom_options</code>. (I&#8217;m not certain <a href="https://github.com/roidrage/lograge/issues/265">why there are both</a>, but I think mostly for legacy reasons and newer custom_payload? is what you should read for?)</li><li>If we just put <code>params</code> in there, then a bunch of ugly <code>&lt;ActionController::Parameters</code> show up in the log if you have nested hash params. We could fix that with <code>params.to_unsafe_h</code>, but&#8230;</li><li>We should really use <code>request.filtered_parameters</code> instead to make sure we&#8217;re not logging anything that&#8217;s been filtered out with <a href="https://blog.saeloun.com/2019/12/03/rails-6-adds-activesupport-parameter-filter.html">Rails 6 config.filter_parameters</a>. (Thanks <a href="https://www.reddit.com/r/ruby/comments/oy0h58/logging_uri_query_params_with_lograge/h7pu626/">/u/ezekg on reddit</a>). This also converts to an ordinary hash that isn&#8217;t ActionController::Parameters, taking care of previous bullet point. </li><li>(It kind of seems like lograge README could use a PR updating it?)</li></ul>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
  config.lograge.custom_payload do |controller|
    exceptions = %w(controller action format id)
    params: controller.request.filtered_parameters.except(*exceptions)
  end
</pre></div>


<p>That gets us a log line that might look something like this:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
method=GET path=/search format=html controller=SearchController action=index status=200 duration=107.66 view=87.32 db=29.00 params={&quot;q&quot;=&gt;&quot;foo&quot;}
</pre></div>


<p>OK. The <code>params</code> hash isn&#8217;t exactly the same as the query string, it can include things not in the URL query string (like controller and action, that we have to strip above, among others), and it can in some cases omit things that are in the query string. It just depends on your routing and other configuration and logic.</p>



<p>The params hash itself is what default rails logs&#8230; but what if we just log the actual URL query string instead? Benefits:</p>



<ul><li>it&#8217;s easier to search the logs for actually an exact specific known URL (which can get more complicated like <code>/search?q=foo&amp;range%5Byear_facet_isim%5D%5Bbegin%5D=4&amp;source=foo</code> or something). Which is something I sometimes want to do, say I got a URL reported from an error tracking service and now I want to find that exact line in the log. </li><li>I actually like having the exact actual URL (well, starting from path) in the logs. </li><li>It&#8217;s a lot simpler, we don&#8217;t need to filter out controller/action/format/id etc. </li><li>It&#8217;s actually a bit more concise? And part of what I&#8217;m dealing with in general using lograge is trying to reduce my bytes of logfile for papertrail!</li></ul>



<p>Drawbacks?</p>



<ul><li>if you had some kind of <em>structured</em> log search (I don&#8217;t at present, but I guess could with <a href="https://documentation.solarwinds.com/en/success_center/papertrail/content/kb/how-it-works/json-search.htm">papertrail features</a> by switching to json format?), it might be easier to do something like &#8220;find a /search with q=foo and source=ef without worrying about other params)</li><li>To the extent that params hash can include things not in the actual url, is that important to log like that?</li><li>&#8230;.?</li></ul>



<p>Curious what other people think&#8230; am I crazy for wanting the actual URL in there, not the params hash?</p>



<p>At any rate, it&#8217;s pretty easy to do. Note we use <code>filtered_path</code> rather than <code>fullpath</code> to again take account of Rails 6 parameter filtering, and <a href="https://www.reddit.com/r/ruby/comments/oy0h58/logging_uri_query_params_with_lograge/h7pu626/">thanks again /u/ezekg</a>: </p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
  config.lograge.custom_payload do |controller|
    {
      path: controller.request.filtered_path
    }
  end
</pre></div>


<p>This is actually overwriting the default path to be one that has the query string too:</p>



<pre class="wp-block-preformatted">method=GET path=/search?q=libraries format=html ...</pre>



<p>You could of course add a different key <code>fullpath</code> instead, if you wanted to keep <code>path</code> as it is, perhaps for easier collation in some kind of log analyzing system that wants to group things by same path invariant of query string. </p>



<p>I&#8217;m gonna try this out!</p>



<h2>Meanwhile, on lograge&#8230;</h2>



<p>As long as we&#8217;re talking about lograge&#8230;. based on commit history, history of Issues and Pull Requests&#8230; the fact that CI isn&#8217;t currently running (<a href="https://www.theregister.com/2020/11/02/travis_ci_pricng/">travis.org</a> grr) and <a href="https://github.com/roidrage/lograge/blob/master/.travis.yml#L19-L22">doesn&#8217;t even try to test on Rails 6.0</a>+ (although lograge seems to work fine)&#8230; one might worry that lograge is currently un/under-maintained&#8230;.  No comment on a <a href="https://github.com/roidrage/lograge/issues/328">GH issue filed in May asking about project status</a>. </p>



<p>It still seems to be one of the more popular solutions to trying to tame Rails kind of out of control logs. It&#8217;s mentioned for instance in docs from <a href="https://documentation.solarwinds.com/en/success_center/papertrail/content/kb/configuration/configuring-centralized-logging-from-ruby-on-rails-apps.htm?cshid=pt-configuration-configuring-centralized-logging-from-ruby-on-rails-apps#lograge">papertrail</a> and <a href="https://www.honeybadger.io/blog/ruby-logger-lograge/">honeybadger</a>, and many many other blog posts. </p>



<p>What will it&#8217;s future be? </p>



<p>Looking around for other possibilties, I found <a href="https://github.com/reidmorrison/semantic_logger">semantic_logger</a> (<a href="https://github.com/reidmorrison/rails_semantic_logger">rails_semantic_logger</a>). It&#8217;s got similar features.  It seems to be much more maintained.  It&#8217;s got a respectable number of github stars, although not nearly as many as lograge, and it&#8217;s not featured in blogs and third-party platform docs nearly as much. </p>



<p>It&#8217;s also a bit more sophisticated and featureful. For better or worse. For instance mainly I&#8217;m thinking of how it tries to improve app performance by moving logging to a background thread. This is neat&#8230; and also can lead to a whole new class of <a href="https://github.com/reidmorrison/rails_semantic_logger/issues/122">bug, mysterious warning, or configuration burden</a>. </p>



<p>For now I&#8217;m sticking to the more popular lograge, but I wish it had CI up that was testing with Rails 6.1, at least! </p>



<p>Incidentally, trying to get Rails to log more compactly like both lograge and rails_semantic_logger do&#8230; is somewhat more complicated than you might expect, as demonstrated by the code in both projects that does it! Especially semantic_logger is hundreds of lines of somewhat baroque code split accross several files. A refactor of logging around Rails 5 (I think?) to use <code>ActiveSupport::LogSubscriber</code> made it <em>possible</em> to customize Rails logging like this (although I think both lograge and rails_semantic_logger still do some monkey-patching too!), but in the end didn&#8217;t make it all that easy or obvious or future-proof. This may discourage too many other alternatives for the initial primary use case of both lograge and rails_semantic_logger &#8212; turn a rails action into <em>one</em> log line, with a structured format. </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2021/08/04/logging-uri-query-params-with-lograge/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Notes on Cloudfront in front of Rails Assets on Heroku, with CORS</title>
		<link>https://bibwild.wordpress.com/2021/06/23/notes-on-cloudfront-in-front-of-rails-assets-on-heroku-with-cors/</link>
					<comments>https://bibwild.wordpress.com/2021/06/23/notes-on-cloudfront-in-front-of-rails-assets-on-heroku-with-cors/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 23 Jun 2021 16:37:50 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9239</guid>

					<description><![CDATA[Heroku really recommends using a CDN in front of your Rails app static assets &#8212; which, unlike in non-heroku circumstances where a web server like nginx might be taking care of it, otherwise on heroku static assets will be served directly by your Rails app, consuming limited/expensive dyno resources. After evaluating a variety of options &#8230; <a href="https://bibwild.wordpress.com/2021/06/23/notes-on-cloudfront-in-front-of-rails-assets-on-heroku-with-cors/" class="more-link">Continue reading <span class="screen-reader-text">Notes on Cloudfront in front of Rails Assets on Heroku, with&#160;CORS</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>Heroku <a href="https://devcenter.heroku.com/articles/rails-asset-pipeline">really recommends</a> using a CDN in front of your Rails app static assets &#8212; which, unlike in non-heroku circumstances where a web server like nginx might be taking care of it,  otherwise on heroku static assets will be served directly by your Rails app, consuming limited/expensive dyno resources. </p>



<p>After evaluating a variety of options (including some heroku add-ons), I decided <a href="https://aws.amazon.com/cloudfront/">AWS Cloudfront</a> made the most sense for us &#8212; simple enough, cheap, and we are already using other direct AWS services (including S3 and SES). </p>



<p>While <a href="https://devcenter.heroku.com/articles/using-amazon-cloudfront-cdn">heroku has an article on using Cloudfront</a>, which even covers <a href="https://devcenter.heroku.com/articles/using-amazon-cloudfront-cdn#adding-cloudfront-to-rails">Rails specifically</a>, and even <a href="https://devcenter.heroku.com/articles/using-amazon-cloudfront-cdn#adding-cloudfront-to-rails">CORS issues specifically</a>, I found it a bit too vague to get me all the way there. And while there are lots of blog posts you can find on this topic, I found many of them outdated (Rails has introduced new API; Cloudfront has also changed it&#8217;s configuration options!), or otherwise spotty/thin. </p>



<p>So while I&#8217;m not an expert on this stuff, i&#8217;m going to tell you what I was able to discover, and what I did to set up Cloudfront as a CDN in front of Rails static assets running on heroku &#8212; although there&#8217;s really nothing at all specific to heroku here, if you have any other context where Rails is directly serving assets in production. </p>



<p>First how I set up Rails, then Cloudfront, then some notes and concerns. Btw, you might not need to care about <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">CORS</a> here, but one reason you might is if you are serving any fonts (<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">including font-awesome or other icon fonts!</a>) from Rails static assets. </p>



<h2>Rails setup</h2>



<p>In <code>config/environments/production.rb</code></p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
# set heroku config var RAILS_ASSET_HOST to your cloudfront
# hostname, will look like `xxxxxxxx.cloudfront.net`
config.asset_host = ENV&#91;'RAILS_ASSET_HOST']

config.public_file_server.headers = {
  # CORS:
  'Access-Control-Allow-Origin' =&gt; &quot;*&quot;, 
  # tell Cloudfront to cache a long time:
  'Cache-Control' =&gt; 'public, max-age=31536000' 
}
</pre></div>


<h2>Cloudfront Setup</h2>



<p>I changed some things from default. The only one that absolutely necessary &#8212; if you want CORS to work &#8212; seemed to be changing <em>Allowed HTTP Methods</em> to include <em>OPTIONS</em>. </p>



<p>Click on &#8220;Create Distribution&#8221;. All defaults except:</p>



<ul><li><em>Origin Domain Name</em>:  your heroku app host like <code>app-name.herokuapp.com</code></li><li><em>Origin protocol policy: </em> Switch to &#8220;HTTPS Only&#8221;. Seems like a good idea to ensure secure traffic between cloudfront and origin, no?</li><li><em>Allowed HTTP Methods</em>:<em> </em>Switch to <code>GET, HEAD, OPTIONS</code>. In my experimentation, necessary for CORS from a browser to work &#8212; which <a href="https://aws.amazon.com/premiumsupport/knowledge-center/no-access-control-allow-origin-error/">AWS docs also suggest</a>.</li><li><em>Cached HTTP Methods:</em> Click &#8220;OPTIONS&#8221; too now that we&#8217;re allowing it, I don&#8217;t see any reason not to?</li><li><em>Compress objects automatically</em>: yes<ul><li> Sprockets is creating .gz versions of all your assets, but they&#8217;re going to be completely ignored in a Cloudfront setup either way. <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/2639.png" alt="☹" class="wp-smiley" style="height: 1em; max-height: 1em;" /> (Is there a way to tell Sprockets to stop doing it? WHO KNOWS not me, it&#8217;s so hard to figure out how to reliably talk to Sprockets).  But we can get what it was trying to do by having Cloudfront encrypt stuff for us, seems like a good idea, Google PageSpeed will like it, etc?  </li><li>I noticed by experimentation that Cloudfront will compress CSS and JS (sometimes with brotli sometimes gz, even with the same browser, don&#8217;t know how it decides, don&#8217;t care), but is smart enough not to bother trying to compress a .jpg or .png (which already has internal compression). </li></ul></li><li><em>Comment field</em>: If there&#8217;s a way to edit it after you create the distribution, I haven&#8217;t found it, so pick a good one!</li></ul>



<h2>Notes on CORS</h2>



<p>AWS docs <a href="https://aws.amazon.com/premiumsupport/knowledge-center/no-access-control-allow-origin-error/">here</a> and <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/header-caching.html#header-caching-web-cors">here</a> suggest for CORS support you also need to configure the Cloudfront distribution to forward additional headers — Origin, and possibly Access-Control-Request-Headers and Access-Control-Request-Method. Which you can do by setting up a custom &#8220;cache policy&#8221;. Or maybe instead by by setting the &#8220;Origin Request Policy&#8221;. Or maybe instead by setting custom cache header settings differently using the <code>Use legacy cache settings</code> option. It got confusing &#8212; and none of these settings seemed to be necessary to me for CORS to be working fine, nor could I see any of these settings making any difference in CloudFront behavior or what headers were included in responses. </p>



<p>Maybe they would matter more if I were trying to use a more specific <code>Access-Control-Allow-Origin</code> than just setting it to <code>*</code>? But about that&#8230;.</p>



<p>If you set <code>Access-Control-Allow-Origin</code> to a single host, <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Origin#cors_and_caching">MDN docs</a> say you <em>have</em> to also return a <code>Vary: Origin</code> header. Easy enough to add that to your Rails <code>config.public_file_server.headers</code>.  But I couldn&#8217;t get Cloudfront to forward/return this <code>Vary</code> header with it&#8217;s responses. Trying all manner of cache policy settings, referring to AWS&#8217;s <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorCustomOrigin.html#ResponseCustomRemovedHeaders">quite confusing documentation on the Vary header in Cloudfront</a> and trying to do what it said &#8212; couldn&#8217;t get it to happen. </p>



<p>And what if you actually need more than one allowed origin?  Per spec  <code>Access-Control-Allow-Origin</code> as again <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Origin">explained by MDN</a>, you can&#8217;t just include more than one in the header, the header is only allowed one: &#8221;&nbsp;If the server supports clients from multiple origins, it must return the origin for the specific client making the request.&#8221;  And you can&#8217;t do that with Rails static/global <code>config.public_file_server.headers</code>, we&#8217;d need to use and setup <a href="https://github.com/cyu/rack-cors">rack-cors</a> instead, or something else. </p>



<p>So I just said, eh, <code>*</code> is probably just fine. I don&#8217;t think it actually involves any security issues for rails static assets to do this?  I think it&#8217;s probably what everyone else is doing? </p>



<p>The <em>only</em> setup I needed for this to work was setting Cloudfront to allow <code>OPTIONS</code> HTTP method, and setting Rails <code>config.public_file_server.headers</code> to include <code>'Cache-Control' =&gt; 'public, max-age=31536000'</code>.</p>



<h2>Notes on Cache-Control max-age</h2>



<p>A lot of the existing guides <em>don&#8217;t</em> have you setting <code>config.public_file_server.headers</code> to include <code>'Cache-Control' =&gt; 'public, max-age=31536000'</code>. </p>



<p>But without this, will Cloudfront actually be caching at all? If with every single request to cloudfront, cloudfront makes a request to the Rails app for the asset and just proxies it &#8212; we&#8217;re not really getting much of the point of using Cloudfront in the first place, to avoid the traffic to our app! </p>



<p>Well, it turns out <strong>yes</strong>, Cloudfront will cache anyway. Maybe because of the <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesDefaultTTL">Cloudfront Default TTL setting</a>? My Default TTL was left at the Cloudfront default, 86400 seconds (one day). So I&#8217;d think that maybe Cloudfront would be caching resources for a day when I&#8217;m not supplying any <code>Cache-Control</code> or <code>Expires</code> headers?  </p>



<p>In my observation, it was actually caching for less than this though. Maybe an hour? (Want to know if it&#8217;s caching or not? Look at headers returned by Cloudfront. One easy way to do this? <code>curl -IXGET https://whatever.cloudfront.net/my/asset.jpg</code>, you&#8217;ll see a header either <code>x-cache: Miss from cloudfront</code> or <code>x-cache: Hit from cloudfront</code>). </p>



<p>Of course, Cloudfront doesn&#8217;t <em>promise</em> to cache for as long as it&#8217;s allowed to, it can evict things for it&#8217;s own reasons/policies before then, so maybe that&#8217;s all that&#8217;s going on. </p>



<p>Still, Rails assets are fingerprinted, so they are cacheable <em>forever</em>, so why not tell Cloudfront that? Maybe more importantly, if Rails isn&#8217;t returning a Cache-Cobntrol header, then <em>Cloudfront</em> isn&#8217;t either to actual user-agents, which means they won&#8217;t know they can cache the response in their own caches, and they&#8217;ll keep requesting/checking it on every reload too, which is not great for your far too large CSS and JS application files!</p>



<p>So, I think it&#8217;s probably a great idea to set the far-future <code>Cache-Control</code> header with <code>config.public_file_server.headers</code> as I&#8217;ve done above. We tell Cloudfront it can cache for the max-allowed-by-spec one year, and this also (I checked) gets Cloudfront to forward the header on to user-agents who will also know they can cache. </p>



<h2>Note on limiting Cloudfront Distribution to just static assets?</h2>



<p>The CloudFront distribution created above will actually proxy/cache our entire Rails app, you could access dynamic actions through it too. That&#8217;s not what we intend it for, our app won&#8217;t generate any URLs to it that way, but someone could. </p>



<p>Is that a problem?</p>



<p>I don&#8217;t know? </p>



<p>Some blog posts try to suggest limiting it only being willing to proxy/cache static assets instead, but this is actually a pain to do for a couple reasons:</p>



<ol><li>Cloudfront has changed their configuration for &#8220;path patterns&#8221; since many blog posts were written (unless you are using &#8220;legacy cache settings&#8221; options), such that I&#8217;m confused about how to do it at all, if there&#8217;s a way to get a distribution to stop caching/proxying/serving anything <em>but</em> a given path pattern anymore?</li><li>Modern Rails with webpacker has static assets at <em>both </em><code>/assets</code> and <code>/packs</code>, so you&#8217;d need two path patterns, making it even more confusing. (Why Rails why? Why aren&#8217;t packs just at <code>public/assets/packs</code> so all static assets are still under <code>/assets</code>?)</li></ol>



<p>I just gave up on figuring this out and figured it isn&#8217;t really a problem that Cloudfront is willing to proxy/cache/serve things I am not intending for it?  Is it? I hope? </p>



<h2>Note on Rails asset_path helper and asset_host</h2>



<p>You may have realized that Rails has both <code>asset_path</code> and <code>asset_url</code> helpers for linking to an asset. (And similar helpers with dashes instead of underscores in sass, and probably different implementations, <a href="https://guides.rubyonrails.org/asset_pipeline.html#css-and-sass">via sass-rails</a>)</p>



<p>Normally <code>asset_path</code> returns a relative URL without a host, and <code>asset_url</code>  returns a URL with a hostname in it. Since using an external <code>asset_host</code> requires we include the host with all URLs for assets to properly target CDN&#8230; you might think you have to stop using <code>asset_path</code> anywhere and just use <code>asset_url</code>&#8230; <em>You would be wrong. </em></p>



<p>It turns out if <code>config.asset_host</code> is set, <code>asset_path</code> starts including the host too. So everything is fine using asset_path.  Not sure if at that point it&#8217;s a synonym for asset_url? I think not entirely, because I think in fact once I set <code>config.asset_host</code>, some of my uses of <code>asset_url</code> actually started <em>erroring</em> and failing tests? And I had to actually only use asset_path? In ways I don&#8217;t really understand what&#8217;s going on and can&#8217;t explain it?</p>



<p>Ah, Rails. </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2021/06/23/notes-on-cloudfront-in-front-of-rails-assets-on-heroku-with-cors/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Heroku release phase, rails db:migrate, and command failure</title>
		<link>https://bibwild.wordpress.com/2021/06/16/heroku-release-phase-rails-dbmigrate-and-command-failure/</link>
					<comments>https://bibwild.wordpress.com/2021/06/16/heroku-release-phase-rails-dbmigrate-and-command-failure/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 16 Jun 2021 19:36:59 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9181</guid>

					<description><![CDATA[If you use capistrano to deploy a Rails app, it will typically run a rails db:migrate with every deploy, to apply any database schema changes. If you are deploying to heroku you might want to do the same thing. The heroku &#8220;release phase&#8221; feature makes this possible. (Introduced in 2017, the release phase feature is &#8230; <a href="https://bibwild.wordpress.com/2021/06/16/heroku-release-phase-rails-dbmigrate-and-command-failure/" class="more-link">Continue reading <span class="screen-reader-text">Heroku release phase, rails db:migrate, and command&#160;failure</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>If you use <a href="https://capistranorb.com/">capistrano</a> to deploy a Rails app, it will <a href="https://github.com/capistrano/rails">typically</a> run a <code>rails db:migrate</code> with every deploy, to apply any database schema changes. </p>



<p>If you are deploying to <a href="https://heroku.com">heroku</a> you might want to do the same thing. The <a href="https://devcenter.heroku.com/articles/release-phase">heroku &#8220;release phase&#8221; feature</a> makes this possible. (Introduced in 2017, the release phase feature is one of heroku&#8217;s more recent major features, as heroku dev has seemed to really stabilize and/or stagnate).</p>



<p>The release phase docs mention &#8220;running database schema migrations&#8221; as a use case, and there are a few (<a href="https://scottbartell.com/2020/01/22/automating-rails-database-migrations-on-heroku/">(1)</a>, <a href="https://rubyyagi.com/auto-migrate-heroku/">(2)</a>, <a href="https://mentalized.net/journal/2017/04/22/run-rails-migrations-on-heroku-deploy/">(3)</a>) blog posts on the web suggesting doing exactly that with Rails. Basically as simple as adding <code>release: bundle exec rake db:migrate</code> to your <code>Procfile</code>. </p>



<p>While some of the blog posts do remind you that &#8220;If the Release Phase fails the app will not be deployed&#8221;, I have found the implications of this to be more confusing in practice than one would originally assume. Particularly because on heroku <a href="https://devcenter.heroku.com/articles/releases">changing a config var</a> triggers a release; and it can be confusing to notice when such a release has failed. </p>



<p>It pays to consider the details a bit so you understand what&#8217;s going on, and possibly consider somewhat more complicated release logic than simply calling out to <code>rake db:migrate</code>. </p>



<h2>1) What if a config var change makes your Rails app unable to boot?</h2>



<p>I don&#8217;t know how unusual this is, but I actually had a real-world bug like this when in the process of setting up our heroku app.  Without confusing things with the details, we can simulate such a bug simply by putting this in, say, <code>config/application.rb</code>:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: plain; title: ; notranslate">
if ENV&#91;'FAIL_TO_BOOT']
  raise "I am refusing to boot"
end
</pre></div>


<p>Obviously my real bug was weirder, but the result was the same &#8212; with some settings of one or more heroku configuration variables, the app would raise an exception during boot. And we hadn&#8217;t noticed this in testing, before deploying to heroku. </p>



<p>Now, on heroku, using CLI or web dashboard, set the config var <code>FAIL_TO_BOOT</code> to &#8220;true&#8221;. </p>



<h3><em>Without</em> a release phase, what happens? </h3>



<ul><li>The <em>release</em> is <em>successful</em>! If you look at the release in the dashboard (&#8220;Activity&#8221; tab) or <code>heroku releases</code>, it shows up as successful. Which means heroku brings up new dynos and shuts down the previous ones, that&#8217;s what a release is. </li><li>The app crashes when heroku tries to start it in the new dynos. </li><li>The dynos will be in &#8220;crashed&#8221; state when looked at in <code>heroku ps</code> or dashboard. </li><li>If a user tries to access the web app, they will get the generic heroku-level &#8220;could not start app&#8221; error screen (unless you&#8217;ve customized your heroku error screens, as usual). </li><li>You can look in your heroku logs to see the error and stack trace that prevented app boot. </li></ul>



<p>Downside: your app is down. </p>



<p>Upside: It is pretty obvious that your app is down, and (relatively) why. </p>



<h3><em>With</em> a db:migrate release phase, what happens?</h3>



<p>The Rails <code>db:migrate</code> rake task has a dependency on the rails <code>:environment</code> task, meaning it boots the Rails app before executing. You just changed your config variable <code>FAIL_TO_BOOT: true</code> such that the Rails app can&#8217;t boot. Changing the config variable triggered a release. </p>



<p>As part of the release, the db:migrate release phase is run&#8230; which fails. </p>



<ul><li>The release is <em>not </em>succesful, it failed. </li><li>You don&#8217;t get any immediate feedback to that effect in response to your <code>heroku config:add</code> command or on the dashboard GUI in the &#8220;settings&#8221; tab. You may go about your business assuming it succeeded. </li><li>If you look at the release in <code>heroku releases</code> or dashboard &#8220;activity&#8221; tab you will see it failed. </li><li>You do get an email that it failed. Maybe you notice it right away, or maybe you notice it later, and have to figure out &#8220;wait, which release failed? And what were the effects of that? Should I be worried?&#8221;</li><li>The effects are:  <ul><li>The config variable <em>appears</em> changed in heroku&#8217;s dashboard or in response to <code>heroku config:get</code> etc. </li><li>The old dynos without the config variable change are still running. They don&#8217;t have the change. If you open a one-off dyno, it will be using the old release, and have the old (eg) ENV[&#8216;FAIL_TO_BOOT&#8217;] value. </li><li>ANY subsequent attempts at a releases will keep fail, so long as the app is in a state (based on teh current config variables) that it can&#8217;t boot. </li></ul></li></ul>



<p>Again, this really happened to me! It is a fairly confusing situation. </p>



<p>Upside: Your app is actually still up, even though you broke it, the old release that is running is still running, that&#8217;s good?</p>



<p>Downside: It&#8217;s really confusing what happened. You might not notice at first. Things remain in a messed up inconsistent and confusing state until you notice, figure out what&#8217;s going on, what release caused it, and how to fix it. </p>



<p>It&#8217;s a bit terrifying that any config variable change <em>could</em> do this. But I guess most people don&#8217;t run into it like I did, since I haven&#8217;t seen it mentioned? </p>



<h2>2) A heroku pg:promote is a config variable change, that will create a release in which db:migrate release phase fails. </h2>



<p><code><a href="https://devcenter.heroku.com/articles/heroku-postgresql#pg-promote">heroku pg:promote</a></code> is a command that will change which of multiple attached heroku postgreses are attached as the &#8220;primary&#8221; database, pointed to by the <code>DATABASE_URL</code> config variable. </p>



<p>For a typical app with only one database, you still might use <code>pg:promote</code> for a database upgrade process; for setting up or changing a postgres high-availability leader/follower; or, for what I was experimenting with it for, using <a href="https://devcenter.heroku.com/articles/heroku-postgres-rollback#common-use-case-recovery-after-critical-data-loss">heroku&#8217;s postgres-log-based rollback feature. </a></p>



<p>I had assumed that <code>pg:promote</code> was a zero-downtime operation. But, in debugging it&#8217;s interaction with my release phase, I noticed that <code>pg:promote</code> actually creates TWO heroku releases. </p>



<ol><li>First it creates a release labelled <code>Detach DATABASE</code> , in which there is no <code>DATABASE_URL</code> configuration variable at all. </li><li>Then it creates another release labelled <code>Attach DATABASE</code> in which the <code>DATABASE_URL</code> configuration variable is defined to it&#8217;s new value. </li></ol>



<p>Why does it do this instead of one release that just changes the <code>DATABASE_URL</code>? I don&#8217;t know. My app  (like most Rails and probably other apps) can&#8217;t actually function without <code>DATABASE_URL</code> set, so if that first release ever actually runs, it will just error out. Does this mean there&#8217;s an instant with a &#8220;bad&#8221; release deployed, that <code>pg:promote</code> isn&#8217;t actually zero-downtime?  I am not sure, it doens&#8217;t seem right (I did file a heroku support ticket asking&#8230;.). </p>



<p>But under normal circumstances, either it&#8217;s not a problem, or most people(?) don&#8217;t notice. </p>



<h3>But what if you have a db:migrate release phase?</h3>



<p>When it tries to do release (1) above, that release will <em>fail.</em> Because it tries to run <code>db:migrate</code>, and it can&#8217;t do that without a <code>DATABASE_URL</code> set, so it raises, the release phase exits in an error condition, the release fails. </p>



<p>Actually what happens is without DATABASE_URL set, the Rails app will assume a postgres URL in a &#8220;default&#8221; location, try to connect to, and fail, with an error message (hello googlers?), like:</p>



<pre class="wp-block-preformatted">ActiveRecord::ConnectionNotEstablished: could not connect to server: No such file or directory
	Is the server running locally and accepting
	connections on Unix domain socket "/var/run/postgresql/.s.PGSQL.5432"?</pre>



<p>Now, release (2) is coming down the pike seconds later, this is actually <em>fine</em>, and <em>will</em> be zero outage. We had a release that failed (so never was deployed), and seconds later the next correct release succeeds. Great!</p>



<p>The only problem is that we got an email notifying us that release 1 failed, and it&#8217;s also visible as failing in the heroku release list, etc. </p>



<p>A &#8220;background&#8221; (not in response to a <code>git push</code> or other code push to heroku) release failing is already a confusing situation &#8212; a&#8221;false positives&#8221; that actually mean &#8220;nothing unexpected or problematic happened, just ignore this and carry on.&#8221; is&#8230; really not something I want. (I call this the &#8220;error notification crying wolf&#8221;, right? I try to make sure my error notifications never do it, because it takes your time away from flow unecessarily, and/or makes it much harder to stay vigilant to real errors). </p>



<p>Now, there is a fairly simple solution to <em>this particular</em> problem. Here&#8217;s what I did. I changed my heroku release phase from <code>rake db:migrate</code> to a custom rake task, say  <code>release: bundle exec rake my_custom_heroku_release_phase</code>, defined like so:</p>



<figure class="wp-block-embed is-type-rich is-provider-embed wp-block-embed-embed"><div class="wp-block-embed__wrapper">
<style>.gist table { margin-bottom: 0; }</style><div style="tab-size: 8" id="gist110142017" class="gist">
    <div class="gist-file" translate="no">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-custom-rake" class="file my-2">
    
    <div itemprop="text" class="Box-body p-0 blob-wrapper data type-ruby  ">

        
<div class="js-check-bidi js-blob-code-container blob-code-content">

  <template class="js-file-alert-template">
  <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
  
    <span>
      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
    </span>


  <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">    Show hidden characters
</a>
</div>
</div></template>
<template class="js-line-alert-template">
  <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="line-alert tooltipped tooltipped-e">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
</span></template>

  <table data-hpc class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip data-tagsearch-lang="Ruby" data-tagsearch-path="custom.rake">
        <tr>
          <td id="file-custom-rake-L1" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="1"></td>
          <td id="file-custom-rake-LC1" class="blob-code blob-code-inner js-file-line"><span class=pl-en>task</span> <span class=pl-pds>:my_custom_heroku_release_phase</span> <span class=pl-k>do</span></td>
        </tr>
        <tr>
          <td id="file-custom-rake-L2" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="2"></td>
          <td id="file-custom-rake-LC2" class="blob-code blob-code-inner js-file-line">  <span class=pl-k>if</span> <span class=pl-c1>ENV</span><span class=pl-kos>[</span><span class=pl-s>&#39;DATABASE_URL&#39;</span><span class=pl-kos>]</span></td>
        </tr>
        <tr>
          <td id="file-custom-rake-L3" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="3"></td>
          <td id="file-custom-rake-LC3" class="blob-code blob-code-inner js-file-line">    <span class=pl-v>Rake</span>::<span class=pl-v>Task</span><span class=pl-kos>[</span><span class=pl-s>&quot;db:migrate&quot;</span><span class=pl-kos>]</span><span class=pl-kos>.</span><span class=pl-en>invoke</span></td>
        </tr>
        <tr>
          <td id="file-custom-rake-L4" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="4"></td>
          <td id="file-custom-rake-LC4" class="blob-code blob-code-inner js-file-line">  <span class=pl-k>else</span></td>
        </tr>
        <tr>
          <td id="file-custom-rake-L5" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="5"></td>
          <td id="file-custom-rake-LC5" class="blob-code blob-code-inner js-file-line">    $stderr<span class=pl-kos>.</span><span class=pl-en>puts</span> <span class=pl-s>&quot;<span class=pl-cce>\n</span>!!! WARNING, no ENV[&#39;DATABASE_URL&#39;], not running rake db:migrate as part of heroku release !!!<span class=pl-cce>\n</span><span class=pl-cce>\n</span>&quot;</span></td>
        </tr>
        <tr>
          <td id="file-custom-rake-L6" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="6"></td>
          <td id="file-custom-rake-LC6" class="blob-code blob-code-inner js-file-line">  <span class=pl-k>end</span></td>
        </tr>
        <tr>
          <td id="file-custom-rake-L7" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="7"></td>
          <td id="file-custom-rake-LC7" class="blob-code blob-code-inner js-file-line"><span class=pl-k>end</span></td>
        </tr>
  </table>
</div>


    </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/jrochkind/f4977b6fe89bfcac55b3bfdfc869ead5/raw/52983cafebd2dc609bab9e254d7792801f3aeeeb/custom.rake" style="float:right">view raw</a>
        <a href="https://gist.github.com/jrochkind/f4977b6fe89bfcac55b3bfdfc869ead5#file-custom-rake">
          custom.rake
        </a>
        hosted with &#10084; by <a href="https://github.com">GitHub</a>
      </div>
    </div>
</div>

</div></figure>



<p>Now that release (1) above at least won&#8217;t fail, it has the same behavior as a &#8220;traditional&#8221; heroku app without a release phase. </p>



<h2>Swallow-and-report all errors?</h2>



<p>When a release fails because a release phase has failed as result of a <code>git push</code> to heroku, that&#8217;s quite clear and fine!</p>



<p>But the confusion of the &#8220;background&#8221; release failure, triggered by a config var change, is high enough that part of me wants to just <code>rescue StandardError</code> in there, and prevent a failed release phase from ever exiting with a failure code, so heroku will never use a <code>db:migrate</code> release phase to abort a release. </p>



<p>Just return the behavior to the pre-release-phase heroku behavior &#8212; you can put your app in a situation where it will be crashed and not work, but maybe that&#8217;s better not a mysterious inconsistent heroku app state that happens in the background and you find out about only through asynchronous email notifications from heroku that are difficult to understand/diagnose. It&#8217;s all much more obvious.</p>



<p>On the other hand, if a db:migrate has failed not becuase of some unrelated boot process problem that is going to keep the app from launching too even if it were released, but simply because the db:migrate itself actually  failed&#8230; you kind of want the release to fail? That&#8217;s good? Keep the old release running, not a new release with code that expects a db migration that didn&#8217;t happen?</p>



<p>So I&#8217;m not really sure. </p>



<p>If you did want to rescue-swallow-and-notify, the custom rake task for your heroku release logic &#8212; instead of just telling heroku to run a standard thing like <code>db:migrate</code> on release &#8212; is certainly convenient. </p>



<h2>Also, do you really always want to db:migrate anyway? What about db:schema:load?</h2>



<p>Another alternative&#8230; if you are deploying an app with an <em>empty</em> database, standard Rails convention is to run <code>rails db:schema:load instead of db:migrate</code>. The db:migrate will <em>probably</em> work anyway, but will be slower, and somewhat more error-prone. </p>



<p>I guess this could come up on heroku with an initial deploy or (for some reason) a database that&#8217;s been nuked and restarted, or perhaps a Heroku <a href="https://devcenter.heroku.com/articles/github-integration-review-apps">&#8220;Review app&#8221;</a>? (I don&#8217;t use those yet)</p>



<p>stevenharman has a solution that actually checks the database, and runs the appropriate rails task depending on state, here <a href="https://gist.github.com/stevenharman/98576bf49b050b9e59fb26626b7cceff#file-bin-heroku_release-sh">in this gist.</a>  </p>



<p>I&#8217;d probably do it as a rake task instead of a bash file if I were going to do that. I&#8217;m not doing it at all yet. </p>



<p>Note that stevenharman&#8217;s solution will actually catch a non-existing or non-connectable database and not try to run migrations&#8230; but it will print an error message and <code>exit 1</code> in that case, failing the release &#8212; meaning that you will get a failed release in the <code>pg:promote</code> case mentioned above! </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2021/06/16/heroku-release-phase-rails-dbmigrate-and-command-failure/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Rails auto-scaling on Heroku</title>
		<link>https://bibwild.wordpress.com/2021/01/27/rails-auto-scaling-on-heroku/</link>
					<comments>https://bibwild.wordpress.com/2021/01/27/rails-auto-scaling-on-heroku/#comments</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 27 Jan 2021 17:28:45 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9069</guid>

					<description><![CDATA[We are investigating moving our medium-small-ish Rails app to heroku. We looked at both the Rails Autoscale add-on available on heroku marketplace, and the hirefire.io service which is not listed on heroku marketplace and I almost didn&#8217;t realize it existed. I guess hirefire.io doesn&#8217;t have any kind of a partnership with heroku, but still uses &#8230; <a href="https://bibwild.wordpress.com/2021/01/27/rails-auto-scaling-on-heroku/" class="more-link">Continue reading <span class="screen-reader-text">Rails auto-scaling on&#160;Heroku</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>We are investigating moving our medium-small-ish Rails app to heroku.  </p>



<p>We looked at both the <a href="https://elements.heroku.com/addons/rails-autoscale">Rails Autoscale add-on available on heroku marketplace</a>, and the <a href="https://www.hirefire.io/">hirefire.io service</a> which is <em>not</em> listed on heroku marketplace and I almost didn&#8217;t realize it existed. </p>



<p>I guess hirefire.io doesn&#8217;t have any kind of a partnership with heroku, but still uses the heroku API to provide an autoscale service.  hirefire.io ended up looking more fully-featured and lesser priced than Rails Autoscale; so the main service of this post is just trying to increase visibility of hirefire.io and therefore competition in the field, which benefits us consumers. </p>



<h2>Background: Interest in auto-scaling Rails background jobs</h2>



<p>At first I didn&#8217;t realize there was such a thing as &#8220;auto-scaling&#8221; on heroku, but once I did, I realized it could indeed save us lots of money.  </p>



<p>I am more interested in scaling <em>Rails background workers</em> than I a web workers though &#8212; our background workers are busiest when we are doing &#8220;ingests&#8221; into our digital collections/digital asset management system, so the work is highly variable. Auto-scaling up to more when there is ingest work piling up can give us really nice inget throughput while keeping costs low. </p>



<p>On the other hand, our web traffic is fairly low and probably isn&#8217;t going to go up by an order of magnitude (non-profit cultural institution here). And after <a href="https://bibwild.wordpress.com/2020/11/19/comparing-performance-of-a-rails-app-on-different-heroku-formations/">discovering that a &#8220;standard&#8221; dyno is just <em>too slow</em></a>, we will likely be running a performance-m or performance-l anyway &#8212; which likely can handle all anticipated traffic on it&#8217;s own. If we have an auto-scaling solution, we might configure it for web dynos, but we are especially interested in good features for background scaling. </p>



<p>There is a <a href="https://devcenter.heroku.com/articles/scaling#autoscaling">heroku built-in autoscale feature</a>, but it only works for <code>performance</code> dynos, <em>and</em> won&#8217;t do anything for Rails background job dynos, so that was right out. </p>



<p>That could work for Rails bg jobs, the Rails Autoscale add-on on the heroku marketplace; and then we found hirefire.io. </p>



<h2>Pricing: Pretty different</h2>



<h3>hirefire</h3>



<p>As of now January 2021, <a href="https://www.hirefire.io/">hirefire.io</a> has pretty simple and affordable pricing. <strong>$15/month/heroku application</strong>. <em>Auto-scaling as many dynos and process types as you like</em>. </p>



<p>hirefire.io by default can only check into your apps metrics to decide if a scaling event can occur <em>once per minute</em>. If you want more frequent than that (up to once every 15 seconds), you have to pay an additional $10/month, for <strong>$25/month/heroku application</strong>. </p>



<p>Even though it is not a heroku add-on, hirefire does advertise that they bill pro-rated to the second, just like heroku and heroku add-ons. </p>



<h3>Rails autoscale</h3>



<p>Rails autoscale has a more <a href="https://railsautoscale.com/#pricing">tiered approach to pricing</a> that is based on number and type of dynos you are scaling.  Starting at $9/month for 1-3 standard dynos, the next tier up is $39 for up to 9 standard dynos, all the way up to $279 (!) for 1 to 99 dynos.  If you have performance dynos involved, from $39/month for 1-3 performance dynos, up to $599/month for up to 99 performance dynos. </p>



<p>For our anticipated uses&#8230; if we<em> only</em> scale bg dynos, I might want to scale from (low) 1 or 2 to (high) 5 or 6 standard dynos, so we&#8217;d be at $39/month. Our web dynos are likely to be performance and I wouldn&#8217;t want/need to scale more than probably 2, but that puts us into performance dyno tier, so we&#8217;re looking at $99/month. </p>



<p>This is of course significantly more expensive than hirefire.io&#8217;s flat rate. </p>



<h4>Metric Resolution</h4>



<p>Since Hirefire had an additional charge for finer than 1-minute resolution on checks for autoscaling, we&#8217;ll discuss resolution here in this section too. Rails Autoscale has same resolution for all tiers, and I think <a href="https://railsautoscale.com/docs/questions/#how-quickly-does-rails-autoscale-respond-to-a-capacity-issue">it&#8217;s generally 10 seconds</a>, so approximately the same as hirefire if you pay the extra $10 for increased resolution. </p>



<h2>Configuration</h2>



<p>Let&#8217;s look at configuration screens to get a sense of feature-sets. </p>



<h3>Rails Autoscale</h3>



<h4>web dynos</h4>



<p>To configure web dynos, here&#8217;s what you get, with default values:</p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2021/01/r-a-web.png"><img data-attachment-id="9083" data-permalink="https://bibwild.wordpress.com/r-a-web/" data-orig-file="https://bibwild.files.wordpress.com/2021/01/r-a-web.png" data-orig-size="1828,1246" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="r-a-web" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2021/01/r-a-web.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2021/01/r-a-web.png?w=1024" src="https://bibwild.files.wordpress.com/2021/01/r-a-web.png?w=1024" alt="" class="wp-image-9083" srcset="https://bibwild.files.wordpress.com/2021/01/r-a-web.png?w=1024 1024w, https://bibwild.files.wordpress.com/2021/01/r-a-web.png?w=150 150w, https://bibwild.files.wordpress.com/2021/01/r-a-web.png?w=300 300w, https://bibwild.files.wordpress.com/2021/01/r-a-web.png?w=768 768w, https://bibwild.files.wordpress.com/2021/01/r-a-web.png 1828w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure>



<p>The metric Rails Autoscale uses for <a href="https://devcenter.heroku.com/articles/rails-autoscale#request-queue-time-threshold">scaling web dynos is time in heroku routing queue</a>, which seems right to me &#8212; when things are spending longer in heroku routing queue before getting to a dyno, it means scale up. </p>



<h4>worker dynos</h4>



<p>For scaling worker dynos, Rails Autoscale can scale dyno type named &#8220;worker&#8221; &#8212; it can understand ruby queuing libraries <a href="https://devcenter.heroku.com/articles/rails-autoscale#worker-autoscaling">Sidekiq, Resque, Delayed Job, or Que</a>. I&#8217;m not certain if there are options for writing custom adapter code for other backends. </p>



<p>Here&#8217;s what the configuration options are &#8212; sorry these aren&#8217;t the defaults, I&#8217;ve already customized them and lost track of what defaults are. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png"><img data-attachment-id="9087" data-permalink="https://bibwild.wordpress.com/screen-shot-2021-01-27-at-11-44-46-am/" data-orig-file="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png" data-orig-size="864,738" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2021-01-27-at-11.44.46-am" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png?w=864" src="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png?w=864" alt="" class="wp-image-9087" srcset="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png 864w, https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png?w=150 150w, https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png?w=300 300w, https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png?w=768 768w" sizes="(max-width: 864px) 100vw, 864px" /></a></figure>



<p>You can see that worker dynos are scaled based on the metric &#8220;number of jobs queued&#8221;, and you can tell it to only pay attention to certain queues if you want. </p>



<h3>Hirefire</h3>



<p>Hirefire has <em>far more options</em> for customization than Rails Autoscale, which can make it a bit overwhelming, but also potentially more powerful. </p>



<h4>web dynos</h4>



<p>You can actually configure <em>as many Heroku process types as you have</em> for autoscale, not just ones named &#8220;web&#8221; and &#8220;worker&#8221;. And for each, you have <a href="https://help.hirefire.io/article/46-getting-started">your choice of  several metrics</a> to be used as scaling triggers. </p>



<p>For web, I think <code>Queue Time (percentile, average)</code> matches what Rails Autoscale does, configured to <code>percentile</code>, <code>95</code>, and is probably the best to use unless you have a reason to use another.  (&#8220;<a href="https://devcenter.heroku.com/articles/rails-autoscale#request-queue-time-threshold">Rails Autoscale tracks the 95th percentile queue time, which for most applications will hover well below the default threshold of 100ms.</a>&#8220;)<br><br>Here&#8217;s what configuration Hirefire makes available if you are scaling on &#8220;queue time&#8221; like Rails Autoscale, configuration may vary for other metrics. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png"><img data-attachment-id="9095" data-permalink="https://bibwild.wordpress.com/screen-shot-2021-01-27-at-12-02-07-pm/" data-orig-file="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png" data-orig-size="701,1013" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2021-01-27-at-12.02.07-pm" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png?w=208" data-large-file="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png?w=701" src="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png?w=701" alt="" class="wp-image-9095" srcset="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png 701w, https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png?w=104 104w, https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png?w=208 208w" sizes="(max-width: 701px) 100vw, 701px" /></a></figure>



<p>I <em>think</em> if you fill in the right numbers, you can configure to work equivalently to Rails Autoscale. </p>



<h4>worker dynos</h4>



<p>If you have more than one heroku process type for workers — say, working on different queues — Hirefire can scale the independently, with entirely separate configuration. This is pretty handy, and I don&#8217;t <em>think</em> Rails Autoscale offers this.  (<strong>update</strong> i may be wrong, Rails Autoscale says they do support this, so check on it yourself if it matters to you). </p>



<p>For worker dynos, you could choose to scale based on actual &#8220;dyno load&#8221;, but I think this is probably mostly for types of processes where there isn&#8217;t the ability to look at &#8220;number of jobs&#8221;. A &#8220;number of jobs in queue&#8221; like Rails Autoscale does makes a lot more sense to me as an effective metric for scaling queue-based bg workers. </p>



<p>Hirefire&#8217;s metric is slightly difererent than Rails Autoscale&#8217;s &#8220;jobs in queue&#8221;. For recognized ruby queue systems (<a href="https://help.hirefire.io/article/53-job-queue-ruby-on-rails">a larger list</a> than Rails Autoscale&#8217;s; <em>and</em> you can write your own custom adapter for whatever you like), it actually measures jobs in queue <em><strong>plus</strong></em><strong> </strong>workers currently busy. So queued+in-progress, rather than Rails Autoscale&#8217;s just queued. I actually have a bit of trouble wrapping my head around the implications of this, but basically, it means that  Hirefire&#8217;s &#8220;jobs in queue&#8221; metric strategy is intended to try to scale all the way to emptying your queue, or reaching your max scale limit, whichever comes first.  I think this may make sense and work out at least as well or perhaps better than Rails Autoscale&#8217;s approach?</p>



<p>Here&#8217;s what configuration Hirefire makes available for worker dynos scaling on &#8220;job queue&#8221; metric. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2021/01/screen.png"><img data-attachment-id="9116" data-permalink="https://bibwild.wordpress.com/screen/" data-orig-file="https://bibwild.files.wordpress.com/2021/01/screen.png" data-orig-size="577,923" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2021/01/screen.png?w=188" data-large-file="https://bibwild.files.wordpress.com/2021/01/screen.png?w=577" src="https://bibwild.files.wordpress.com/2021/01/screen.png?w=577" alt="" class="wp-image-9116" srcset="https://bibwild.files.wordpress.com/2021/01/screen.png 577w, https://bibwild.files.wordpress.com/2021/01/screen.png?w=94 94w, https://bibwild.files.wordpress.com/2021/01/screen.png?w=188 188w" sizes="(max-width: 577px) 100vw, 577px" /></a></figure>



<p>Since the metric isn&#8217;t the same as Rails Autosale, we can&#8217;t configure this to work identically. But there are a whole bunch of configuration options, some similar to Rails Autoscale&#8217;s. </p>



<p>The most important thing here is that &#8220;Ratio&#8221; configuration. It may not be obvious, but with the way the hirefire metric works, you are basically meant to configure this to equal the number of workers/threads you have on each dyno. I have it configured to 3 because my heroku worker processes use resque, with resque_pool, configured to run 3 resque workers on each dyno. If you use sidekiq, set <code>ratio</code> to your configured <code>concurrency</code> &#8212; or if you are running more than one sidekiq process, processes*concurrency.  Basically how many jobs your dyno can be concurrently working is what you should normally set for &#8216;ratio&#8217;. </p>



<h2>Hirefire not a heroku plugin</h2>



<p>Hirefire isn&#8217;t actually a heroku plugin. In addition to that meaning separate invoicing, there can be some other inconveniences. </p>



<p>Since hirefire only can interact with heroku API, for some metrics  (<a href="https://help.hirefire.io/article/49-logplex-queue-time">including the &#8220;queue time&#8221; metric that is probably optimal for web dyno scaling</a>) you have to configure your app to log regular statistics to heroku&#8217;s &#8220;Logplex&#8221; system. This can add a lot of noise to your log, and for heroku logging add-ons that are tired based on number of log lines or bytes, can push you up to higher pricing tiers. </p>



<p>If you use paperclip, I think you should be able to use the <a href="https://documentation.solarwinds.com/en/Success_Center/papertrail/Content/kb/how-it-works/log-filtering.htm">log filtering</a> feature to solve this, keep that noise out of your logs and avoid impacting data log transfer limits. However, if you ever have cause to look at heroku&#8217;s raw logs, that noise will still be there. </p>



<h2>Support and Docs</h2>



<p>I asked a couple questions of both Hirefire and Rails Autoscale as part of my evaluation, and got back well-informed and easy-to-understand answers quickly from both. Support for both seems to be great. </p>



<p>I would say the documentation is decent-but-not-exhaustive for both products. Hirefire may have slightly more complete documentation. </p>



<h2>Other Features?</h2>



<p>There are other things you might want to compare, various kinds of observability (bar chart or graph of dynos or observed metrics) and notification. I don&#8217;t have time to get into the details (and didn&#8217;t actually spend much time exploring them to evaluate), but they seem to offer roughly similar features. </p>



<h2>Conclusion</h2>



<p>Rails Autoscale is quite a bit more expensive than hirefire.io&#8217;s flat rate, once you get past Rails Autoscale&#8217;s most basic tier (scaling no more than 3 standard dynos).  </p>



<p>It&#8217;s true that autoscaling <em>saves</em> you money over not, so even an expensive price could be considered a &#8216;cut&#8217; of that, and possibly for many ecommerce sites even $99 a month might a drop in the bucket (!)&#8230;. but this price difference is <em>so significant</em> with hirefire (which has flat rate regardless of dynos), that it seems to me it would take a <em>lot</em> of additional features/value to justify. </p>



<p>And it&#8217;s not clear that Rails Autoscale has any feature advantage. In general, hirefire.io seems to have <em>more</em> features and flexibility. </p>



<p>Until 2021, hirefire.io could only analyze metrics with 1-minute resolution, so perhaps that was a &#8220;killer feature&#8221;?</p>



<p>Honestly I wonder if this price difference is sustained by Rails Autoscale only because most customers aren&#8217;t aware of hirefire.io, it not being listed on the heroku marketplace? Single-invoice billing is handy, but probably not worth $80+ a month.    I guess hirefire&#8217;s logplex noise is a bit inconvenient?</p>



<p>Or is there something else I&#8217;m missing? Pricing competition is good for the consumer.</p>



<p>And are there any other heroku autoscale solutions, that can handle Rails bg job dynos, that I still don&#8217;t know about?</p>



<p><strong>update a day after writing</strong> <a href="https://www.reddit.com/r/Heroku/comments/l69y8v/rails_autoscaling_on_heroku/gkzfzho/">djcp on a reddit thread writes:</a></p>



<blockquote class="wp-block-quote"><p>I used to be a principal engineer for the heroku add-ons program.</p><p>One issue with hirefire is they request account level oauth tokens that essentially give them ability to do anything with your apps, where Rails Autoscaling worked with us to create a partnership and integrate with our &#8220;official&#8221; add-on APIs that limits security concerns and are scoped to the application that&#8217;s being scaled.</p><p>Part of the reason for hirefire working the way it does is historical, but we&#8217;ve supported the endpoints they need to scale for &#8220;official&#8221; partners for years now.</p><p>A lot of heroku customers use hirefire so please don&#8217;t think I&#8217;m spreading FUD, but you should be aware you&#8217;re giving a third party very broad rights to do things to your apps. They probably won&#8217;t, of course, but what if there&#8217;s a compromise?</p><p>&#8220;Official&#8221; add-on providers are given limited scoped tokens to (mostly) only the actions / endpoints they need, minimizing blast radius if they do get compromised.</p></blockquote>



<p>You can read some <a href="https://www.reddit.com/r/Heroku/comments/l69y8v/rails_autoscaling_on_heroku/gkzfzho/">more discussion at that thread. </a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2021/01/27/rails-auto-scaling-on-heroku/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>

		<media:content url="https://bibwild.files.wordpress.com/2021/01/r-a-web.png?w=1024" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-11.44.46-am.png?w=864" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2021/01/screen-shot-2021-01-27-at-12.02.07-pm.png?w=701" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2021/01/screen.png?w=577" medium="image"/>
	</item>
		<item>
		<title>Gem authors, check your release sizes</title>
		<link>https://bibwild.wordpress.com/2021/01/11/gem-authors-check-your-release-sizes/</link>
					<comments>https://bibwild.wordpress.com/2021/01/11/gem-authors-check-your-release-sizes/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Mon, 11 Jan 2021 22:32:56 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=9040</guid>

					<description><![CDATA[Most gems should probably be a couple hundred kb at most. I&#8217;m talking about the package actually stored in and downloaded from rubygems by an app using the gem. After all, source code is just text, and it doesn&#8217;t take up much space. OK, maybe some gems have a couple images in there. But if &#8230; <a href="https://bibwild.wordpress.com/2021/01/11/gem-authors-check-your-release-sizes/" class="more-link">Continue reading <span class="screen-reader-text">Gem authors, check your release&#160;sizes</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>Most gems should probably be a couple hundred kb at most. I&#8217;m talking about the package actually stored in and downloaded from rubygems by an app using the gem. </p>



<p>After all, source code is just text, and it doesn&#8217;t take up much space. OK, maybe some gems have a couple images in there. </p>



<p>But if you are looking at your gem in rubygems and realize that it&#8217;s 10MB or bigger&#8230; and that it seems to be getting bigger with every release&#8230; something is probably wrong and worth looking into it. </p>



<p>One way to look into it is to look at the actual gem package. If you use the <a href="https://schneems.com/blogs/2016-03-18-bundler-release-tasks">handy bundler rake task</a> to release your gem (and I recommend it), you have a <code>./pkg</code> directory in your source you last released from. Inside it are &#8220;.gem&#8221; files for  each release you&#8217;ve made from there, unless you&#8217;ve cleaned it up recently. </p>



<p><a href="https://www.veracode.com/blog/secure-development/how-extract-ruby-source-code-gem-packages-java">.gem files are just .tar files it turns out. </a> That have more tar and gz files inside them etc. We can go into it, extract contents, and use the handy unix utility <code>du -sh</code> to see what is taking up all the space.</p>



<h2>How I found the bytes </h2>



<pre class="wp-block-preformatted">jrochkind-chf kithe (master ?) $ cd pkg

jrochkind-chf pkg (master ?) $ ls
kithe-2.0.0.beta1.gem        kithe-2.0.0.pre.rc1.gem
kithe-2.0.0.gem            kithe-2.0.1.gem
kithe-2.0.0.pre.beta1.gem    kithe-2.0.2.gem

jrochkind-chf pkg (master ?) $ mkdir exploded

jrochkind-chf pkg (master ?) $ cp kithe-2.0.0.gem exploded/kithe-2.0.0.tar

jrochkind-chf pkg (master ?) $ cd exploded

jrochkind-chf exploded (master ?) $ tar -xvf kithe-2.0.0.tar
 x metadata.gz
 x data.tar.gz
 x checksums.yaml.gz

jrochkind-chf exploded (master ?) $  mkdir unpacked_data_tar

jrochkind-chf exploded (master ?) $ tar -xvf data.tar.gz -C unpacked_data_tar/

jrochkind-chf exploded (master ?) $ cd unpacked_data_tar/
/Users/jrochkind/code/kithe/pkg/exploded/unpacked_data_tar

jrochkind-chf unpacked_data_tar (master ?) $ du -sh *
 4.0K    MIT-LICENSE
  12K    README.md
 4.0K    Rakefile
 160K    app
 8.0K    config
  32K    db
 100K    lib
 300M    spec

jrochkind-chf unpacked_data_tar (master ?) $ cd spec

jrochkind-chf spec (master ?) $ du -sh *
 8.0K    derivative_transformers
 300M    dummy
  12K    factories
  24K    indexing
  72K    models
 4.0K    rails_helper.rb
  44K    shrine
  12K    simple_form_enhancements
 8.0K    spec_helper.rb
 188K    test_support
 4.0K    validators

jrochkind-chf spec (master ?) $ cd dummy/

jrochkind-chf dummy (master ?) $ du -sh *
 4.0K    Rakefile
  56K    app
  24K    bin
 124K    config
 4.0K    config.ru
 8.0K    db
 300M    log
 4.0K    package.json
  12K    public
 4.0K    tmp</pre>



<p>Doh! In this particular gem, I have a dummy rails app, and it has 300MB of logs, cause I haven&#8217;t b bothered trimming them in a while, that are winding up including in the gem release package distributed to rubygems and downloaded by all consumers!  Even if they were small, I don&#8217;t want these in the released gem package at all!</p>



<p>That&#8217;s not good!  It only turns into 12MB instead of 300MB, because log files are so compressable and there is compression involved in assembling the rubygems package. But I have no idea how much space it&#8217;s actually taking up on consuming applications machines. This is very irresponsible!</p>



<h2>What controls what files are included in the gem package?</h2>



<p>Your .gemspec file of course. The line <code>s.files = </code> is an array of every file to include in the gem package. Well, plus <code>s.test_files</code> is another array of more files, that aren&#8217;t supposed to be necessary to run the gem, but are to test it. </p>



<p>(Rubygems was set up to allow automated *testing* of gems after download, is why test files are included in the release package. I am not sure how useful this is, and who if anyone does it; although I believe that some linux distro packagers try to make use of it, for better or worse). </p>



<p>But nobody wants to list every file in your gem individually, manually editing the array every time you add, remove, or move one. Fortunately, gemspec files are executable ruby code, so you can use ruby as a shortcut. </p>



<p>I have seen two main ways of doing this, with different &#8220;gem skeleton generators&#8221; taking one of two approaches. </p>



<p>Sometimes a shell out to git is used &#8212; the idea is that everything you have checked into your git should be in the gem release package, no more or  no less. For instance, one of my gems has this in it, not sure where it came from or who/what generated it. </p>



<pre class="wp-block-preformatted">spec.files = `<code>git ls-files -z</code>`.split("\x0").reject do |f|
 f.match(%r{^(test|spec|features)/})
end</pre>



<p>In that case, it wouldn&#8217;t have included anything in ./spec already, so this obviously isn&#8217;t actually the gem we were looking at before. </p>



<p>But in this case, in addition to using ruby logic to manipulate the results, nothing excluded by your <code>.gitignore</code> file will end up included in your gem package, great! </p>



<p>In <code>kithe</code> we were looking at before, those log files <em>were</em> in the .gitignore (they weren&#8217;t in my repo!), so if I had been using that git-shellout technique, they wouldn&#8217;t have been included in the ruby release already. </p>



<p>But&#8230; I wasn&#8217;t. Instead this gem has a gemspec that looks like:</p>



<pre class="wp-block-preformatted">s.test_files = Dir["spec/*<em>/</em>"]</pre>



<p>Just include every single file inside <code>./spec</code> in the test_files list. Oops. Then I get all those log files!</p>



<h2>One way to fix</h2>



<p>I don&#8217;t really know which is to be preferred of the git-shellout approach vs the dir-glob approach. I suspect it is the subject of historical religious wars in rubydom, when there were still more people around to argue about such things. Any opinions? Or another approach?</p>



<p>Without being in the mood to restructure this gemspec in anyway, I just did the simplest thing to keep those log files out&#8230;</p>



<pre class="wp-block-preformatted">Dir["spec/*<em>/</em>"].delete_if {|a| a =~ %r{/dummy/log/}}</pre>



<p>Build the package without releasing with the handy bundler supplied <code>rake build</code> task&#8230; and my gem release package size goes from 12MB to 64K. (which actually kind of sounds like a minimum block size or something, right?)</p>



<p>Phew! That&#8217;s a big difference! Sorry for anyone using previous versions and winding up downloading all that cruft! (Actually this particular gem is mostly a proof of concept at this point and I don&#8217;t think anyone else is using it). </p>



<h2>Check your gem sizes!</h2>



<p>I&#8217;d be willing to be there are <em>lots</em> of released gems with heavily bloated release packages like this. This isn&#8217;t the first one I&#8217;ve realized was my fault. Because who pays attention to gem sizes anyway? Apparently not many!</p>



<p>But rubygems <a href="https://rubygems.org/gems/kithe">does list them</a>, so it&#8217;s pretty easy to see. Are your gem release packages multiple megs, when there&#8217;s no good reason for them to be?  Do they get <em>bigger</em> every release by far more than the bytes of lines of code  you think were added? At some point in gem history was there a big jump from hundreds of KB to multiple MB?  When nothing particularly actually happened to gem logic to lead to that?</p>



<p>All hints that you might be including things you didn&#8217;t mean to include, possibly things that grow each release. </p>



<p>You don&#8217;t need to have a dummy rails app in your repo to accidentally do this (I accidentally did it once with a gem that had nothing to do with rails). There could be other kind of log files. Or test coverage or performance metric files, or any other artifacts of your build or your development, especially ones that grow over time &#8212; that aren&#8217;t actually meant to or needed as part of the gem release package!</p>



<p>It&#8217;s good to sanity check your gem release packages now and then.  In most cases, your gem release package should be hundreds of KB at most, not MBs. Help keep your users&#8217; installs and builds faster and slimmer! </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2021/01/11/gem-authors-check-your-release-sizes/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Updating SolrCloud configuration in ruby</title>
		<link>https://bibwild.wordpress.com/2020/12/15/updating-solrcloud-configuration-in-ruby/</link>
					<comments>https://bibwild.wordpress.com/2020/12/15/updating-solrcloud-configuration-in-ruby/#comments</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Tue, 15 Dec 2020 18:00:58 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8964</guid>

					<description><![CDATA[We have an app that uses Solr. We currently run a Solr in legacy &#8220;not cloud&#8221; mode. Our solr configuration directory is on disk on the Solr server, and it&#8217;s up to our processes to get our desired solr configuration there, and to update it when it changes. We are in the process of moving &#8230; <a href="https://bibwild.wordpress.com/2020/12/15/updating-solrcloud-configuration-in-ruby/" class="more-link">Continue reading <span class="screen-reader-text">Updating SolrCloud configuration in&#160;ruby</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>We have an app that uses Solr. We currently run a Solr in legacy &#8220;not cloud&#8221; mode. Our solr configuration directory is on disk on the Solr server, and it&#8217;s up to our processes to get our desired solr configuration there, and to update it when it changes. </p>



<p>We are in the process of moving to a Solr in &#8220;<a href="https://lucene.apache.org/solr/guide/6_6/getting-started-with-solrcloud.html">SolrCloud mode</a>&#8220;, <em>probably</em> via the SearchStax managed Solr service. Our Solr &#8220;Cloud&#8221; might only have one node, but &#8220;SolrCloud mode&#8221; gives us access to additional API&#8217;s for managing your solr configuration, as opposed to writing it directly to disk (which may not be possible at all in SolrCloud mode? And certainly isn&#8217;t using managed SearchStax). </p>



<p>That is, the Solr <a href="https://lucene.apache.org/solr/guide/8_6/configsets-api.html">ConfigSets API</a>, although you might also want to use a few pieces of the <a href="https://lucene.apache.org/solr/guide/8_6/collection-management.html">Collection Management API</a> for associating a configset with a Solr collection. </p>



<p>Basically, you are taking your desired solr config directory, zipping it up, and <a href="https://lucene.apache.org/solr/guide/8_6/configsets-api.html#configsets-upload">uploading it to Solr as a &#8220;config set&#8221; [or &#8220;configset&#8221;] with a certain name</a>. Then you can create collections using this config set, or reassign which named configset an existing collection uses. </p>



<p>I wasn&#8217;t able to find any existing ruby gems for interacting with these Solr API&#8217;s. <a href="https://github.com/rsolr/rsolr">RSolr</a> is a &#8220;ruby client for interacting with solr&#8221;, but was written before most of these administrative API&#8217;s existed for Solr, and doesn&#8217;t seem to have been updated to deal with them (unless I missed it), RSolr seems to be mostly/only about querying solr, and some limited indexing.</p>



<p>But no worries, it&#8217;s not too hard to wrap the specific API I want to use in some ruby. Which did seem far better to me than writing the specific HTTP requests each time (and making sure you are dealing with errors etc!).  (And yes, I will share the code with you). </p>



<p>I decided I wanted an object that was bound to a particular solr collection at a particular solr instance; and was backed by a particular local directory with solr config. That worked well for my use case, and I wound up with an API that looks like this:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
updater = SolrConfigsetUpdater.new(
  solr_url: &quot;https://example.com/solr&quot;,
  conf_dir: &quot;./solr/conf&quot;,
  collection_name: &quot;myCollection&quot;
)

# will zip up ./solr/conf and upload it as named MyConfigset:
updater.upload(&quot;myConfigset&quot;)

updater.list #=&gt; &#91;&quot;myConfigSet&quot;]
updater.config_name # what configset name is MyCollection currently configured to use?
# =&gt; &quot;oldConfigSet&quot;

# what if we try to delete the one it's using?
updater.delete(&quot;oldConfigSet&quot;)
# =&gt; raises SolrConfigsetUpdater::SolrError with message:
# &quot;Can not delete ConfigSet as it is currently being used by collection &#91;myConfigset]&quot;

# okay let's change it to use the new one and delete the old one

updater.update_config_name(&quot;myConfigset&quot;)
# now MyCollection uses this new configset, although we possibly
# need to reload the collection to make that so
updater.reload
# now let's delete the one we're not using
updater.delete(&quot;oldConfigSet&quot;)
</pre></div>


<p>OK, great. There were some tricks in there in trying to catch the apparently multiple ways Solr can report different kinds of errors, to make sure Solr-reported errors turn into exceptions ideally with good error messages. </p>



<p>Now, in addition to uploading a configset initially for a collection you are creating to use, the main use case I have is wanting to UPDATE the configuration to new values in an existing collection. Sure, this often requires a reindex afterwards. </p>



<p>If you have the <a href="https://lucene.apache.org/solr/guide/8_7/solr-upgrade-notes.html">recently released Solr 8.7</a>, it will let you <em>overwrite</em> an existing configset, so this can be done pretty easily. </p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
updater.upload(updater.config_name, overwrite: true)
updater.reload
</pre></div>


<p>But prior to Solr 8.7 you can not overwrite an existing configset. And SearchStax doesn&#8217;t yet have Solr 8.7. So one way or another, we need to do a dance where we upload the configset under a new name than switch the collection to use it. </p>



<p>Having this updater object that lets us easily execute relevant Solr API lets us easily experiment with different logic flows for this. For instance in a <a href="https://dev.lucene.apache.narkive.com/HI7lTF0o/jira-created-solr-12925-configsets-api-should-allow-update-of-existing-configset#post4">Solr listserv thread</a>, Alex Halovnic suggests a somewhat complicated 8-step process workaround, which we can implement like so:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
current_name = updater.config_name
temp_name = "#{current_name}_temp"

updater.create(from: current_name, to: temp_name)
updater.change_config_name(temp_name)
updater.reload
updater.delete(current_name)
updater.upload(configset_name: current_name)
updater.change_config_name(current_name)
updater.reload
updater.delete(temp_name)
</pre></div>


<p>That works. But talking to Dann Bohn at Penn State University, he shared a different algorithm, which goes like:</p>



<ul><li>Make a cryptographic digest hash of the entire solr directory, which we&#8217;re going to use in the configset name. </li><li>Check if the collection is <em>already</em> using a configset named $<code>name_$digest</code>, which if it already is, you&#8217;re done, no change needed. </li><li>Otherwise, upload the configset with the fingerprint-based name, switch the collection to use it, reload, delete the configset that the collection used to use. </li></ul>



<p>At first this seemed like overkill to me, but after thinking and experimenting with it, I like it! It is really quick to make a digest of a handful of files, that&#8217;s not a big deal. (I use first 7 chars of hex SHA256). And even if we had Solr 8.7, I like that we can avoid doing any operation on solr at all if there had been no changes &#8212; I really want to use this operation much like a Rails <code>db:migrate</code>, running it on every deploy to make sure the solr schema matches the one in the repo for the depoy. </p>



<p>Dann also shared <a href="https://github.com/psu-stewardship/scholarsphere/blob/develop/lib/scholarsphere/solr_config.rb">his</a> <a href="https://github.com/psu-stewardship/scholarsphere/blob/develop/lib/scholarsphere/solr_admin.rb">open</a> source <a href="https://github.com/psu-stewardship/scholarsphere/blob/develop/lib/tasks/solr.rake">code</a> with me, which was helpful for seeing how to make the digest, how to make a Zip file in ruby, etc.  Thanks Dann!</p>



<h2>Sharing my code</h2>



<p>So I also wrote some methods to implement those variant updating stragies, Dann&#8217;s, and Alex Halovnic&#8217;s from the list etc. </p>



<p>I <em>thought</em> about wrapping this all up as a gem, but I didn&#8217;t really have the time to make it <em>really good enough</em> for that. My API is a little bit janky, I didn&#8217;t spend the extra time think it out really well to minimize the need for future backwards incompat changes like I would if it were a gem. I also couldn&#8217;t figure out a great way to write automated tests for this that I would find particularly useful; so in my code base it&#8217;s actually not currently test-covered (shhhhh) but in a gem I&#8217;d want to solve that somehow. </p>



<p>But I <em>did</em> try to write the code general purpose/flexible so other people could use it for their use cases; I tried to document it to my highest standards; and I put it all in <em>one file</em> which actually might not be the best OO abstraction/design, but makes it easier for you to copy and paste the single file for your own use. :)</p>



<p>So you can <a href="https://github.com/sciencehistory/scihist_digicoll/blob/a0a825a98cf0056d8e23df4fd5b479c8b8fd69d0/app/services/solr_configset_updater.rb">find my code here</a>;  it <a href="https://github.com/sciencehistory/scihist_digicoll/blob/master/LICENSE.txt">is apache-licensed</a>; and you are welcome to copy and paste it and do whatever you like with it, including making a gem yourself if you want. Maybe I&#8217;ll get around to making it a gem in the future myself, I dunno, curious if there&#8217;s interest. </p>



<h2>The SearchStax proprietary API&#8217;s</h2>



<p>SearchStax has it&#8217;s <em>own</em> API&#8217;s that can I think be used for <a href="https://www.searchstax.com/docs/staxapi2ZK/">updating configsets</a> and setting collections to use certain configsets etc. When I started exploring them, they are&#8217;t the <em>worst</em> vendor API&#8217;s I&#8217;ve seen, but I did find them a bit cumbersome to work with. The auth system involves a lot of steps (why can&#8217;t you just create an API Key from the SearchStax Web GUI?).</p>



<p>Overall I found them harder to use than just the standard Solr Cloud API&#8217;s, which worked fine in the SearchStax deployment, and have the added bonus of being transferable to any SolrCloud deployment instead of being SearchStax-specific.   While the SearchStax docs and support try to steer you to the SearchStax specific API&#8217;s, I don&#8217;t think there&#8217;s really any good reason for this. (Perhaps the custom SearchStax API&#8217;s were written long ago when Solr API&#8217;s weren&#8217;t as complete?)</p>



<p>SearchStax support suggested that the SearchStax APIs were somehow more secure; but my SearchStax Solr API&#8217;s are protected behind HTTP basic auth, and if I&#8217;ve created basic auth credentials (or IP addr allowlist) those API&#8217;s will be <em>available</em> to anyone with auth to access Solr whether I use em or not! And support also suggested that the SearchStax API use would be logged, whereas my direct Solr API use would not be, which seems to be true at least in default setup, I can probably  configure solr logging differently, but it just isn&#8217;t that important to me for these particular functions. </p>



<p>So after some initial exploration with SearchStax API, I realized that SolrCloud API (which I had never used before) could do everything I need and was more straightforward and transferable to use, and I&#8217;m happy with my decision to go with that. </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2020/12/15/updating-solrcloud-configuration-in-ruby/feed/</wfw:commentRss>
			<slash:comments>3</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Are you talking to Heroku redis in cleartext or SSL?</title>
		<link>https://bibwild.wordpress.com/2020/11/24/are-you-talking-to-heroku-redis-in-cleartext-or-ssl/</link>
					<comments>https://bibwild.wordpress.com/2020/11/24/are-you-talking-to-heroku-redis-in-cleartext-or-ssl/#comments</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Tue, 24 Nov 2020 19:57:49 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[heroku]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8929</guid>

					<description><![CDATA[In &#8220;typical&#8221; Redis installation, you might be talking to redis on localhost or on a private network, and clients typically talk to redis in cleartext. Redis doesn&#8217;t even natively support communications over SSL. (Or maybe it does now with redis6?) However, the Heroku redis add-on (the one from Heroku itself) supports SSL connections via &#8220;Stunnel&#8221;, &#8230; <a href="https://bibwild.wordpress.com/2020/11/24/are-you-talking-to-heroku-redis-in-cleartext-or-ssl/" class="more-link">Continue reading <span class="screen-reader-text">Are you talking to Heroku redis in cleartext or&#160;SSL?</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>In &#8220;typical&#8221; Redis installation, you might be talking to redis on localhost or on a private network, and clients typically talk to redis in cleartext. Redis doesn&#8217;t even natively support communications over SSL. (Or maybe it does now with redis6?)</p>



<p>However, the <a href="https://elements.heroku.com/addons/heroku-redis">Heroku redis add-on</a> (the one from Heroku itself) supports SSL connections via &#8220;Stunnel&#8221;, a <a href="https://redislabs.com/blog/stunnel-secure-redis-ssl/">tool popular with other redis users use to get SSL redis connections too</a>. (Or maybe via native redis with redis6? Not sure if you&#8217;d know the difference, or if it matters). </p>



<p>There are <a href="https://devcenter.heroku.com/articles/securing-heroku-redis">heroku docs on all of this</a> which say:</p>



<blockquote class="wp-block-quote"><p>While you can connect to Heroku Redis without the Stunnel buildpack, it is not recommend. The data traveling over the wire will be unencrypted.</p></blockquote>



<p>Perhaps especially because on heroku your app does not talk to redis via localhost or on a private network, but on a public network. </p>



<p>But I think I&#8217;ve worked on heroku apps before that missed this advice and are still talking to heroku in the clear. I just happened to run across it when I got curious about the <code>REDIS_TLS_URL</code> env/config variable I noticed heroku setting. </p>



<p>Which brings us to another thing, that <a href="https://devcenter.heroku.com/articles/securing-heroku-redis">heroku doc on it</a> is out of date, it doesn&#8217;t mention the <code>REDIS_TLS_URL</code> config variable, just the <code>REDIS_URL</code> one. The difference? the TLS version will be a url beginning with <code>rediss://</code> instead of <code>redis://</code> , note extra <code>s</code>, which many redis clients use as a convention for &#8220;SSL connection to redis probably via stunnel since redis itself doens&#8217;t support it&#8221;. The redis docs provide ruby and go examples which instead use <code>REDIS_URL</code> and writing code to swap the <code>redis://</code> for <code>rediss://</code> and even hard-code port number adjustments,  which is silly!</p>



<p><em>(While I continue to be very impressed with heroku as a product, I keep running into weird things like this outdated documentation, that does not match my experience/impression of heroku&#8217;s all-around technical excellence, and makes me worry if heroku is slipping&#8230;). </em></p>



<p>The docs also mention a weird <code>driver: ruby</code> arg for initializing the Redis client that I&#8217;m not sure what it is and it doesn&#8217;t seem necessary. </p>



<p>The docs are correct that you have to tell the ruby Redis client not to try to verify SSL keys against trusted root certs, and this implementation uses a self-signed cert.  Otherwise you will get an error that looks like: <code>OpenSSL::SSL::SSLError: SSL_connect returned=1 errno=0 state=error: certificate verify failed (self signed certificate in certificate chain)</code></p>



<p>So, can be as simple as:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
redis_client = Redis.new(url: ENV&#91;'REDIS_TLS_URL'], ssl_params: { verify_mode: OpenSSL::SSL::VERIFY_NONE })

$redis = redis_client
# and/or
Resque.redis = redis_client
</pre></div>


<p>I don&#8217;t use sidekiq on this project currently, but to get the SSL connection with VERIFY_NONE, looking at <a href="https://github.com/mperham/sidekiq/wiki/Using-Redis#complete-control">sidekiq docs</a> maybe on sidekiq docs you might have to(?):</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
redis_conn = proc {
  Redis.new(url: ENV&#91;'REDIS_TLS_URL'], ssl_params: { verify_mode: OpenSSL::SSL::VERIFY_NONE })
}

Sidekiq.configure_client do |config|
  config.redis = ConnectionPool.new(size: 5, &redis_conn)
end

Sidekiq.configure_server do |config|
  config.redis = ConnectionPool.new(size: 25, &redis_conn)
end
</pre></div>


<p>(Not sure what values you should pick for connection pool size). </p>



<p>While the sidekiq docs mention heroku in passing, they don&#8217;t mention need for SSL connections &#8212; I think awareness of this heroku feature and their recommendation you use it may not actually be common!</p>



<h2>Update: Beware <code>REDIS_URL</code> can also be <code>rediss</code></h2>



<p>On one of my apps I saw a <code>REDIS_URL</code> which used <code>redis:</code> and a <code>REDIS_TLS_URL</code> which uses (secure) <code>rediss:</code>. </p>



<p>But on another app, it provides *only* a <code>REDIS_URL</code>, which is <code>rediss</code> &#8212; meaning you have to set the <code>verify_mode: OpenSSL::SSL::VERIFY_NONE</code> when passing it to ruby redis client.  So you have to be prepared to do this with <code>REDIS_URL</code> values too &#8212; I think it shouldn&#8217;t hurt to set the <code>ssl_params</code> option even if you pass it a non-ssl <code>redis:</code> url, so just set it all the time? </p>



<p>This second app was heroku-20 stack, and the first was heroku-18 stack, is that the difference? No idea. </p>



<p>Documented anywhere? I doubt it. Definitely seems sloppy for what I expect of heroku, making me get a bit suspicious of whether heroku is sticking to the really impressive level of technical excellence and documentation I expect from them. </p>



<p>So, your best bet is to check for both <code>REDIS_TLS_URL</code> and <code>REDIS_URL</code>, prefering the TLS one if present, realizing the <code>REDIS_URL</code> can have a <code>rediss://</code> value in it too. </p>



<p>The <a href="https://devcenter.heroku.com/articles/securing-heroku-redis">heroku docs</a> also say you don&#8217;t get secure TLS redis connection on &#8220;hobby&#8221; plans, but I&#8221;m not sure that&#8217;s actually true anymore on heroku-20? Not trusting the docs is not a good sign. </p>



<p></p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2020/11/24/are-you-talking-to-heroku-redis-in-cleartext-or-ssl/feed/</wfw:commentRss>
			<slash:comments>5</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Comparing performance of a Rails app on different Heroku formations</title>
		<link>https://bibwild.wordpress.com/2020/11/19/comparing-performance-of-a-rails-app-on-different-heroku-formations/</link>
					<comments>https://bibwild.wordpress.com/2020/11/19/comparing-performance-of-a-rails-app-on-different-heroku-formations/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Thu, 19 Nov 2020 20:51:39 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8675</guid>

					<description><![CDATA[I develop a &#8220;digital collections&#8221; or &#8220;asset management&#8221; app, which manages and makes digitized historical objects and their descriptions available to the public, from the collections here at the Science History Institute. The app receives relatively low level of traffic (according to Google Analytics, around 25K pageviews a month), although we want it to be &#8230; <a href="https://bibwild.wordpress.com/2020/11/19/comparing-performance-of-a-rails-app-on-different-heroku-formations/" class="more-link">Continue reading <span class="screen-reader-text">Comparing performance of a Rails app on different Heroku&#160;formations</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I develop a &#8220;digital collections&#8221; or &#8220;asset management&#8221; <a href="https://digital.sciencehistory.org/">app</a>, which manages and makes digitized historical objects and their descriptions available to the public, from the collections here at the <a href="https://www.sciencehistory.org/">Science History Institute</a>. </p>



<p>The app receives relatively low level of traffic (according to Google Analytics, around 25K pageviews a <em>month</em>), although we want it to be able to handle spikes without falling down. It is not the most performance-optimized app, it does have some relatively slow responses and can be RAM-hungry. But it works adequately on our current infrastructure: Web traffic is handled on a single AWS EC2 <a href="https://aws.amazon.com/ec2/instance-types/t2/">t2.medium</a> instance, with 10 <a href="https://www.phusionpassenger.com/">passenger</a> processes (free version of passenger, so no multi-threading).</p>



<p>We are currently investigating the possibility of moving our infrastructure to <a href="https://www.heroku.com/home">heroku</a>. After <a href="https://bibwild.wordpress.com/2020/10/15/unexpected-performance-characteristics-when-exploring-migrating-a-rails-app-to-heroku/">realizing that heroku standard dynos did not</a> seem to have the performance characteristics I had expected, I decided to approach performance testing more methodically, to compare different heroku dyno formations to each other and to our current infrastructure.  Our basic research question is probably <em><strong>What heroku formation do we need to have similar performance to our existing infrastructure</strong></em>?</p>



<p>I am not an expert at doing this &#8212; I did some research, read <a href="https://www.speedshop.co/2015/07/29/scaling-ruby-apps-to-1000-rpm.html">some</a> <a href="https://work.stevegrossi.com/2015/02/07/load-testing-rails-apps-with-apache-bench-siege-and-jmeter/">blog</a> <a href="https://devcenter.heroku.com/articles/deploying-rails-applications-with-the-puma-web-server">posts</a>, did some thinking, and embarked on this. I am going to lead you through how I approached this and what I found. Feedback or suggestions are welcome.  <strong>The most surprising result I found was much poorer performance from heroku standard dynos than I expected, </strong>and specifically that standard dynos would not match performance of present infrastructure. </p>



<h2>What URLs to use in test</h2>



<p>Some older load-testing tools only support testing one URL over and over. I decided I wanted to test a larger sample list of URLs &#8212; to be a more &#8220;realistic&#8221; load, and also because repeatedly requesting only one URL might accidentally use caches in ways you aren&#8217;t expecting giving you unrepresentative results. (Our app does not currently use fragment caching, but caches you might not even be thinking about include <a href="https://severalnines.com/database-blog/overview-caching-postgresql">postgres&#8217;s built-in</a> automatic caches, or passenger&#8217;s automatic <a href="https://www.phusionpassenger.com/library/config/nginx/optimization/#turbocaching">turbocache</a> (which I don&#8217;t think we have turned on)). </p>



<p>My initial thought to get a list of such URLs from our already-in-production app  from production logs, to get a sample of what real traffic looks like. There were a couple barriers for me to using production logs as URLs: </p>



<ol><li>Some of those URLs might require authentication, or be POST requests. The bulk of our app&#8217;s traffic is GET requests available without authentication, and I didn&#8217;t feel like the added complexity of setting up anything else in a load traffic was worthwhile. </li><li>Our app on heroku isn&#8217;t fully functional yet. Without having connected it to a Solr or background job workers, only certain URLs are available. </li></ol>



<p>In fact, a large portion of our traffic is an &#8220;item&#8221; or &#8220;work&#8221; detail page like <a href="https://digital.sciencehistory.org/works/8049g603d">this one</a>. Additionally, those are the pages that can be the biggest performance challenge, since the current implementation includes a thumbnail for every scanned page or other image, so response time unfortunately scales with number of pages in an item. </p>



<p>So I decided a good list of URLs was simply a representative same of those &#8220;work detail&#8221; pages. In fact, rather than completely random sample, I took the 50 <em>largest/slowe</em>st<em> </em>work pages, and then added in another 150 randomly chosen from our current ~8K pages. And gave them all a randomly shuffled order. </p>



<p>In our app, every time a browser requests a work detail page, the JS on that page makes an additional request for a JSON document that powers our <a href="https://digital.sciencehistory.org/works/f4752h72t/viewer/xk81jm43b">page viewer</a>. So for each of those 200 work detail pages, I added the JSON request URL, for a more &#8220;realistic&#8221; load, and 400 total URLs.  </p>



<h2>Performance: &#8220;base speed&#8221; vs &#8220;throughput under load&#8221;</h2>



<p>Thinking about it, I realized there were two kinds of &#8220;performance&#8221; or &#8220;speed&#8221; to think about. </p>



<p>You might just have a really slow app, to exagerate let&#8217;s say typical responses are 5 seconds. That&#8217;s under low/no-traffic, a single browser is the only thing interacting with the app, it makes a single request, and has to wait 5 seconds for a response. </p>



<p>That number might be changed by optimizations or performance regressions in your code (including your dependencies). It might also be changed by moving or changing hardware or virtualization environment &#8212; including giving your database more CPU/RAM resources, etc. </p>



<p>But that number will<em> </em><strong>not </strong>change by horizontally scaling your deployment &#8212; adding more puma or passenger processes or threads, scaling out hosts with a load balancer or heroku dynos. None of that will change this <em><strong>base speed</strong></em> because it&#8217;s just how long the app takes to prepare a response when <em>not</em> under load, how slow it is in a test only <em>one</em> web worker , where adding web workers won&#8217;t matter because they won&#8217;t be used. </p>



<p><strong>Then</strong> there&#8217;s what happens to the app actually under load by multiple users at once. The <em>base speed</em> is kind of a lower bound on throughput under load &#8212; page response time is never going to get <em>better</em> than 5s for our hypothetical very slow app (without changing the underlying base speed). But it can get a lot worse if it&#8217;s hammered by traffic. This <em><strong>throughput under load </strong></em> can be effected not only by changing base speed, but also by various forms of horizontal scaling &#8212; how many puma or passenger processes you have with how many threads each, and how many CPUs they have access to, as well as number of heroku dynos or other hosts behind a load balancer. </p>



<p><em>(I had been thinking about this distinction already, but <a href="https://www.speedshop.co/2015/07/29/scaling-ruby-apps-to-1000-rpm.html">Nate Berkopec&#8217;s great blog post</a> on scaling Rails apps gave me the &#8220;speed&#8221; vs &#8220;throughout&#8221; terminology to use). </em></p>



<p>For my condition, we are not changing the code at all. But we are changing the host architecture from a manual EC2 t2.medium to heroku dynos (of various possible types) in a way that could effect <em>base speed</em>, and we&#8217;re <em>also</em> changing our scaling architecture in a way that could change <em>throughput under load </em>on top of that &#8212; from one t2.medium with 10 passenger process to possibly multiple heroku dynos behind heroku&#8217;s load balancer, and also (for Reasons) switching from free passenger to trying puma with multiple threads per process. (we are running puma 5 with new <a href="https://github.com/puma/puma/blob/master/5.0-Upgrade.md">experimental performance features</a> turned on). </p>



<p>So we&#8217;ll want to get a sense of base speed of the various host choices, and also look at how throughput under load changes based on various choices. </p>



<h2>Benchmarking tool: wrk</h2>



<p>We&#8217;re going to use <a href="https://github.com/wg/wrk">wrk</a>.  </p>



<p>There are <a href="https://k6.io/blog/comparing-best-open-source-load-testing-tools">LOTS of choices</a>  for HTTP benchmarking/load testing, with really varying complexity and from different eras of web history. I got a bit overwhelmed by it, but settled on wrk. Some other choices didn&#8217;t have all the features we need (some way to test a list of URLs, with at least some limited percentile distribution reporting). Others were much more flexible and complicated and I had trouble even figuring out how to use them!</p>



<p>wrk does need a custom lua script in order to handle a list of URLs.  I found a nice script <a href="https://github.com/timotta/wrk-scripts">here</a>, and modified it slightly to take filename from an ENV variable, and <em>not</em> randomly shuffle input list.  </p>



<p>It&#8217;s a bit confusing understanding the meaning of &#8220;threads&#8221; vs &#8220;connections&#8221; in <code>wrk</code> arguments. This <a href="https://engineering.appfolio.com/appfolio-engineering/2019/4/21/wrk-it-my-experiences-load-testing-with-an-interesting-new-tool">blog post from appfolio</a> clears it up a bit.  I decided to leave threads set to 1, and vary connections for load &#8212; so <code>-c1 -t1 </code>is a &#8220;one URL at a time&#8221; setting we can use to test &#8220;base speed&#8221;, and we can benchmark throughput under load by increasing connections. </p>



<p>We want to make sure we run the test for long enough to touch all 400 URLs in our list at least once, even in the slower setups, to have a good comparison &#8212; ideally it would be go through the list more than once, but for my own ergonomics I had to get through a lot of tests so ended up less tha ideal. (Should I have put fewer than 400 URLs in? Not sure). </p>



<h2>Conclusions in advance</h2>



<p>As benchmarking posts go (especially when I&#8217;m the one writing them), I&#8217;m about to drop a <strong>lot</strong> of words and data on you. So to maximize the audience that sees the conclusions (because they surprise me, and I want feedback/pushback on them), I&#8217;m going to give you some conclusions up front. </p>



<p>Our current infrastructure has web app on a single EC2 t2.medium, which is a burstable EC2 type &#8212; our relatively low-traffic app does not exhaust it&#8217;s burst credits. Measuring base speed (just one concurrent request at a time), we found that <em>performance</em> dynos seem to have about the CPU speed of a bursting t2.medium (just a hair slower). </p>



<p>But <em>standard</em> dynos are as a rule 2 to 3 times slower; additionally they are highly variable, and that variability can be over hours/days. A 3 minute period can have measured response times 2 or more times slower than another 3 minute period a couple hours later. But they seem to typically be 2-3x slower than our current infrastructure. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/basic.png"><img data-attachment-id="8851" data-permalink="https://bibwild.wordpress.com/basic/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/basic.png" data-orig-size="816,762" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="basic" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/basic.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/basic.png?w=816" src="https://bibwild.files.wordpress.com/2020/11/basic.png?w=816" alt="" class="wp-image-8851" srcset="https://bibwild.files.wordpress.com/2020/11/basic.png 816w, https://bibwild.files.wordpress.com/2020/11/basic.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/basic.png?w=300 300w, https://bibwild.files.wordpress.com/2020/11/basic.png?w=768 768w" sizes="(max-width: 816px) 100vw, 816px" /></a></figure>



<p>Under load, they scale about how you&#8217;d expect if you knew how many CPUs are present, no real surprises. Our existing t2.medium has two CPUs, so can handle 2 simultaneous requests as fast as 1, and after that degrades linearly. </p>



<p>A single <em>performance-L </em>($500/month) has 4 CPUs (8 hyperthreads), so scales under load much <em>better</em> than our current infrastructure. </p>



<p>A single <em>performance-M </em>($250/month) has only 1 CPU (!), so scales pretty terribly under load. </p>



<p>Testing scaling with 4 standard-2x&#8217;s ($200/month total), we see that it <em>scales</em> relatively evenly. Although lumpily because of variability, and it <em>starts out</em> so much worse performing that even as it scales &#8220;evenly&#8221; it&#8217;s still out-performed by all other arcchitectures. :( (At these relatively fast <em>median</em> response times you might say it&#8217;s still fast enough who cares, but in our fat tail of slower pages it gets more distressing). </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png"><img data-attachment-id="8899" data-permalink="https://bibwild.wordpress.com/load-median-compare/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png" data-orig-size="752,577" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="load.median.compare" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=752" alt="" class="wp-image-8899" srcset="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png 752w, https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>Now we&#8217;ll give you lots of measurements, or you can skip all that to my <a href="#discussion">summary discussion</a> or <a href="#conclusion">conclusions</a> for our own project at the end. </p>



<h2>Let&#8217;s compare base speed</h2>



<p>OK, let&#8217;s get to actual measurements! For &#8220;base speed&#8221; measurements, we&#8217;ll be telling <code>wrk</code> to use only one connection and one thread. </p>



<h3>Existing t2.medium: base speed</h3>



<p>Our current infrastructure is one EC2 <strong>t2.medium</strong>. This EC2 instance type has two vCPUs and 4GB of RAM. On that single EC2 instance, we run passenger (free not enterprise) set to have 10 passenger processes, although the base speed test with only one connection should only touch one of the workers.  The <code>t2</code> is a &#8220;<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-performance-instances.html">burstable</a>&#8221; type, and we <strong>do</strong> always have burst credits (this is not a high traffic app; verified we never exhausted burst credits in these tests), so our test load may be taking advantage of burst cpu. </p>



<pre class="wp-block-preformatted">$ URLS=./sample_works.txt  wrk -c 1 -t 1 -d 3m --timeout 20s --latency -s load_test/multiplepaths.lua.txt https://[current staging server]
 multiplepaths: Found 400 paths
 multiplepaths: Found 400 paths
 Running 3m test @ https://staging-digital.sciencehistory.org
   1 threads and 1 connections
   Thread Stats   Avg      Stdev     Max   +/- Stdev
     Latency   311.00ms  388.11ms   2.37s    86.45%
     Req/Sec    11.89      8.96    40.00     69.95%
   Latency Distribution
      50%   90.99ms
      75%  453.40ms
      90%  868.81ms
      99%    1.72s
   966 requests in 3.00m, 177.43MB read
 Requests/sec:      5.37
 Transfer/sec:      0.99MB</pre>



<p>I&#8217;m actually feeling pretty good about those numbers on our current infrastructure! 90ms median, not bad, and even 453ms 75th percentile is not too bad. Now, our test load involves some JSON responses that are quicker to deliver than corresponding HTML page, but still pretty good. The 90th/99th/and max request (2.37s) aren&#8217;t great, but I knew I had some slow pages, this matches my previous understanding of how slow they are in our current infrastructure. <br></p>



<p><strong>90th percentile is ~9 times 50th percenile. </strong></p>



<p>I don&#8217;t have an understanding of why the two different <code>Req/Sec</code> and <code>Requests/Sec</code> <a href="https://github.com/wg/wrk/issues/259">values are so different</a>, and don&#8217;t totally understand what to do with the <code>Stdev</code> and <code>+/- Stdev</code> values, so I&#8217;m just going to be sticking to looking at the latency percentiles, I think &#8220;latency&#8221; could also be called &#8220;response times&#8221; here. </p>



<p>But ok, this is our baseline for this workload.  And doing this 3 minute test at various points over the past few days, I can say it&#8217;s nicely regular and consistent, occasionally I got a slower run, but 50th percentile was usually 90ms&#8211;105ms, right around there. </p>



<h3>Heroku standard-2x: base speed</h3>



<p>From previous mucking about, I learned I can only reliably fit <em>one</em> puma worker in a standard-1x, and <a href="https://devcenter.heroku.com/articles/deploying-rails-applications-with-the-puma-web-server#process-count-value">heroku says</a> &#8220;we typically recommend a minimum of&nbsp;<code>2</code>&nbsp;processes, if possible&#8221; (for routing algorithmic reasons when scaled to multiple dynos),  so I am just starting at a standard-2x with two puma workers each with 5 threads, matching <a href="https://devcenter.heroku.com/articles/deploying-rails-applications-with-the-puma-web-server#recommended-default-puma-process-and-thread-configuration">heroku recommendations</a> for a standard-2x dyno. </p>



<p>So one thing I discovered is that bencharks from a heroku <code>standard</code> dyno are <em>really</em> variable, but here are typical ones:</p>



<pre class="wp-block-preformatted">$ heroku dyno:resize
 type     size         qty  cost/mo
 ───────  ───────────  ───  ───────
 web      Standard-2X  1    50

$ heroku config:get --shell WEB_CONCURRENCY RAILS_MAX_THREADS
 WEB_CONCURRENCY=2
 RAILS_MAX_THREADS=5

$ URLS=./sample_works.txt  wrk -c 1 -t 1 -d 3m --timeout 20s --latency -s load_test/multiplepaths.lua.txt https://scihist-digicoll.herokuapp.com/
 multiplepaths: Found 400 paths
 multiplepaths: Found 400 paths
 Running 3m test @ https://scihist-digicoll.herokuapp.com/
   1 threads and 1 connections
   Thread Stats   Avg      Stdev     Max   +/- Stdev
     Latency   645.08ms  768.94ms   4.41s    85.52%
     Req/Sec     5.78      4.36    20.00     72.73%
   Latency Distribution
      50%  271.39ms
      75%  948.00ms
      90%    1.74s
      99%    3.50s
   427 requests in 3.00m, 74.51MB read
 Requests/sec:      2.37
 Transfer/sec:    423.67KB</pre>



<p>I had heard that heroku <code>standard</code> dynos would have variable performance, because they are shared multi-tenant resources. I had been thinking of this like during a 3 minute test I might see around the same median with more standard deviation &#8212; but instead, what it looks like to me is that running this benchmark on Monday at 9am might give <em>very</em> different results than at 9:50am or Tuesday at 2pm. <strong>The variability is over a way longer timeframe than my 3 minute test</strong> &#8212; so that&#8217;s something learned. </p>



<p>Running this here and there over the past week, the above results seem to me typical of what I saw. (To get better than &#8220;seem typical&#8221; on this resource, you&#8217;d have to run a test, over several days or a week I think, probably not hammering the server the whole time, to get a sense of actual statistical distribution of the variability). </p>



<p>I sometimes saw tests that were quite a bit slower than this, up to a 500ms median. I rarely if ever saw results too much faster than this on a standard-2x. 90th percentile is ~6x  median, less than my current infrastructure, but that still gets up there to 1.74 instead of 864ms. </p>



<p>This typical one is quite a bit slower than than our current infrastructure, our median response time is 3x the latency, with 90th and max  being around 2x. This was worse than I expected. </p>



<h3>Heroku performance-m: base speed</h3>



<p>Although we might be able to fit more puma workers in RAM,  we&#8217;re running a single-connection base speed test, so it shouldn&#8217;t matter to, and we won&#8217;t adjust it. </p>



<pre class="wp-block-preformatted">$ heroku dyno:resize
 type     size           qty  cost/mo
 ───────  ─────────────  ───  ───────
 web      Performance-M  1    250

$ heroku config:get --shell WEB_CONCURRENCY RAILS_MAX_THREADS
 WEB_CONCURRENCY=2
 RAILS_MAX_THREADS=5

$ URLS=./sample_works.txt  wrk -c 1 -t 1 -d 3m --timeout 20s --latency -s load_test/multiplepaths.lua.txt https://scihist-digicoll.herokuapp.com/
 multiplepaths: Found 400 paths
 multiplepaths: Found 400 paths
 Running 3m test @ https://scihist-digicoll.herokuapp.com/
   1 threads and 1 connections
   Thread Stats   Avg      Stdev     Max   +/- Stdev
     Latency   377.88ms  481.96ms   3.33s    86.57%
     Req/Sec    10.36      7.78    30.00     37.03%
   Latency Distribution
      50%  117.62ms
      75%  528.68ms
      90%    1.02s
      99%    2.19s
   793 requests in 3.00m, 145.70MB read
 Requests/sec:      4.40
 Transfer/sec:    828.70KB</pre>



<p>This is a lot closer to the ballpark of our current infrastructure. It&#8217;s a bit slower (117ms median intead of 90ms median), but in running this now and then over the past week it was remarkably, thankfully, consistent. Median and 99th percentile are both 28% slower (makes me feel comforted that those numbers are the same in these two runs!), that doesn&#8217;t bother me so much if it&#8217;s predictable and regular, which it appears to be.   The <code>max</code> appears to me still a little bit less regular on heroku for some reason, since performance is supposed to be non-shared AWS resources, you wouldn&#8217;t expect it to be, but slow requests are slow, ok. </p>



<p>90th percentile is ~9x median, about the same as my current infrastructure. </p>



<h3>heroku performance-l: base speed</h3>



<pre class="wp-block-preformatted">$ heroku dyno:resize
 type     size           qty  cost/mo
 ───────  ─────────────  ───  ───────
 web      Performance-L  1    500

$ heroku config:get --shell WEB_CONCURRENCY RAILS_MAX_THREADS
 WEB_CONCURRENCY=2
 RAILS_MAX_THREADS=5

URLS=./sample_works.txt  wrk -c 1 -t 1 -d 3m --timeout 20s --latency -s load_test/multiplepaths.lua.txt https://scihist-digicoll.herokuapp.com/
 multiplepaths: Found 400 paths
 multiplepaths: Found 400 paths
 Running 3m test @ https://scihist-digicoll.herokuapp.com/
   1 threads and 1 connections
   Thread Stats   Avg      Stdev     Max   +/- Stdev
     Latency   471.29ms  658.35ms   5.15s    87.98%
     Req/Sec    10.18      7.78    30.00     36.20%
   Latency Distribution
      50%  123.08ms
      75%  635.00ms
      90%    1.30s
      99%    2.86s
   704 requests in 3.00m, 130.43MB read
 Requests/sec:      3.91
 Transfer/sec:    741.94KB</pre>



<p>No news is good news, it looks very much like <code>performance-m</code>, which is exactly what we expected, because this isn&#8217;t a load test. It tells us that performance-m and performance-l seem to have similar CPU speeds and similar predictable non-variable regularity, which is what I find running this test periodically over a week. </p>



<p>90th percentile is ~10x median, about the same as current infrastructure. </p>



<p>The higher Max speed is just evidence of what I mentioned, the speed of slowest request did seem to vary more than on our manual t2.medium, can&#8217;t really explain why. </p>



<h3>Summary: Base speed</h3>



<p>Not sure how helpful this visualization is,  charting 50th, 75th, and 90th percentile responses across architectures. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/basic.png"><img data-attachment-id="8851" data-permalink="https://bibwild.wordpress.com/basic/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/basic.png" data-orig-size="816,762" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="basic" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/basic.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/basic.png?w=816" src="https://bibwild.files.wordpress.com/2020/11/basic.png?w=816" alt="" class="wp-image-8851" srcset="https://bibwild.files.wordpress.com/2020/11/basic.png 816w, https://bibwild.files.wordpress.com/2020/11/basic.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/basic.png?w=300 300w, https://bibwild.files.wordpress.com/2020/11/basic.png?w=768 768w" sizes="(max-width: 816px) 100vw, 816px" /></a></figure>



<p>But basically: performance dynos perform similarly to my (bursting) t2.medium. Can&#8217;t explain why performance-l seems slightly slower than performance-m, might be just incidental variation when I ran the tests. </p>



<p><strong>The standard-2x is about twice as slow as my (bursting) t2.medium. </strong>Again recall standard-2x results varied a <em>lot</em> every time I ran them, the one I reported seems &#8220;typical&#8221; to me, that&#8217;s not super scientific, admittedly, but I&#8217;m confident that standard-2x are a lot slower in median response times than my current infrastructure. </p>



<h2>Throughput under load</h2>



<p>Ok, now we&#8217;re going to test using wrk to use more connections. In fact, I&#8217;ll test each setup with various number of connections, and graph the result, to get a sense of how each formation can handle throughput under load. (This means a lot of minutes to get all these results, at 3 minutes per number of connection test, per formation!). </p>



<p>An additional thing we can learn from this test, on heroku we can look at how much RAM is being used after a load test, to get a sense of the app&#8217;s RAM usage under traffic to understand the maximum number of puma workers we might be able to fit in a given dyno. </p>



<h3>Existing t2.medium: Under load</h3>



<p>A <a href="https://aws.amazon.com/ec2/instance-types/t2/">t2.medium</a> has 4G of RAM and 2 CPUs. We run 10 passenger workers (no multi-threading, since we are free, rather than enterprise, passenger). So what do we expect? With 2 CPUs and more than 2 workers, I&#8217;d expect it to handle 2 simultaneous streams of requests <em>almost</em> as well as 1; 3-10 should be quite a bit slower because they are competing for the 2 CPUs. Over 10, performance will probably become catastrophic. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png"><img data-attachment-id="8865" data-permalink="https://bibwild.wordpress.com/t2medium-load_-median-1-2/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png" data-orig-size="752,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="t2medium.load_.median-1" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png?w=752" alt="" class="wp-image-8865" srcset="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png 752w, https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>2 connections are exactly flat with 1, as expected for our two CPUs, hooray!</p>



<p>Then it goes up at a strikingly even line. Going over 10 (to 12) simultaneous connections doesn&#8217;t matter, even though we&#8217;ve exhausted our workers, I guess at this point there&#8217;s so much competition for the two CPUs already. </p>



<p>The slope of this curve is really nice too actually. Without load, our median response time is 100ms, but even at a totally overloaded 12 overloaded connections, it&#8217;s only 550ms, which actually isn&#8217;t too bad. </p>



<p>We can make a graph that in addition to median also has 75th, 90th, and 99th percentile response time on it:</p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png"><img data-attachment-id="8868" data-permalink="https://bibwild.wordpress.com/t2medium-load_-distro/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png" data-orig-size="752,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="t2medium.load_.distro" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png?w=752" alt="" class="wp-image-8868" srcset="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png 752w, https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>It doesn&#8217;t tell us too much; it tells us the upper percentiles rise at about the same rate as the median. At 1 simultaneous connection 90th percentile of 846ms is about 9 times the median of 93ms; at 10 requests the 90th percentile of 3.6 seconds is about 8 times the median of 471ms. </p>



<p><strong>This does remind us that under load when things get slow, this has more of a disastrous effect on already slow requests than fast requests. </strong>When not under load, even our 90th percentile was kind of sort of barley acceptable at 846ms, but under load at 3.6 seconds it really isn&#8217;t. </p>



<h3>Single Standard-2X dyno: Under load</h3>



<p>A standard-2X dyno <a href="https://devcenter.heroku.com/articles/dyno-types">has 1G of RAM</a>.  The (amazing, excellent, thanks schneems) heroku puma guide <a href="https://devcenter.heroku.com/articles/deploying-rails-applications-with-the-puma-web-server#recommended-default-puma-process-and-thread-configuration">suggests running two puma workers with 5 threads each. </a> At first I wanted to try running <em>three</em> workers, which seemed to fit into available RAM &#8212; but under heavy load-testing I was getting Heroku <code>R14 Memory Quota Exceeded</code> errors, so we&#8217;ll just stick with the heroku docs recommendations. Two workers with 5 threads each fit with plenty of headroom.  </p>



<p>A standard-2x dyno is runs on shared (multi-tenant) underlying Amazon virtual hardware. So while it is running on hardware with 4 CPUs (each of which can run two &#8220;<a href="https://www.credera.com/insights/whats-in-a-vcpu-state-of-amazon-ec2-in-2018/">hyperthreads</a>&#8220;), the puma doc suggests &#8220;it is best to assume only one process can execute at a time&#8221; on <code>standard</code> dynos. </p>



<p>What do we expect? Well, if it really only had one CPU, it would immediately start getting bad at 2 simulataneous connections, and just get worse from there. When we exceed the two worker count, will it get even worse? What about when we exceed the 10 thread (2 workers * 5 threads) count?</p>



<p><strong>You&#8217;d never run just one dyno if you were expecting this much traffic, </strong>you&#8217;d always horizontally scale. This very artificial test is just to get a sense of it&#8217;s characteristics. </p>



<p>Also, we remember that standard-2x&#8217;s are just really variable; I could get much worse or better runs than this, but graphed numbers from a run that seemed typical. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png"><img data-attachment-id="8874" data-permalink="https://bibwild.wordpress.com/standard2x-1-load_-median/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png" data-orig-size="752,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="standard2x.1.load_.median" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png?w=752" alt="" class="wp-image-8874" srcset="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png 752w, https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>Well, it really does act like 1 CPU, 2 simultaneous connections is <em>immediately</em> a lot worse than 1. </p>



<p>The line isn&#8217;t quite as straight as in our existing t2.medium, but it&#8217;s still pretty straight; I&#8217;d attribute the slight lumpiness to just the variability of shared-architecture standard dyno, and figure it would get perfectly straight with more data. </p>



<p>It degrades at about the same rate of our baseline t2.medium, but when you start out slower, that&#8217;s more disastrous. Our t2.medium at an overloaded 10 simultaneous requests is 473ms (pretty tolerable actually), 5 times the median at one request only. This standard-2x has a median response time of 273 ms at only one simultaneous request, and at an overloaded 10 requests has a median response time also about 5x worse, but that becomes a less tolerable 1480ms. </p>



<p>Does also graphing the 75th, 90th, and 99th percentile tell us much?</p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png"><img data-attachment-id="8877" data-permalink="https://bibwild.wordpress.com/standard2x-1-load_-distro/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png" data-orig-size="752,514" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="standard2x.1.load_.distro" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png?w=752" alt="" class="wp-image-8877" srcset="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png 752w, https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>Eh, I think the lumpiness is still just standard shared-architecture variability. </p>



<p>The rate of &#8220;getting worse&#8221; as we add more overloaded connections is actually a bit better than it was on our t2.medium, but since it already starts out so much slower, we&#8217;ll just call it a wash. (On t2.medium, 90th percentile without load is 846ms and under an overloaded 10 connections 3.6s. On this single standard-2x, it&#8217;s 1.8s and 5.2s). </p>



<p>I&#8217;m not sure how much these charts with various percentiles on them tell us, I&#8217;ll not include them for every architecture hence. </p>



<h3>standard-2x, 4 dynos: Under load</h3>



<p>OK, realistically we already know you shouldn&#8217;t have just one standard-2x dyno under that kind of load. You&#8217;d scale out, either manually or perhaps using something like the <a href="https://elements.heroku.com/addons/rails-autoscale">neat Rails Autoscale add-on</a>. </p>



<p>Let&#8217;s measure with 4 dynos. Each is still running 2 puma workers, with 5 threads each. </p>



<p>What do we expect? Hm, treating each dyno as if it has only one CPU, we&#8217;d expect it to be able to handle traffic pretty levelly up to 4 simultenous connections, distributed to 4 dynos. It&#8217;s going to do worse after that, but up to 8 there is still one puma worker per connection so it might get even worse after 8?</p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png"><img data-attachment-id="8882" data-permalink="https://bibwild.wordpress.com/standard2x-4-load_-median/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png" data-orig-size="752,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="standard2x.4.load_.median" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png?w=752" alt="" class="wp-image-8882" srcset="https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png 752w, https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>Well&#8230; I think that actually <em>is</em> relatively flat from 1 to 4 simultaneous connections, except for lumpiness from variability. But lumpiness from variability is huge! We&#8217;re talking 250ms median measured at 1 connection, up to 369ms measured median at 2, down to 274ms at 3. </p>



<p>And then maybe yeah, a fairly shallow slope up to 8 simutaneous connections than steeper. </p>



<p>But it&#8217;s all fairly shallow slope compared to our base t2.medium. At 8 connections (after which we pretty much max out), the standard-2x median of 464ms is only 1.8 times the median at 1 conection. Compared to the t2.median increase of 3.7 times. </p>



<p>As we&#8217;d expect, scaling out to 4 dynos (with four cpus/8 hyperthreads) helps us scale well &#8212; the problem is the baseline is so slow to begin (with very high bounds of variability making it regularly even slower).</p>



<h3>performance-m:  Under load</h3>



<p>A performance-m has <a href="https://devcenter.heroku.com/articles/dyno-types">2.5 GB of memory</a>. It only has <a href="https://devcenter.heroku.com/articles/deploying-rails-applications-with-the-puma-web-server#process-count-value">one physical CPU, although two &#8220;vCPUs&#8221;</a> (two hyperthreads) &#8212; and these are all your apps, it is not shared. </p>



<p>By testing under load, I demonstrated I could actually fit 12 workers on there without any memory limit errors. But is there any point to doing that with only 1/2 CPUs? Under a bit of testing, it appeared not. </p>



<p>The <a href="https://devcenter.heroku.com/articles/deploying-rails-applications-with-the-puma-web-server#recommended-default-puma-process-and-thread-configuration">heroku puma docs</a> recommend only 2 processes with 5 threads. <strong>You could do a whole little mini-experiment just trying to measure/optimize process/thread count on performance-m! </strong>We&#8217;ve already got too much data here, but in some experimentation it looked to me like <strong>5 processes with 2 threads each</strong> performed better (and certainly no worse) than 2 processes with 5 threads &#8212; if you&#8217;ve got the RAM just sitting there anyway (as we do), why not?</p>



<p><strong>I actually tested with 6 puma processes with 2 threads each. </strong>There is still a large amount of RAM headroom we aren&#8217;t going to use even under load. </p>



<p><strong>What do we expect? </strong>Well, with the 2 &#8220;hyperthreads&#8221; perhaps it can handle 2 simultaneous requests nearly as well as 1 (or not?); after that, we expect it to degrade quickly same as our original t2.medium did. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png"><img data-attachment-id="8889" data-permalink="https://bibwild.wordpress.com/perf-m-load_-median/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png" data-orig-size="752,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="perf-m.load_.median" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png?w=752" alt="" class="wp-image-8889" srcset="https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png 752w, https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>It an handle 2 connections slightly better than you&#8217;d expect if there really was only 1 CPU, so I guess a hyperthread does give you something. Then the slope picks up, as you&#8217;d expect; and it looks like it does get steeper after 4 simultaneous connections, yup. </p>



<h3>performance-l: Under load</h3>



<p>A performance-l ($500/month) costs twice as much as a performance-m ($250/month), but has <em>far</em> more than twice as much <a href="https://devcenter.heroku.com/articles/dyno-types">resources</a>. performance-l has a whopping 14GB of RAM compared to performance-m&#8217;s 2.5GB; and performance-l has 4 real CPUs/hyperthreads available to use (visible using the <a href="https://devcenter.heroku.com/articles/deploying-rails-applications-with-the-puma-web-server#process-count-value">nproc technique in the heroku puma article. </a></p>



<p>Because we have <em>plenty</em> of RAM to do so, we&#8217;re going to run 10 worker processes to match our original t2.medium&#8217;s. We still ran with 2 threads, just cause it seems like maybe you should never run a puma worker with only one thread? But who knows, maybe 10 workers with 1 thread each would perform better; plenty of room (but not plenty of my energy) for yet more experimentation. </p>



<p>What do we expect? The graph should be pretty flat up to 4 simultaneous connections, then it should start getting worse, pretty evenly as simultaneous connections rise all the way up to 12. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png"><img data-attachment-id="8895" data-permalink="https://bibwild.wordpress.com/performance-l-load_-median/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png" data-orig-size="752,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="performance-l.load_.median" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png?w=752" alt="" class="wp-image-8895" srcset="https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png 752w, https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>It is indeed pretty flat up to 4 simultaneous connections. Then up to 8 it&#8217;s still not too bad &#8212; median at 8 is only ~1.5 median at 1(!). Then it gets worse after 8 (oh yeah, 8 hyperthreads?). </p>



<p>But the slope is wonderfully shallow all the way. Even at 12 simultaneous connections, the median response time of 266ms is only 2.5x what it was at one connection. (In our original t2.medium, at 12 simultaneous connections median response time was over 5x what it was at 1 connection). </p>



<p>This thing is indeed a monster. </p>



<h2>Summary Comparison: Under load</h2>



<p>We showed a lot of graphs that look similar, but they all had different sclaes on the y-axis. Let&#8217;s plot median response times under load of all architectures on the same graph, and see what we&#8217;re really dealing with. </p>



<figure class="wp-block-image size-large"><a href="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png"><img data-attachment-id="8899" data-permalink="https://bibwild.wordpress.com/load-median-compare/" data-orig-file="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png" data-orig-size="752,577" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="load.median.compare" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=752" src="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=752" alt="" class="wp-image-8899" srcset="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png 752w, https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=150 150w, https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=300 300w" sizes="(max-width: 752px) 100vw, 752px" /></a></figure>



<p>The blue t2.medium is our baseline, what we have now. We can see that there isn&#8217;t really a similar heroku option, we have our choice of better or worse. </p>



<p>The performance-l is just plain better than what we have now. It starts out performing about the same as what we have now for 1 or 2 simultaneous connections, but then scales <em>so much flatter</em>. </p>



<p>The performance-m also starts out about thesame, but sccales <em>so much worse</em> than even what we have now. (it&#8217;s that 1 real CPU instead of 2, I guess?). </p>



<p>The standard-2x scaled to 4 dynos&#8230; has it&#8217;s own characteristics. It&#8217;s baseline is pretty terrible, it&#8217;s 2 to 3 times as slow as what we have now even not under load. But then it scales pretty well, since it&#8217;s 4 dynos after all, it doesn&#8217;t get worse as fast as performance-m does. But it started out so bad, that it remains far worse than our original t2.medium even under load.  Adding more dynos to standard-2x will help it remain steady under even <em>higher</em> load, but won&#8217;t help it&#8217;s underlying problem that it&#8217;s just slower than everyone else. </p>



<h2 id="discussion">Discussion: Thoughts and Surprises</h2>



<ul><li>I had been thinking of a t2.medium (even with burst) as &#8220;typical&#8221; (it is after all much slower than my 2015 Macbook), and has been assuming (in retrospect with no particular basis) that a heroku<em> standard</em> dyno would perform similarly. <ul><li>Most discussion and heroku docs, as well as the naming itself, suggest that a &#8216;standard&#8217; dyno is, well, standard, and performance dynos are for &#8220;super scale, high traffic apps&#8221;, which is not me. </li><li><strong>But in fact, heroku standard dynos are much slower <em>and</em> more variable in performance than a bursting t2.medium.</strong> I suspect they are slower than other options you might consider non-heroku &#8220;typical&#8221; options. <br><br><br><br> </li></ul></li><li>My conclusion is honestly that <strong>&#8220;standard&#8221;  dynos are really &#8220;for very fast, well-optimized apps that can handle slow and variable CPU&#8221; and &#8220;performance&#8221; dynos are really &#8220;standard, matching the CPU speeds  you&#8217;d get from a typical non-heroku option&#8221;</strong>.  <em>But this is not how they are documented or usually talked about. Are other people having really different experiences/conclusions than me? </em>If so, why, or where have I gone wrong?<ul><li>This of course has implications for estimating your heroku budget if considering switching over. :( </li></ul><ul><li>If you have a well-optimized fast app, say even 95th percentile is 200ms (on bursting t2.medium), then you can handle standard slowness &#8212; so what your 95th percentile is now 600ms (and during some time periods even much slower, 1s or worse, due to variability). That&#8217;s not so bad for a 95th percentile.</li><li>One way to get a very fast is of course caching. There is lots of discussion of using caching in Rails, sometimes the message (explicit or implicit) is &#8220;you have to use lots of caching to get reasonable performance cause Rails is so slow.&#8221; What if many of these people are on heroku, and it&#8217;s really <em>you have to use lots of caching to get reasonable performance on heroku <strong>standard</strong> dyno</em>??</li><li>I personally don&#8217;t think caching is maintenance free; in my experience properly doing cache invalidation and dealing with significant processing spikes needed when you <em>choose</em> to invalidate your entire cache (cause cached HTML needs to change) lead to real maintenance/development cost.  I have not needed caching to meet my performance goals on present architecture. </li><li>Everyone doesn&#8217;t necessarily have the same performance goals/requirements. Mine of a low-traffic non-commercial site are are maybe more modest, I just need users not to be super annoyed.   But whatever your performance goals, you&#8217;re going to have to spend more time on optimization on a heroku standard than something with much faster CPU &#8212; like a standard affordable mid-tier EC2. Am I wrong? <br><br><br></li></ul></li><li>One significant factor on heroku <em>standard</em> dyno performance is that they use shared/multi-tenant infrastructure. I wonder if they&#8217;ve actually gotten <em>lower performance</em> over time, as many customers (who you may be sharing with) have gotten better at maximizing their utilization, so the shared CPUs are typically more busy? Like a frog boiling, maybe nobody noticed that <em>standard</em> dynos have become lower performance? I dunno, brainstorming.<ul><li>Or maybe there are so many apps that <em>start</em> on heroku instead of switcching from somewhere else, that people just don&#8217;t realize that standard dynos are much slower than other low/mid-tier options?</li><li>I was expecting to pay a premium for heroku &#8212; but even standard-2x&#8217;s are a significant premium over paying for t2.medium EC2 yourself, one I found quite reasonable&#8230;. performance dynos are of course even more premium. <br><br><br></li></ul></li><li>I had a sort of baked-in premise that most Rails apps are &#8220;IO-bound&#8221;, they spend more time waiting on IO than using CPU. I don&#8217;t know where I got that idea, I heard it once a long time ago and it became part of my mental model. <strong>I now do not believe this is true true of my app, and I do not in fact believe it is true of most Rails apps in 2020. I would hypothesize that most Rails apps today are in fact CPU-bound</strong>. <br><br></li><li>The performance-m dyno only has <em>one CPU. </em> I had somehow also been assuming that it would have two CPUs &#8212; I&#8217;m not sure why, maybe just because at that price! It would be a <em>much</em> better deal with two CPUs. <ul><li>Instead we have a huge jump from $250 performance-m to $500 performance-l that has 4x the CPUs and ~5x the RAM. </li><li>So it doesn&#8217;t make financial sense to have more than one performance-m dyno, you might as well go to performance-l. But this really complicates auto-scaling, whether using <a href="https://devcenter.heroku.com/articles/scaling#autoscaling">Heroku&#8217;s feature</a>  , or the awesome <a href="https://elements.heroku.com/addons/rails-autoscale">Rails Autoscale add-on</a>.  I am not sure I can afford a performance-l all the time, and a performance-m might be sufficient most of the time. But if 20% of the time I&#8217;m going to need more (or even 5%, or even unexpectedly-mentioned-in-national-media), it would be nice to set things up to autoscale up&#8230;. I guess to financially irrational 2 or more performance-m&#8217;s? :(<br><br></li></ul></li><li>The performance-l is a <em>very big machine</em>, that is significantly <em>beefier</em> than my current infrastructure. And has <em>far more</em> RAM than I need/can use with only 4 physical cores. If I consider standard dynos to be pretty effectively low tier (as I do), heroku to me is kind of missing mid-tier options.  A 2 CPU option at 2.5G or 5G of RAM would make a lot of sense to me, and actually be exactly what I need&#8230; really I think performance-m would make more sense with 2 CPUs at it&#8217;s existing already-premium price point, and to be called a &#8220;performance&#8221; dyno. . Maybe heroku is intentionally trying set options to funnel people to the highest-priced performance-l. </li></ul>



<h2 id="conclusion">Conclusion: What are we going to do?</h2>



<p>In my investigations of heroku, my opinion of the developer UX and general service quality only increases. It&#8217;s a great product, that would increase our operational capacity and reliability, and substitute for so many person-hours of sysadmin/operational time if we were self-managing (even on cloud architecture like EC2). </p>



<p>But I had originally been figuring we&#8217;d use standard dynos (even more affordably, possibly auto-scaled with Rails Autoscale plugin), and am disappointed that they end up looking so much lower performance than our current infrastructure. </p>



<p>Could we use them anyway? Response time going from 100ms to 300ms &#8212; hey, 300ms is still <em>fine</em>, even if I&#8217;m sad to lose those really nice numbers I got from a bit of optimization. But this app has a <em>wide </em>long-tail ; our 75th percentile going from 450ms to 1s, our 90th percentile going from 860ms to 1.74s and our 99th going from 2.3s to 4.4s &#8212; <em>a lot harder to swallow. </em>Especially when we know that due to standard dyno variability, a slow-ish page that on my present architecture is <em>reliably</em> 1.5s, could really be anywhere from 3 to 9(!) on heroku. </p>



<p>I would anticipate having to spend a lot more developer time on optimization on heroku standard dynos &#8212; or, i this small over-burdened non-commercial shop, <em>not</em> prioritizing that (or not having the skills for it), and having our performance just get bad. </p>



<p><strong>So I&#8217;m really reluctant to suggest moving our app to heroku with standard dynos. </strong></p>



<p>A performance-l dyno is going to let us not have to think about performance any more than we do now, while scaling under high-traffic <em>better</em> than we do now &#8212; I suspect we&#8217;d never need to scale to more than one performance-l dyno. But it&#8217;s <em>pricey</em> for us. </p>



<p>A performance-m dyno has a base-speed that&#8217;s fine, but scales very poorly and unaffordably. Doesn&#8217;t handle an increase in load very well as one dyno, and to get more CPUs you have to pay far too much (especially compared to standard dynos I had been assuming I&#8217;d use). </p>



<p><strong>So I don&#8217;t really like any of my options</strong>. If we do heroku, maybe we&#8217;ll try a performance-m, and &#8220;hope&#8221; our traffic is light enough that a single one will do? Maybe with Rails autoscale for traffic spikes, even though 2 performance-m dynos isn&#8217;t financially efficient? If we are scaling to 2 (or more!) performance-m&#8217;s more than very occasionally, switch to performance-l, which means we need to make sure we have the budget for it?</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2020/11/19/comparing-performance-of-a-rails-app-on-different-heroku-formations/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/basic.png?w=816" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=752" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/basic.png?w=816" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.median-1.png?w=752" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/t2medium.load_.distro.png?w=752" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.median.png?w=752" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/standard2x.1.load_.distro.png?w=752" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/standard2x.4.load_.median.png?w=752" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/perf-m.load_.median.png?w=752" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/performance-l.load_.median.png?w=752" medium="image"/>

		<media:content url="https://bibwild.files.wordpress.com/2020/11/load.median.compare.png?w=752" medium="image"/>
	</item>
		<item>
		<title>faster_s3_url: Optimized S3 url generation in ruby</title>
		<link>https://bibwild.wordpress.com/2020/10/01/faster_s3_url-optimized-s3-url-generation-in-ruby/</link>
					<comments>https://bibwild.wordpress.com/2020/10/01/faster_s3_url-optimized-s3-url-generation-in-ruby/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Thu, 01 Oct 2020 18:10:58 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8625</guid>

					<description><![CDATA[Subsequent to my previous investigation about S3 URL generation performance, I ended up writing a gem with optimized implementations of S3 URL generation. github: faster_s3_url It has no dependencies (not even aws-sdk). It can speed up both public and presigned URL generation by around an order of magnitude. In benchmarks on my 2015 MacBook compared &#8230; <a href="https://bibwild.wordpress.com/2020/10/01/faster_s3_url-optimized-s3-url-generation-in-ruby/" class="more-link">Continue reading <span class="screen-reader-text">faster_s3_url: Optimized S3 url generation in&#160;ruby</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>Subsequent to my <a href="https://bibwild.wordpress.com/2020/08/26/speeding-up-s3-url-generation-in-ruby/">previous investigation about S3 URL generation performance</a><strong>,</strong> I ended up writing a gem with optimized implementations of S3 URL generation. </p>



<p>github: <a href="https://github.com/jrochkind/faster_s3_url">faster_s3_url</a> </p>



<p>It has no dependencies (not even aws-sdk). It can speed up both public and presigned URL generation by around an order of magnitude. In benchmarks on my 2015 MacBook compared to <code>aws-sdk-s3</code>:  public URLs from 180 in 10ms to 2200 in 10ms; presigned URLs from 10 in 10ms to 300 in 10ms (!!). </p>



<p>While if you are only generating a couple S3 URLs at a time you probably wouldn&#8217;t notice aws-sdk-ruby&#8217;s poor performance, if you are generating even just hundreds at a time, and especially for presigned URLs, it can really make a difference. </p>



<p>faster_s3_url supports the full API for <code>aws-sdk-s3</code> presigned URLs , including custom params like <code>response_content_disposition</code>. It&#8217;s tests actually test that results match what <code>aws-sdk-s3</code> would generate. </p>



<p>For <a href="https://shrinerb.com/">shrine</a> users, faster_s3_url includes a Shrine storage sub-class that can be drop-in replacement of <code>Shrine::Storage::S3</code> to just have all your S3 URL generations via shrine be using the optimized implementation. </p>



<p>Key in giving me the confidence to think I could pull off an independent S3 presigned URL implementation was WeTransfer&#8217;s <a href="https://github.com/WeTransfer/wt_s3_signer">wt_s3_signer</a> gem be succesful. wt_s3_signer makes some assumptions/restrictions to get even <em>higher</em> performance than faster_s3_url (two or three times as fast) &#8212; but the restrictions/assumptions and API to get that performance weren&#8217;t suitable for use cases, so I implemented my own.  </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2020/10/01/faster_s3_url-optimized-s3-url-generation-in-ruby/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Delete all S3 key versions with ruby AWS SDK v3</title>
		<link>https://bibwild.wordpress.com/2020/09/23/delete-all-s3-key-versions-with-ruby-aws-sdk-v3/</link>
					<comments>https://bibwild.wordpress.com/2020/09/23/delete-all-s3-key-versions-with-ruby-aws-sdk-v3/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 23 Sep 2020 15:37:06 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8614</guid>

					<description><![CDATA[If your S3 bucket is versioned, then deleting an object from s3 will leave a previous version there, as a sort of undo history. You may have a &#8220;noncurrent expiration lifecycle policy&#8221; set which will delete the old versions after so many days, but within that window, they are there. What if you were deleting &#8230; <a href="https://bibwild.wordpress.com/2020/09/23/delete-all-s3-key-versions-with-ruby-aws-sdk-v3/" class="more-link">Continue reading <span class="screen-reader-text">Delete all S3 key versions with ruby AWS SDK&#160;v3</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>If your S3 bucket is <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html">versioned</a>, then deleting an object from s3 will leave a previous version there, as a sort of undo history.   You may have a &#8220;noncurrent expiration lifecycle policy&#8221; set which will delete the old versions after so many days, but within that window, they are there. </p>



<p>What if you were deleting something that accidentally included some kind of sensitive or confidential information, and you really want it gone? </p>



<p>To make matters worse, if your bucket is public, the version is public too, and can be requested by an unauthenticated user that has the URL including a versionID, with a URL that looks something like: <code>https://mybucket.s3.amazonaws.com/path/to/someting.pdf?versionId=ZyxTgv_pQAtUS8QGBIlTY4eKmANAYwHT</code> To be fair, it would be pretty hard to &#8220;guess&#8221; this versionID!  But if it&#8217;s really sensitive info, that might not be good enough. </p>



<p>It was a bit tricky for me to figure out how to do this with the latest version of ruby SDK (as I write, &#8220;<strong>v3</strong>&#8220;, googling sometimes gave old versions). </p>



<p>It turns out you need to first retrieve a list of all versions with bucket.<a href="https://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/S3/Bucket.html#object_versions-instance_method">object_versions</a> . With no arg, that will return ALL the versions in the bucket, which could be a lot to retrieve, not what you want when focused on just deleting certain things. </p>



<p>If you wanted to delete all versions in a certain &#8220;directory&#8221;, that&#8217;s actually easiest of all:</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
s3_bucket.object_versions(prefix: "path/to/").batch_delete!
</pre></div>


<p>But what if you want to delete all versions from a specific key?  As far as I can tell, this is trickier than it should be. </p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
# danger! This may delete more than you wanted
s3_bucket.object_versions(prefix: "path/to/something.doc").batch_delete!
</pre></div>


<p>Because of how S3 &#8220;paths&#8221; (which are really just prefixes) work, that will ALSO delete all versions for <code>path/to/something.doc2</code> or <code>path/to/something.docdocdoc</code> etc, for anything else with that as a prefix. There probably aren&#8217;t keys like that in your bucket, but that seems dangerously sloppy to assume, that&#8217;s how we get super weird bugs later. </p>



<p>I guess there&#8217;d be no better way than this?</p>


<div class="wp-block-syntaxhighlighter-code "><pre class="brush: ruby; title: ; notranslate">
key = "path/to/something.doc"
s3_bucket.object_versions(prefix: key).each do |object_version|
  object_version.delete if object_version.object_key == key
end
</pre></div>


<p>Is there anyone reading this who knows more about this than me, and can say if there&#8217;s a better way, or confirm if there isn&#8217;t?</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2020/09/23/delete-all-s3-key-versions-with-ruby-aws-sdk-v3/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Github Actions tutorial for ruby CI on Drifting Ruby</title>
		<link>https://bibwild.wordpress.com/2020/09/09/github-actions-tutorial-for-ruby-ci-on-drifting-ruby/</link>
					<comments>https://bibwild.wordpress.com/2020/09/09/github-actions-tutorial-for-ruby-ci-on-drifting-ruby/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 09 Sep 2020 20:00:02 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8585</guid>

					<description><![CDATA[I&#8217;ve been using travis for free automated testing (&#8220;continuous integration&#8221;, CI) on my open source projects for a long time. It works pretty well. But it&#8217;s got some little annoyances here and there, including with github integration, that I don&#8217;t really expect to get fixed after its acquisition by private equity. They also seem to &#8230; <a href="https://bibwild.wordpress.com/2020/09/09/github-actions-tutorial-for-ruby-ci-on-drifting-ruby/" class="more-link">Continue reading <span class="screen-reader-text">Github Actions tutorial for ruby CI on Drifting&#160;Ruby</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I&#8217;ve been using travis for free automated testing (&#8220;continuous integration&#8221;, CI) on my open source projects for a long time. It works pretty well. But it&#8217;s got some little annoyances here and there, including with github integration, that I don&#8217;t really expect to get fixed after its <a href="https://news.ycombinator.com/item?id=18978251">acquisition by private equity.</a>  They also seem to have cut off actual support channels (other than &#8216;forums&#8217;) for free use; I used to get really good (if not rapid) support when having troubles, now I kinda feel on my own. </p>



<p>So after hearing about the pretty flexible and powerful newish <a href="https://github.com/features/actions">Github Actions</a> feature, I was interested in considering that as an alternative. It looks like it should be free for public/open source projects on github. And will presumably have good integration with the rest of github and few kinks. Yeah, this is an example of how a platform getting an advantage starting out by having good third-party integration can gradually come to absorb all of that functionality itself; but I just need something that works (and, well, is free for open source),  I don&#8217;t want to spend a lot of time on CI, I just want it to work and get out of the way. (And Github clearly introduced this feature to try to avoid being overtaken by Gitlab, which had integrated flexible CI/CD). </p>



<p><strong>So anyway. </strong>I was interested in it, but having a lot of trouble figuring out how to set it up. Github Actions is a <em>very flexible</em> tool, a whole platform really, which you can use to set up almost any kind of automated task you want, in many different languages. Which made it hard for me to figure out &#8220;Okay, I just want tests to run on all PR commits, and report back to the PR if it&#8217;s mergeable&#8221;. </p>



<p>And it was really hard to figure this out from the docs, it&#8217;s such a flexible abstract tool. And I have found it hard to find third party write-ups and tutorials and blogs and such &#8212; in part because Github Actions was in beta development for so long, that some of the write-ups I did find were out of date. </p>



<p>Fortunately <a href="https://www.driftingruby.com/episodes/github-actions">Drifting Ruby has provided a great tutorial, which gets you started with a basic ruby CI testing</a>. It looks pretty straightforward to for instance figure out how to swap in rspec for <code>rake test</code>. And I always find it easier to google for solutions to additional fancy things I want to do, finding results either in official docs or third-party blogs, when I have the basic skeleton in place. </p>



<p>I hope to find time to experiment with Github Actions in the future. I am writing this blog post in part to log for myself the Drifting Ruby episode so I don&#8217;t lose it!  The show summary has this super useful template:</p>



<figure class="wp-block-embed is-type-rich is-provider-embed wp-block-embed-embed"><div class="wp-block-embed__wrapper">
<style>.gist table { margin-bottom: 0; }</style><div style="tab-size: 8" id="gist105292280" class="gist">
    <div class="gist-file" translate="no">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-github-actions-ruby-ci-example-yaml" class="file my-2">
    
    <div itemprop="text" class="Box-body p-0 blob-wrapper data type-yaml  ">

        
<div class="js-check-bidi js-blob-code-container blob-code-content">

  <template class="js-file-alert-template">
  <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
  
    <span>
      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
    </span>


  <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">    Show hidden characters
</a>
</div>
</div></template>
<template class="js-line-alert-template">
  <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="line-alert tooltipped tooltipped-e">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
</span></template>

  <table data-hpc class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip data-tagsearch-lang="YAML" data-tagsearch-path="github-actions-ruby-ci-example.yaml">
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L1" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="1"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s">.github/workflows/main.yml</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L2" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="2"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-ent">name</span>: <span class="pl-s">CI</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L3" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="3"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC3" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L4" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="4"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-ent">on</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L5" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="5"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC5" class="blob-code blob-code-inner js-file-line">  <span class="pl-ent">push</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L6" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="6"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC6" class="blob-code blob-code-inner js-file-line">    <span class="pl-ent">branches</span>: <span class="pl-s">[ master, develop ]</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L7" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="7"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC7" class="blob-code blob-code-inner js-file-line">  <span class="pl-ent">pull_request</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L8" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="8"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC8" class="blob-code blob-code-inner js-file-line">    <span class="pl-ent">branches</span>: <span class="pl-s">[ master, develop ]</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L9" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="9"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC9" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L10" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="10"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-ent">jobs</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L11" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="11"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC11" class="blob-code blob-code-inner js-file-line">  <span class="pl-ent">test</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L12" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="12"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC12" class="blob-code blob-code-inner js-file-line">    <span class="pl-c"><span class="pl-c">#</span> services:</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L13" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="13"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC13" class="blob-code blob-code-inner js-file-line">    <span class="pl-c"><span class="pl-c">#</span>   db:</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L14" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="14"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC14" class="blob-code blob-code-inner js-file-line">    <span class="pl-c"><span class="pl-c">#</span>     image: postgres:11</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L15" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="15"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC15" class="blob-code blob-code-inner js-file-line">    <span class="pl-c"><span class="pl-c">#</span>     ports: [&#39;5432:5432&#39;]</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L16" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="16"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC16" class="blob-code blob-code-inner js-file-line">    <span class="pl-ent">runs-on</span>: <span class="pl-s">ubuntu-latest</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L17" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="17"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC17" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L18" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="18"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC18" class="blob-code blob-code-inner js-file-line">    <span class="pl-ent">steps</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L19" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="19"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC19" class="blob-code blob-code-inner js-file-line">      &#8211; <span class="pl-ent">uses</span>: <span class="pl-s">actions/checkout@v2</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L20" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="20"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC20" class="blob-code blob-code-inner js-file-line">      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Setup Ruby</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L21" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="21"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC21" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">uses</span>: <span class="pl-s">ruby/setup-ruby@v1.45.0</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L22" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="22"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC22" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">with</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L23" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="23"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC23" class="blob-code blob-code-inner js-file-line">          <span class="pl-ent">ruby-version</span>: <span class="pl-s">2.7.1</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L24" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="24"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC24" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L25" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="25"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC25" class="blob-code blob-code-inner js-file-line">      &#8211; <span class="pl-ent">uses</span>: <span class="pl-s">Borales/actions-yarn@v2.3.0</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L26" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="26"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC26" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">with</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L27" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="27"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC27" class="blob-code blob-code-inner js-file-line">          <span class="pl-ent">cmd</span>: <span class="pl-s">install</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L28" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="28"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC28" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L29" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="29"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC29" class="blob-code blob-code-inner js-file-line">      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Install Dependencies</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L30" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="30"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC30" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">run</span>: <span class="pl-s">|</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L31" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="31"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC31" class="blob-code blob-code-inner js-file-line"><span class="pl-s">          # sudo apt install -yqq libpq-dev</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L32" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="32"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC32" class="blob-code blob-code-inner js-file-line"><span class="pl-s">          gem install bundler</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L33" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="33"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC33" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L34" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="34"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC34" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span>      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Install Gems</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L35" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="35"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC35" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">run</span>: <span class="pl-s">|</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L36" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="36"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC36" class="blob-code blob-code-inner js-file-line"><span class="pl-s">          bundle install</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L37" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="37"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC37" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L38" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="38"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC38" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span>      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Prepare Database</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L39" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="39"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC39" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">run</span>: <span class="pl-s">|</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L40" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="40"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC40" class="blob-code blob-code-inner js-file-line"><span class="pl-s">          bundle exec rails db:prepare</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L41" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="41"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC41" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L42" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="42"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC42" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span>      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Run Tests</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L43" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="43"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC43" class="blob-code blob-code-inner js-file-line">        <span class="pl-c"><span class="pl-c">#</span> env:</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L44" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="44"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC44" class="blob-code blob-code-inner js-file-line">        <span class="pl-c"><span class="pl-c">#</span>   DATABASE_URL: postgres://postgres:@localhost:5432/databasename</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L45" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="45"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC45" class="blob-code blob-code-inner js-file-line">        <span class="pl-c"><span class="pl-c">#</span>   RAILS_MASTER_KEY: ${{secrets.RAILS_MASTER_KEY}}</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L46" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="46"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC46" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">run</span>: <span class="pl-s">|</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L47" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="47"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC47" class="blob-code blob-code-inner js-file-line"><span class="pl-s">          bundle exec rails test</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L48" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="48"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC48" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L49" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="49"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC49" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span>      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Create Coverage Artifact</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L50" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="50"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC50" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">uses</span>: <span class="pl-s">actions/upload-artifact@v2</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L51" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="51"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC51" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">with</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L52" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="52"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC52" class="blob-code blob-code-inner js-file-line">          <span class="pl-ent">name</span>: <span class="pl-s">code-coverage</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L53" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="53"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC53" class="blob-code blob-code-inner js-file-line">          <span class="pl-ent">path</span>: <span class="pl-s">coverage/</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L54" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="54"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC54" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L55" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="55"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC55" class="blob-code blob-code-inner js-file-line">  <span class="pl-ent">security</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L56" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="56"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC56" class="blob-code blob-code-inner js-file-line">    <span class="pl-ent">runs-on</span>: <span class="pl-s">ubuntu-latest</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L57" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="57"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC57" class="blob-code blob-code-inner js-file-line">    <span class="pl-ent">steps</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L58" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="58"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC58" class="blob-code blob-code-inner js-file-line">      &#8211; <span class="pl-ent">uses</span>: <span class="pl-s">actions/checkout@v2</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L59" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="59"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC59" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L60" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="60"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC60" class="blob-code blob-code-inner js-file-line">      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Setup Ruby</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L61" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="61"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC61" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">uses</span>: <span class="pl-s">ruby/setup-ruby@v1.45.0</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L62" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="62"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC62" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">with</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L63" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="63"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC63" class="blob-code blob-code-inner js-file-line">          <span class="pl-ent">ruby-version</span>: <span class="pl-s">2.7.1</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L64" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="64"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC64" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L65" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="65"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC65" class="blob-code blob-code-inner js-file-line">      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Install Brakeman</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L66" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="66"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC66" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">run</span>: <span class="pl-s">|</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L67" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="67"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC67" class="blob-code blob-code-inner js-file-line"><span class="pl-s">          gem install brakeman</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L68" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="68"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC68" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L69" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="69"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC69" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span>      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Run Brakeman</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L70" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="70"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC70" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">run</span>: <span class="pl-s">|</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L71" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="71"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC71" class="blob-code blob-code-inner js-file-line"><span class="pl-s">          brakeman -f json &gt; tmp/brakeman.json || exit 0</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L72" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="72"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC72" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L73" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="73"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC73" class="blob-code blob-code-inner js-file-line"><span class="pl-s"></span>      &#8211; <span class="pl-ent">name</span>: <span class="pl-s">Brakeman Report</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L74" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="74"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC74" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">uses</span>: <span class="pl-s">devmasx/brakeman-linter-action@v1.0.0</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L75" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="75"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC75" class="blob-code blob-code-inner js-file-line">        <span class="pl-ent">env</span>:</td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L76" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="76"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC76" class="blob-code blob-code-inner js-file-line">          <span class="pl-ent">REPORT_PATH</span>: <span class="pl-s">tmp/brakeman.json</span></td>
        </tr>
        <tr>
          <td id="file-github-actions-ruby-ci-example-yaml-L77" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="77"></td>
          <td id="file-github-actions-ruby-ci-example-yaml-LC77" class="blob-code blob-code-inner js-file-line">          <span class="pl-ent">GITHUB_TOKEN</span>: <span class="pl-s">${{secrets.GITHUB_TOKEN}}</span></td>
        </tr>
  </table>
</div>


    </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/jrochkind/e2d1ff059470caadd5d5454382977b53/raw/0b3b0366a0dab27a8fe99332e5a31bdabf3cb7ac/github-actions-ruby-ci-example.yaml" style="float:right">view raw</a>
        <a href="https://gist.github.com/jrochkind/e2d1ff059470caadd5d5454382977b53#file-github-actions-ruby-ci-example-yaml">
          github-actions-ruby-ci-example.yaml
        </a>
        hosted with &#10084; by <a href="https://github.com">GitHub</a>
      </div>
    </div>
</div>

</div></figure>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2020/09/09/github-actions-tutorial-for-ruby-ci-on-drifting-ruby/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Delivery patterns for non-public resources hosted on S3</title>
		<link>https://bibwild.wordpress.com/2020/08/27/access-patterns-for-s3-hosted-resources-with-access-control/</link>
					<comments>https://bibwild.wordpress.com/2020/08/27/access-patterns-for-s3-hosted-resources-with-access-control/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Thu, 27 Aug 2020 18:05:09 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8511</guid>

					<description><![CDATA[I work at the Science History Institute on our Digital Collections app (written in Rails), which is kind of a &#8220;digital asset management&#8221; app combined with a public catalog of our collection. We store many high-resolution TIFF images that can be 100MB+ each, as well as, currently, a handful of PDFs and audio files. We &#8230; <a href="https://bibwild.wordpress.com/2020/08/27/access-patterns-for-s3-hosted-resources-with-access-control/" class="more-link">Continue reading <span class="screen-reader-text">Delivery patterns for non-public resources hosted on&#160;S3</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>I work at the <a href="https://sciencehistory.org">Science History Institute</a> on our <a href="https://digital.sciencehistory.org">Digital Collections</a> app (written in Rails), which is kind of a &#8220;digital asset management&#8221; app combined with a public catalog of our collection. </p>



<p>We store many high-resolution TIFF images that can be 100MB+ each, as well as, currently, a handful of PDFs and audio files. We have around 31,000 digital assets, which make up about 1.8TB. In addition to originals, we have &#8220;derivatives&#8221; for each file (JPG conversions of a TIFF original at various sizes; MP3 conversions of FLAC originals; etc) &#8212; around 295,000 derivatives (~10 per original) taking up around 205GB. Not a huge amount of data compared to some, but big enough to be something to deal with, and we expect it could grow by an order of magnitude in the next couple years. </p>



<p>We store them all &#8212; originals and derivatives &#8212; in S3, which generally works great. </p>



<p>We <em>currently</em> store them all in <em>public</em> S3 buckets, and when we need an image thumb url for an &lt;img src&gt;, we embed a public S3 URL (as opposed to pre-signed URLs) right in our HTML source. Having the user-agent get the resources directly from S3 is awesome, because our app doesn&#8217;t have to worry about handling that portion of the &#8220;traffic&#8221;, something  S3 is quite good at (and there are CDN options which work seamlessly with S3 etc; although our traffic is currently fairly low and we aren&#8217;t using a CDN). </p>



<p>But this approach stops working if some of your assets can <em>not</em> be public,  and need to be access-controlled with some kind of authorization. And we are about to start hosting a class of assets that are such. </p>



<p>Another notable part of our app is that in it&#8217;s current design it can have a LOT of img src thumbs on a page. Maybe 600 small thumbs (one or each scanned page of a book), each of which might use an img srcset to deliver multiple resolutions. We use <a href="https://github.com/aFarkas/lazysizes">Javascript lazy load code</a> so the browser doesn&#8217;t actually try to load all these img src unless they are put in viewport,  but it&#8217;s still a lot of URLs generated on the page, and potentially a lot of image loads.  While this might be excessive and a design in ned of improvement, a 10&#215;10 grid of postage-stamp-sized thumbs on a page (each of which could use a srcset) does not seem unreasonable, right? There can be a lot of URLs on a page in an &#8220;asset management&#8221; type app, it&#8217;s how it is. </p>



<p>As I looked around for advice on this or analysis of the various options, I didn&#8217;t find much. So, in my usual verbose style, I&#8217;m going to outline my research and analysis of the various options here.  None of the options are as magically painless as using public bucket public URL on S3, alas. </p>



<h2>All public-read ACLs, Public URLs</h2>



<p>What we&#8217;re doing now. The S3 bucket is set as public, all files have <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html">S3 public-read ACL</a> set, and we use S3 &#8220;public&#8221; URLs as &lt;img src&gt; in our app. Which might look like <code>https://my-bucket.s3.us-west-2.amazonaws.com/path/to/thumb.jpg</code> . </p>



<p>For actual downloads, we might still use an S3 <a href="https://docs.aws.amazon.com/cli/latest/reference/s3/presign.html">presigned url </a>, not for access control (the object is already public), but to specify a <code>content-disposition</code> response header for S3 to use on the fly. </p>



<h3>Pro</h3>



<ul><li>URLs are persistent and stable and can be bookmarked, or indexed by search engines. (We really want our images in Google Images for visibility) And since the URLs are permanent and good indefinitely, they aren&#8217;t a problem for HTML including these urls in source to be cached indefinitely.  (as long as you don&#8217;t move your stuff around in your S3 buckets). </li><li>S3 public URLs are much cheaper to generate than the cryptographically presigned URLs, so it&#8217;s less of a problem generating 1200+ of them in a page response. (And can be optimized an order of magnitude further beyond the ruby SDK implementation). </li><li>S3 can scale to handle a lot of traffic, and Cloudfront or another CDN can easily be used to scale further. Putting a CDN on top of a public bucket is trivial. Our Rails app is entirely uninvolved in delivering the actual images, so we don&#8217;t need to use precious Rails workers on delivering images. </li></ul>



<h3>Con</h3>



<ul><li>Some of our materials are still being worked on by staff, and haven&#8217;t actually been published yet. But they are still in S3 with a public-read ACL. They have hard to guess URLs that shouldn&#8217;t be referred to on any publically viewable web page &#8212; but we know that shouldn&#8217;t be relied upon for anything truly confidential. <ul><li>That has been an acceptable design so far, as none of these materials are truly confidential, even if not yet published to our site.  But this is about to stop being acceptable as we include more truly confidential materials. </li></ul></li></ul>



<h2>All protected ACL, REDIRECT to presigned URL</h2>



<p>This is the approach taken by  <a href="https://edgeguides.rubyonrails.org/active_storage_overview.html">Rails&#8217; ActiveStorage</a> does in standard setup/easy path. It assumes all resources will stored to S3 <em>without</em> public ACL; a random user can&#8217;t access via S3 without a time-limited presigned URL being supplied by the app. </p>



<p>ActiveStorage&#8217;s standard implementation will give you a URL to your Rails app itself when you ask for a URL for an S3-stored asset &#8212; a rails URL is what might be in your &lt;img src&gt; urls.  That Rails URL will <em>redirect</em> to a unique temporary S3 presigned URL that allows access to the non-public resource. </p>



<h3>Pro</h3>



<ul><li>This pattern allows your app to decide based on current request/logged-in-user and asset, whether to grant acccess, on a case by case basis. (Although it&#8217;s not clear to me where the hooks are in ActiveStorage for this; I don&#8217;t actually use ActiveStorage, and it&#8217;s easy enough to implement this pattern generally, with authorization logic).</li><li>S3 is still delivering assets directly to your users, so scaling issues are still between S3 and the requestor, and your app doesn&#8217;t have to get involved. </li><li>The URLs that show up in your delivered HTML pages, say as &lt;img src&gt; or &lt;a href&gt; URLs &#8212; are pointing your app, and are still persistent and indefinitely valid &#8212; so the HTML is still indefinitely cacheable by any HTTP cache.  The will <em>redirect</em> to a unique-per-user and temporary presigned URL, but that&#8217;s not what&#8217;s in the HTML source. <ul><li>You can even more your images around (to different buckets/locations or entirely different services) without invalidating the cache of the HTML.  the URLs in your cached HTML don&#8217;t change, where they redirect to do. (This may be ActiveStorage&#8217;s motivation for this design?)</li></ul></li></ul>



<h3>Cons  </h3>



<ul><li>Might this interfere with Google Images indexing? While it&#8217;s hard (for me) to predict what might effect Google Images indexing, my own current site&#8217;s experience seems to say <em>its actually fine</em>. Google is willing to index an image &#8220;at&#8221; a URL that actually HTTP 302 redirects to a presigned S3 URL. Even though on every access the redirect will be to a different URL, Google doesn&#8217;t seem to think this is fishy.  Seems to be fine. </li><li>Makes figuring out how to put a CDN in the mix more of a chore, you can&#8217;t just put it in front of your S3, as you only want to CDN/cache public URLs, but may need to use more sophisticated CDN features or setup or choices. </li><li>The asset responses themselves, at presigned URLs, are not cacheable by an HTTP cache, either browser caching or intermediate. (Or at least not for more than a week, the maximum expiry of presigned urls). </li><li><strong>This is the big one.</strong> Let&#8217;s say you have 40 &lt;img src&gt; thumbnails on a page, and use this method. Every browser page load will result in an additional 40 requests <em>to your app</em>. This potentially requires you to scale your app much larger to handle the same amount of actual page requests, because your actual page requests are now (eg) 40x. <ul><li><a href="https://stackoverflow.com/questions/59013049/rails-activestorage-how-to-avoid-one-redirect-for-each-image">This has been reported as an actual problem</a> by Rails ActiveStorage users. An app can suddenly handle far less traffic because it&#8217;s spending so much time doing all these redirects. </li><li>Therefore, ActiveStorage users/developers then tried to figure out how to get ActiveStorage to instead use the &#8220;All public-read ACLs, Public URLs delivered directly&#8221; model we listed above. It is now possible to do that with ActiveStorage (some answers in that StackOverflow), which is great, because it&#8217;s a great model when all your assets can be publicly available&#8230; but that was already easy enough to do without AS, we&#8217;re here cause that&#8217;s not my situation and I need something else!. </li><li>On another platform that isn&#8217;t Rails, the performance concerns might be less, but Rails can be, well, slow here. In <em>my</em> app, a response that does nothing but redirect to <code>https://example.com</code> can still take 100ms to return! I think an out-of-the-box Rails app would be a bit faster, I&#8217;m not sure what is making mine so slow. But even at 50ms, an extra (eg) 40x50ms == 2000ms of worker time for every page delivery is a price to pay. </li><li>In my app where many pages may actually have not 40 but 600+ thumbs on them&#8230; this is can be really bad. Even if JS lazy-loading is used, it just seems like asking for trouble. </li></ul></li></ul>



<h2>All protected ACL, PROXY to presigned URL</h2>



<p>Okay, just like above, but the app action, instead of redireting to S3&#8230;. actually reads the bytes from s3 on the back-end, and delivers them to to the user-agent directly, as a sort of proxy. </p>



<p>The pros/cons are pretty similar to redirect solution, but mostly with a lot of extra cons&#8230;.</p>



<h3>Extra Pro</h3>



<ul><li>I guess it&#8217;s an extra pro that the fact it&#8217;s on S3 is completely invisible to the user-agent, so it can&#8217;t possibly mess up Google Images indexing or anything like that.</li></ul>



<h3>Extra Cons</h3>



<ul><li>If you were worried about the scaling implications of tying up extra app workers with the redirect solution, this is <em><strong>so much worse</strong></em>, as app workers are now tied up for as long as it takes to proxy all those bytes from S3 (hopefully the nginx or passenger you have in front of your web app means you aren&#8217;t worried about slow clients, but that byte shuffling from S3 will still add up). </li><li>For very large assets, such as I have, this is likely incompatible with a heroku deploy, because of <a href="https://devcenter.heroku.com/articles/request-timeout">heroku&#8217;s 30s request timeout</a>. </li></ul>



<p>One reason I mention this option, is I believe it is basically what a <a href="https://github.com/samvera/hyrax">hyrax</a> app (some shared code used in our business domain) does. Hyrax isn&#8217;t necessarily using S3, but I believe does have the Rails app involved in proxying and delivering bytes for all files (including derivatives), including for &lt;img src&gt;.  So that approach is working for them well enough, so maybe shouldn&#8217;t be totally dismissed. But it doesn&#8217;t seem right to me &#8212; I really liked the much better scaling curve of our app when we moved it away from sufia (a hyrax precedessor), and got it to <em>stop</em> proxying bytes like this. Plus I think this is probably a barrier to deploying hyrax apps to heroku, and we are interested in investigating heroku with our app. </p>



<h2>All protected ACL, have nginx proxy to presigned URL?</h2>



<p>OK, like the above &#8220;proxy&#8221; solution, but with a twist. A Rails app is not the right technology for proxying lots of bytes. </p>



<p>But nginx is, that&#8217;s honestly it&#8217;s core use case, it&#8217;s literally built for a proxy use case, right? It should be able to handle lots of em concurrently with reasonable CPU/memory resources. If we can get nginx doing the proxying, we don&#8217;t need to worry about tying up Rails workers doing it. </p>



<p>I got really excited about this for a second&#8230; but it&#8217;s kind of a confusing mess. What URLs are we actually delivering in &lt;img src&gt; in HTML source?  If they are Rails app URLs, that will then trigger an nginx proxy using something like <a href="https://www.nginx.com/resources/wiki/start/topics/examples/x-accel/">nginx x-accel</a> <strong>but</strong> for to a remote (presigned S3) URL instead of a local file, we have all the same downsides as the REDIRECT option above, without any real additional benefit (unless you REALLY want to hide that it&#8217;s from S3). </p>



<p>If instead we want to embed URLs in the HTML source that will end up being handled directly by nginx without touching the Rails app&#8230; it&#8217;s just really confusing to figure out how to set nginx up to proxy non-public content from S3. nginx has to be creating signed requests&#8230; but we also want to access-control it somehow, it should only be creating these when the app has given it permission on a per-request basis&#8230; there are a variety of of nginx third party modules  that look like maybe could be useful to put this together, some more maintained/documented than others&#8230; and it just gets really confusing. </p>



<p>PLUS if you want to depoy to heroku (which we are considering), this nginx still couldn&#8217;t be running on heroku, cause of that 30s limit, it would have to be running on your own non-heroku host somewhere. </p>



<p>I think if I were a larger commercial company with a product involving lots and lots of user-submitted images that I needed to access control and wanted to store on S3&#8230;. I might do some more investigation down this path. But for my use case&#8230; I think this is just too complicated for us to maintain, if it can be made to work at all. </p>



<h2>All Protected ACL, put presigned URLs in HTML source</h2>



<p>Protect all your S3 assets with non-public ACLs, so they can only be accessed after your app decides the requester has privileges to see it, via a presigned URL. But instead of using a redirect or proxy, just generate presigend URLs and use them directly in &lt;img src&gt; for thumbs or or &lt;a href&gt;  for downloads etc. </p>



<h3>Pro</h3>



<ul><li>We can control access at the app level</li><li>No extra requests for redirects or proxies, we aren&#8217;t requiring our app to have a lot more resources to handle an additional request per image thumb loaded. </li><li>Simple. </li></ul>



<h3>Con</h3>



<ul><li>HTML source now includes limited-time-expiring URLs in &lt;img src&gt; etc, so can&#8217;t be cached indefinitely, even for public pages. (Although can be cached for up to a week, the maximum expiry of S3 presigned URLs, which might be good enough). </li><li>Presigned S3 URLs are <a href="https://bibwild.wordpress.com/2020/08/26/speeding-up-s3-url-generation-in-ruby/#presigned">really expensive to generate. </a>It&#8217;s actually infeasible to include hundreds of them on a page, can take almost 1ms per URL generated. This can be optimized somewhat with custom code, but still really expensive. <strong>This is the main blocker here I think</strong>, for what otherwise might be &#8220;simplest thing that will work&#8221;. </li></ul>



<h2>Different S3 ACLs for different resources</h2>



<p>OK, so the &#8220;public bucket&#8221; approach I am using now will work fine for <em>most</em> of my assets. It is a minority that actually need to be access controlled. </p>



<p>While &#8220;access them all with presigned URLs so the app is the one deciding if a given request gets access&#8221; has a certain software engineering consistency appeal  &#8212; the performance and convennience advantages of public_read S3 ACL are maybe too great to give up when 90%+ of my assets work fine with it. </p>



<p>Really, this whole long post is probably to convince myself that this needs to be done, because it seems like such a complicated mess&#8230; but it is, I think the lesser evil. </p>



<p>What makes this hard is that the management interface needs to let a manager <strong>CHANGE</strong> the public-readability status of an asset. And each of my assets might have 12 derivatives, so that&#8217;s 13 files to change, which can&#8217;t be done instantaneously if you wait for S3 to confirm, which probably means a background job.  And you open yourself up to making a mistake and having a resource in the wrong state. </p>



<p>It might make sense to have an architecture that minimizes the number of times state has to be changed. All of our assets start out in a non-published draft state, then are later published; but for most of our resources destined for publication, it&#8217;s okay if they have public_read ACL  in &#8216;draft&#8217; state. Maybe there&#8217;s another flag for whether to <em>really</em> protect/restrict access securely, that can be set on ingest/creation only for the minority of assets that need it? So only needs to be changed if am mistake were made, or decision changed?</p>



<p>Changing &#8220;access state&#8221; on S3 could be done by one of two methods. You could have everything in the same bucket, and actually <a href="https://docs.aws.amazon.com/cli/latest/reference/s3api/put-object-acl.html">change the S3 ACL</a>.  Or you could have two separate buckets, one for public files and one for securely protected files. Then, changing the &#8216;state&#8217; requires a move (<a href="https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html">copy</a> then delete) of the file from one bucket to another. While the copy approach seems more painful, it has a lot of advantages: you can easily see if an object has the &#8216;right&#8217; permissions by just seeing what bucket it is in (while using S3&#8217;s <a href="https://aws.amazon.com/blogs/aws/amazon-s3-block-public-access-another-layer-of-protection-for-your-accounts-and-buckets/">&#8220;block public access&#8221;</a> features on the non-public bucket), making it easier to audit manually or automatically; and you can slap a CDN on top of the &#8220;public&#8221; bucket just as simply as ever, rather than having mixed public/nonpublic content in the same bucket. </p>



<h3>Pro</h3>



<ul><li>The majority of our files that don&#8217;t need to be secured can still benefit from the convenience and performance advantages of public_read ACL. </li><li>Including can still use a straightforward CDN on top of bucket bucket, and HTTP cache-forever these files too. </li><li>Including no major additional load put on our app for serving the majority of assets that are public</li></ul>



<h3>Con</h3>



<ul><li>Additional complexity for app. It has to manage putting files in two different buckets with different ACLs, and generating URLs to the two classes differently. </li><li>Opportunity for bugs where an asset is in the &#8216;wrong&#8217; bucket/ACL. Probably need a regular automated audit of some kind &#8212; making sure you didn&#8217;t leave behind a file in &#8216;public&#8217; bucket that isn&#8217;t actually pointed to by the app is a pain to audit. </li><li>It is expensive to switch the access state of an asset. A book with 600 pages each with 12 derivatives, is over 7K files that need to have their ACLs changed and/or copied to another bucket if the visibility status changes. </li><li>If we try to minimize need to change ACL state,  by leaving files destined to be public with public_read even before publication and having separate state for &#8220;really secure on S3&#8221; &#8212; this is a more confusing mental model for staff asset managers, with more opportunity for human error. Should think carefully of how this is exposed in staff UI. </li><li>For protected things on S3, you still need to use one of the above methods of giving users access, if any users are to be given access after an auth check. </li></ul>



<p>I don&#8217;t love this solution, but this post is a bunch of words to basically convince myself that it is the lesser evil nonetheless. </p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2020/08/27/access-patterns-for-s3-hosted-resources-with-access-control/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Speeding up S3 URL generation in ruby</title>
		<link>https://bibwild.wordpress.com/2020/08/26/speeding-up-s3-url-generation-in-ruby/</link>
					<comments>https://bibwild.wordpress.com/2020/08/26/speeding-up-s3-url-generation-in-ruby/#comments</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 26 Aug 2020 15:54:34 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8445</guid>

					<description><![CDATA[It looks like the AWS SDK is very slow at generating S3 URLs, both public and presigned, and that you can generate around an order of magnitude faster in both cases. This can matter if you are generating hundreds of S3 URLs at once. My app The app I work is a &#8220;digital collections&#8221; or &#8230; <a href="https://bibwild.wordpress.com/2020/08/26/speeding-up-s3-url-generation-in-ruby/" class="more-link">Continue reading <span class="screen-reader-text">Speeding up S3 URL generation in&#160;ruby</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[
<p>It looks like the AWS SDK is very slow at generating S3 URLs, both public and <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/ShareObjectPreSignedURL.html">presigned</a>, and that you can generate around an order of magnitude faster in both cases. This can matter if you are generating hundreds of S3 URLs at once. </p>



<h2>My app</h2>



<p>The app I work is a &#8220;digital collections&#8221; or &#8220;digital asset management&#8221; app. It is about displaing lists of files, so it displays a LOT of thumbnails. The thumbnails are all stored in S3, and at present we generate URLs directly to S3 in <code>src</code>&#8216;s on page. </p>



<p>Some of our pages can have 600 thumbnails. (Say, a digitized medieval manuscript with 600 pages). Also, we use <a href="https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images">srcset</a> to offer the browser two resolutions for each images, so that&#8217;s 1200 URLs. </p>



<p>Is this excessive, should we not put 600 URLs on a page? Maybe, although it&#8217;s what our app does at present. But 100 thumbnails on a page does not seem excessive; imagine a 10&#215;10 grid of postage-stamp-sized thumbs, why not?  And they each could have multiple URLs in a srcset. </p>



<p>It turns out that S3 URL generation can be slow enough to be a bottleneck with 1200 generations in a page, or in some cases even 100. But it can be optimized. </p>



<h2>On Benchmarking</h2>



<p>It&#8217;s hard to do benchmarking in a reliable way. I just used <a href="https://ruby-doc.org/stdlib-2.5.0/libdoc/benchmark/rdoc/Benchmark.html#method-c-bmbm">Benchmark.bmbm</a> here; it is notable that on different runs of my comparisons, I could see results differ by 10-20%. But this should be sufficient for relative comparisons and basic orders of magnitude.  Exact numbers will of course differ on different hardware/platform anyway.  (<a href="https://github.com/evanphx/benchmark-ips">benchmark-ips</a> might possibly be a way to get somewhat more reliable results, but I didn&#8217;t remember it until I was well into this. There may be other options?). </p>



<p>I ran benchmarks on my 2015 Macbook 2.9 GHz Dual-Core Intel Core i5. </p>



<p>I&#8217;m used to my MacBook being <em>faster</em> than our deployed app on an EC2 instance, but in this case running benchmarks on EC2 had very similar results. (Of course, EC2 instance CPU performance can be quite variable). </p>



<h2>Public S3 URLs</h2>



<p>A public S3 URL might look like <code>https://bucket_name.s3.amazonaws.com/path/to/my/object.rb</code> . Or it might have a custom domain name, possibly to a CDN. Pretty simple, right?</p>



<p>Using shrine, you might generate it like <code>model.image_url(public_true)</code>. Which calls <a href="https://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/S3/Object.html#public_url-instance_method">Aws::S3::Object#public_url</a> . Other dependencies or your own code might call the AWS SDK method as well. </p>



<p>I had noticed in earlier profiling that generating S3 URLs seemed to be taking much longer than I expected, looking like a bottleneck for my app.  We use <a href="https://shrinerb.com/">shrine</a>, but shrine <a href="https://github.com/shrinerb/shrine/blob/c039a250845c4df7cac7d9e6f5ca81f985c744eb/lib/shrine/storage/s3.rb#L134">doesn&#8217;t add much overhead here</a>, it&#8217;s pretty much just calling out to the AWS SDK <code>public_url</code> or <code>presigned_url</code> methods. </p>



<p>It seems like generating these URLs should be very simple, right? Here&#8217;s a &#8220;naive&#8221; implementation based on a shrine <a href="https://shrinerb.com/docs/getting-started#uploaded-file">UploadedFile</a> argument. Obviously it would be easy to use a custom or CDN hostname in this implementation alternately. </p>



<style>.gist table { margin-bottom: 0; }</style><div style="tab-size: 8" id="gist105045195" class="gist">
    <div class="gist-file" translate="no">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-naive_s3-rb" class="file my-2">
    
    <div itemprop="text" class="Box-body p-0 blob-wrapper data type-ruby  ">

        
<div class="js-check-bidi js-blob-code-container blob-code-content">

  <template class="js-file-alert-template">
  <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
  
    <span>
      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
    </span>


  <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">    Show hidden characters
</a>
</div>
</div></template>
<template class="js-line-alert-template">
  <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="line-alert tooltipped tooltipped-e">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
</span></template>

  <table data-hpc class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip data-tagsearch-lang="Ruby" data-tagsearch-path="naive_s3.rb">
        <tr>
          <td id="file-naive_s3-rb-L1" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="1"></td>
          <td id="file-naive_s3-rb-LC1" class="blob-code blob-code-inner js-file-line"><span class=pl-k>def</span> <span class=pl-en>naive_public_url</span><span class=pl-kos>(</span><span class=pl-s1>shrine_file</span><span class=pl-kos>)</span></td>
        </tr>
        <tr>
          <td id="file-naive_s3-rb-L2" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="2"></td>
          <td id="file-naive_s3-rb-LC2" class="blob-code blob-code-inner js-file-line">  <span class=pl-s>&quot;https://<span class=pl-s1><span class=pl-kos>#{</span><span class=pl-kos>[</span><span class=pl-s>&quot;<span class=pl-s1><span class=pl-kos>#{</span><span class=pl-s1>shrine_file</span><span class=pl-kos>.</span><span class=pl-en>storage</span><span class=pl-kos>.</span><span class=pl-en>bucket</span><span class=pl-kos>.</span><span class=pl-en>name</span><span class=pl-kos>}</span></span>.s3.amazonaws.com&quot;</span><span class=pl-kos>,</span> *<span class=pl-s1>shrine_file</span><span class=pl-kos>.</span><span class=pl-en>storage</span><span class=pl-kos>.</span><span class=pl-en>prefix</span><span class=pl-kos>,</span> <span class=pl-s1>shrine_file</span><span class=pl-kos>.</span><span class=pl-en>id</span><span class=pl-kos>]</span><span class=pl-kos>.</span><span class=pl-en>join</span><span class=pl-kos>(</span><span class=pl-s>&#39;/&#39;</span><span class=pl-kos>)</span><span class=pl-kos>}</span></span>&quot;</span></td>
        </tr>
        <tr>
          <td id="file-naive_s3-rb-L3" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="3"></td>
          <td id="file-naive_s3-rb-LC3" class="blob-code blob-code-inner js-file-line"><span class=pl-k>end</span></td>
        </tr>
        <tr>
          <td id="file-naive_s3-rb-L4" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="4"></td>
          <td id="file-naive_s3-rb-LC4" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-naive_s3-rb-L5" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="5"></td>
          <td id="file-naive_s3-rb-LC5" class="blob-code blob-code-inner js-file-line"><span class=pl-en>naive_public_url</span><span class=pl-kos>(</span><span class=pl-en>model</span><span class=pl-kos>.</span><span class=pl-en>image</span><span class=pl-kos>)</span></td>
        </tr>
        <tr>
          <td id="file-naive_s3-rb-L6" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="6"></td>
          <td id="file-naive_s3-rb-LC6" class="blob-code blob-code-inner js-file-line"><span class=pl-c>#=&gt; &quot;<a href="https://somebucket.s3.amazonaws.com/path/to/image.jpg&#038;quot" rel="nofollow">https://somebucket.s3.amazonaws.com/path/to/image.jpg&#038;quot</a>;</span></td>
        </tr>
  </table>
</div>


    </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/jrochkind/8b2a0cf539c3ebc916102b961d1aef22/raw/1071ddb6bf129431120f4032097ec267867e45d6/naive_s3.rb" style="float:right">view raw</a>
        <a href="https://gist.github.com/jrochkind/8b2a0cf539c3ebc916102b961d1aef22#file-naive_s3-rb">
          naive_s3.rb
        </a>
        hosted with &#10084; by <a href="https://github.com">GitHub</a>
      </div>
    </div>
</div>




<p>Benchmark generating 1200 URLs with naive implementation  vs a straight call of S3 AWS SDK <code>public_ur</code>l&#8230;</p>



<style>.gist table { margin-bottom: 0; }</style><div style="tab-size: 8" id="gist105045239" class="gist">
    <div class="gist-file" translate="no">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-gistfile1-txt" class="file my-2">
    
    <div itemprop="text" class="Box-body p-0 blob-wrapper data type-text  ">

        
<div class="js-check-bidi js-blob-code-container blob-code-content">

  <template class="js-file-alert-template">
  <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
  
    <span>
      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
    </span>


  <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">    Show hidden characters
</a>
</div>
</div></template>
<template class="js-line-alert-template">
  <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="line-alert tooltipped tooltipped-e">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
</span></template>

  <table data-hpc class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip data-tagsearch-lang="Text" data-tagsearch-path="gistfile1.txt">
        <tr>
          <td id="file-gistfile1-txt-L1" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="1"></td>
          <td id="file-gistfile1-txt-LC1" class="blob-code blob-code-inner js-file-line">original AWS SDK public_url implementation   0.053043   0.000275   0.053318 (  0.053782)</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L2" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="2"></td>
          <td id="file-gistfile1-txt-LC2" class="blob-code blob-code-inner js-file-line">naive implementation                         0.004730   0.000016   0.004746 (  0.004760)</td>
        </tr>
  </table>
</div>


    </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/jrochkind/f1510c7777de1c57e05950fc9ffd1aaa/raw/bfe8e840d17d207368cdc080464640fd9fc530fa/gistfile1.txt" style="float:right">view raw</a>
        <a href="https://gist.github.com/jrochkind/f1510c7777de1c57e05950fc9ffd1aaa#file-gistfile1-txt">
          gistfile1.txt
        </a>
        hosted with &#10084; by <a href="https://github.com">GitHub</a>
      </div>
    </div>
</div>




<p><strong>53ms vs  5ms, it&#8217;s an order of magnitude slower indeed. </strong></p>



<p>53ms is not peanuts when you are trying to keep a web response under 200ms, although it may not be terrible. But let&#8217;s see if we can figure out why it&#8217;s so slow anyway. </p>



<p>Examining with <a href="https://ruby-prof.github.io/">ruby-prof</a> points to what we could see in the <a href="https://github.com/aws/aws-sdk-ruby/blob/4ad4b8f672bdb993a3edf36b6e1a78ebe95a115f/gems/aws-sdk-s3/lib/aws-sdk-s3/customizations/object.rb#L215-L220">basic implementation in AWS SDK source code</a>, no need to dig down the stack. The most expensive elements are the <code>URI.parse</code> and the URI-safe escaping.  Are we missing anything from our naive implementation then?</p>



<p>Well, the URI.parse is just done to make sure we are operating only on the <code>path</code> portion of the URL. But I can&#8217;t figure out any way <a href="https://github.com/aws/aws-sdk-ruby/blob/4ad4b8f672bdb993a3edf36b6e1a78ebe95a115f/gems/aws-sdk-s3/lib/aws-sdk-s3/customizations/bucket.rb#L71-L109">bucket.url</a> would return anything but a hostname-only URL with an empty path anyway, all the examples in docs are such. Maybe it could somehow include a path, but I can&#8217;t figure out any way the URL being parsed would have a <code>?</code> query component or <code>#</code> fragment, and without that it&#8217;s safe to just append things without a parse. (Even without that assumption, there will be faster ways than a parse, which is quite slow!)  Also just calling <code>bucket.url</code> is a bit expensive, and can deal with some live <code>arn:</code> lookups we won&#8217;t be using. </p>



<h3>URI Escaping, the pit of confusing alternatives</h3>



<p>What about escaping? Escaping can be such a confusing topic with S3, with different libraries at different times handling it different/wrong, then it would be sane to just never use any characters in an S3 key that need any escaping, maybe put some validation on your setters to ensure this. And then you don&#8217;t need to take the performance hit of escaping. </p>



<p>But okay, maybe we really need/want escaping to ensure any valid S3 key is turned into a valid S3 URL. Can we do escaping more efficiently?</p>



<p>The original implementation splits the path on <code>/</code> and then runs each component through the SDK&#8217;s own <code>Seahorse::Util.uri_escape(s)</code>. That <a href="https://github.com/aws/aws-sdk-ruby/blob/master/gems/aws-sdk-core/lib/seahorse/util.rb#L11">method&#8217;s implementation</a> uses <code>CGI.escape</code>, but then does <em>two</em> <code>gsub</code>&#8216;s to alter the value somewhat, not being happy with CGI.escape. Those extra gsubs are more performance hit.  I think we can use <code>ERB::Util.url_encode</code> instead of <code>CGI.escape + gsubs </code>to get the same behavior, which might get us some speed-up.  </p>



<p>But we also seem to be escaping more than is necessary. For instance it will escape any <code>!</code> in a key to <code>%21</code>, and it turns out this isn&#8217;t at all necessary, the URL resolve quite fine without escaping this.  If we escape only what is needed, can we go even faster?</p>



<p>I think what we actually need is what <code>URI.escape</code> does &#8212; and since <code>URI.escape</code> doesn&#8217;t escape <code>/</code>, we don&#8217;t need to split on <code>/</code> first, saving us even more time. Annoyingly, URI.escape is marked obsolete/deprecated! But it&#8217;s <a href="https://github.com/ruby/ruby/blob/1eb1add68abe9a4e860fe4dc64b3b105d854a935/lib/bundler/vendor/uri/lib/uri/rfc2396_parser.rb#L300-L313">stdlib implementation is relatively simple pure ruby</a>, it would be easy enough to copy it into our codebase.</p>



<p>Even faster?  The somewhat maintenance-neglected but still working at present <a href="https://github.com/brianmario/escape_utils">escape_utils</a> gem has a C implementation of some escaping routines. It&#8217;s hard when many implementations aren&#8217;t clear on exactly what they are escaping, but I think the <code>escape_uri</code> (note <code>i</code> on the end not <code>l</code>) is doing the same thing as URI.escape. Alas, there seems to be no <code>escape_utils</code> implementation that corresponds to CGI.escape or ERB::Util.url_encode. </p>



<p>So now we have a bunch of possibilities, depending on if we are willing to change escaping semantics and/or use our naive implementation of hostname-supplying. </p>



<figure class="wp-block-table"><table class="has-fixed-layout"><tbody><tr><td>Original AWS SDK public_url</td><td></td><td>100%</td></tr><tr><td><a href="https://gist.github.com/jrochkind/764fb0985b7af3c8d9252e33d47d713e#file-s3_public_url_benchmark-rb-L45-L52">optimized AWS SDK public_url</a></td><td>Avoid the URI.parse, use ERB::Util.url_encode. Should be functionally identical, same output, I think!</td><td>60%</td></tr><tr><td><a href="https://gist.github.com/jrochkind/764fb0985b7af3c8d9252e33d47d713e#file-s3_public_url_benchmark-rb-L10-L12">naive implementation</a></td><td>No escaping of S3 key for URL at all</td><td>7.5%</td></tr><tr><td><a href="https://gist.github.com/jrochkind/764fb0985b7af3c8d9252e33d47d713e#file-s3_public_url_benchmark-rb-L14-L18">naive + ERB::Util.url_encode</a></td><td>should be functionally identical escaping to original implementation, ie over-escaping</td><td>28%</td></tr><tr><td><a href="https://gist.github.com/jrochkind/764fb0985b7af3c8d9252e33d47d713e#file-s3_public_url_benchmark-rb-L37-L43">naive + URI.escape</a></td><td>we think is sufficient escaping, can be done much faster</td><td>15%</td></tr><tr><td><a href="https://gist.github.com/jrochkind/764fb0985b7af3c8d9252e33d47d713e#file-s3_public_url_benchmark-rb-L27-L33">naive + EscapeUtils.escape_uri</a></td><td>we think is identical to URI.escape but faster C implementation</td><td>11%</td></tr></tbody></table></figure>



<p>We have a bunch of opportunities for much faster implementations, even with existing over-escaping implementation.  <a href="https://gist.github.com/jrochkind/764fb0985b7af3c8d9252e33d47d713e">Here&#8217;s the file I used to benchmark. </a></p>



<h2 id="presigned">Presigned S3 URLs</h2>



<p>A Presigned URL is used to give access to non-public content, and/or to specify response headeres you&#8217;d like S3 to include with response, such as <code>Content-Disposition</code>. Presigned S3 URLs all have an expiration (max one week), and involve a cryptographic signature. </p>



<p>I expect most people <em>are</em> using the AWS SDK for these, rather than reinvent an implementation of the cryptographic signing protocol. </p>



<p>And we&#8217;d certainly expect these to be slower than public URLs, because of the crypto signature involved. But can they do be optimized? It looks like yes, at least about an order of magnitude again. </p>



<p>Benchmarking with AWS SDK <a href="https://github.com/aws/aws-sdk-ruby/blob/4ad4b8f672bdb993a3edf36b6e1a78ebe95a115f/gems/aws-sdk-s3/lib/aws-sdk-s3/customizations/object.rb#L191-L197">presigned_url</a>,  <strong>1200 URL generations</strong> can take around <strong>760-900ms</strong>. Wow, that&#8217;s a lot &#8212; this is <em>definitely</em> enough to matter, especially in a web app response you&#8217;d like to keep under 200ms, and this is likely to be a bottleneck. </p>



<p>We do expect the signing to take longer than a public url, but can we do better?</p>



<h3>Look at what the SDK is doing, re-implement a quicker path</h3>



<p>The presigned_url method <a href="https://github.com/aws/aws-sdk-ruby/blob/d70d6c2316779e21c46165801000894f236e021f/gems/aws-sdk-s3/lib/aws-sdk-s3/customizations/object.rb#L191-L197">just instantiates and calls out to an Aws::S3::Presigner</a>. First idea, what if we create a single Aws::S3::Presigner, and re-use it 1200 times, instead of instantiating it 1200 times, passing it the same args <code>#presigned_url</code> would?   Tried that, it was only minor performance improvement. </p>



<p>OK, let&#8217;s look at the <a href="https://github.com/aws/aws-sdk-ruby/blob/d70d6c2316779e21c46165801000894f236e021f/gems/aws-sdk-s3/lib/aws-sdk-s3/presigner.rb">Aws:S3::Presigner implementation</a>. It&#8217;s got kind of a convoluted way of getting a URL, <a href="https://github.com/aws/aws-sdk-ruby/blob/d70d6c2316779e21c46165801000894f236e021f/gems/aws-sdk-s3/lib/aws-sdk-s3/presigner.rb#L139">building a Seahorse::Client::Request</a>, and then <a href="https://github.com/aws/aws-sdk-ruby/blob/d70d6c2316779e21c46165801000894f236e021f/gems/aws-sdk-s3/lib/aws-sdk-s3/presigner.rb#L187">doing something weird</a> with it&#8230;. maybe modifying it to not actually go to the network, but just act as if it had&#8230; returning headers and a signed URL, and then we throw out the headers and just use the signed URL&#8230;. phew!  Ultimately though it does the actual signing work <a href="https://github.com/aws/aws-sdk-ruby/blob/d70d6c2316779e21c46165801000894f236e021f/gems/aws-sdk-s3/lib/aws-sdk-s3/presigner.rb#L242-L250">with another object, an Aws::Sigv4:Signer</a>.</p>



<p>What if we just instantiate one of these ourselves, instantiate it the same arguments the Presigner would have for our use cases, and then call presign_url on it with <a href="https://github.com/aws/aws-sdk-ruby/blob/d70d6c2316779e21c46165801000894f236e021f/gems/aws-sdk-s3/lib/aws-sdk-s3/presigner.rb#L224-L231">the same args the Presigner would have</a>.  Let&#8217;s re-use a Signer object 1200 times instead of instantiating it each time, in case that matters. </p>



<p>We still need to create the public_url in order to sign it. Let&#8217;s use our replacement naive implementation with <code>URI.escape</code> escaping.</p>



<style>.gist table { margin-bottom: 0; }</style><div style="tab-size: 8" id="gist105045263" class="gist">
    <div class="gist-file" translate="no">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-optimized_presigned_s3-rb" class="file my-2">
    
    <div itemprop="text" class="Box-body p-0 blob-wrapper data type-ruby  ">

        
<div class="js-check-bidi js-blob-code-container blob-code-content">

  <template class="js-file-alert-template">
  <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
  
    <span>
      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
    </span>


  <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">    Show hidden characters
</a>
</div>
</div></template>
<template class="js-line-alert-template">
  <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="line-alert tooltipped tooltipped-e">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
</span></template>

  <table data-hpc class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip data-tagsearch-lang="Ruby" data-tagsearch-path="optimized_presigned_s3.rb">
        <tr>
          <td id="file-optimized_presigned_s3-rb-L1" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="1"></td>
          <td id="file-optimized_presigned_s3-rb-LC1" class="blob-code blob-code-inner js-file-line"><span class=pl-c1>AWS_SIG4_SIGNER</span> <span class=pl-c1>=</span> <span class=pl-v>Aws</span>::<span class=pl-v>Sigv4</span>::<span class=pl-v>Signer</span><span class=pl-kos>.</span><span class=pl-en>new</span><span class=pl-kos>(</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L2" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="2"></td>
          <td id="file-optimized_presigned_s3-rb-LC2" class="blob-code blob-code-inner js-file-line">  <span class=pl-pds>service</span>: <span class=pl-s>&#39;s3&#39;</span><span class=pl-kos>,</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L3" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="3"></td>
          <td id="file-optimized_presigned_s3-rb-LC3" class="blob-code blob-code-inner js-file-line">  <span class=pl-pds>region</span>: <span class=pl-c1>AWS_CLIENT</span><span class=pl-kos>.</span><span class=pl-en>config</span><span class=pl-kos>.</span><span class=pl-en>region</span><span class=pl-kos>,</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L4" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="4"></td>
          <td id="file-optimized_presigned_s3-rb-LC4" class="blob-code blob-code-inner js-file-line">  <span class=pl-pds>credentials_provider</span>: <span class=pl-c1>SOME_AWS_CLIENT</span><span class=pl-kos>.</span><span class=pl-en>config</span><span class=pl-kos>.</span><span class=pl-en>credentials</span><span class=pl-kos>,</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L5" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="5"></td>
          <td id="file-optimized_presigned_s3-rb-LC5" class="blob-code blob-code-inner js-file-line">  <span class=pl-pds>unsigned_headers</span>: <span class=pl-v>Aws</span>::<span class=pl-c1>S3</span>::<span class=pl-v>Presigner</span>::<span class=pl-c1>BLACKLISTED_HEADERS</span><span class=pl-kos>,</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L6" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="6"></td>
          <td id="file-optimized_presigned_s3-rb-LC6" class="blob-code blob-code-inner js-file-line">  <span class=pl-pds>uri_escape_path</span>: <span class=pl-c1>false</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L7" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="7"></td>
          <td id="file-optimized_presigned_s3-rb-LC7" class="blob-code blob-code-inner js-file-line"><span class=pl-kos>)</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L8" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="8"></td>
          <td id="file-optimized_presigned_s3-rb-LC8" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L9" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="9"></td>
          <td id="file-optimized_presigned_s3-rb-LC9" class="blob-code blob-code-inner js-file-line"><span class=pl-k>def</span> <span class=pl-en>naive_with_uri_escape_escaping</span><span class=pl-kos>(</span><span class=pl-s1>shrine_file</span><span class=pl-kos>)</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L10" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="10"></td>
          <td id="file-optimized_presigned_s3-rb-LC10" class="blob-code blob-code-inner js-file-line">  <span class=pl-c># because URI.escape does NOT escape `/`, we don&#39;t need to split it, </span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L11" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="11"></td>
          <td id="file-optimized_presigned_s3-rb-LC11" class="blob-code blob-code-inner js-file-line">  <span class=pl-c># which is what actually saves us the time.</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L12" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="12"></td>
          <td id="file-optimized_presigned_s3-rb-LC12" class="blob-code blob-code-inner js-file-line">  <span class=pl-s1>path</span> <span class=pl-c1>=</span> <span class=pl-c1>URI</span><span class=pl-kos>.</span><span class=pl-en>escape</span><span class=pl-kos>(</span><span class=pl-s1>shrine_file</span><span class=pl-kos>.</span><span class=pl-en>id</span><span class=pl-kos>)</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L13" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="13"></td>
          <td id="file-optimized_presigned_s3-rb-LC13" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L14" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="14"></td>
          <td id="file-optimized_presigned_s3-rb-LC14" class="blob-code blob-code-inner js-file-line">  <span class=pl-s>&quot;https://<span class=pl-s1><span class=pl-kos>#{</span><span class=pl-kos>[</span><span class=pl-s>&quot;<span class=pl-s1><span class=pl-kos>#{</span><span class=pl-s1>shrine_file</span><span class=pl-kos>.</span><span class=pl-en>storage</span><span class=pl-kos>.</span><span class=pl-en>bucket</span><span class=pl-kos>.</span><span class=pl-en>name</span><span class=pl-kos>}</span></span>.s3.amazonaws.com&quot;</span><span class=pl-kos>,</span> *<span class=pl-s1>shrine_file</span><span class=pl-kos>.</span><span class=pl-en>storage</span><span class=pl-kos>.</span><span class=pl-en>prefix</span><span class=pl-kos>,</span> <span class=pl-s1>shrine_file</span><span class=pl-kos>.</span><span class=pl-en>id</span><span class=pl-kos>]</span><span class=pl-kos>.</span><span class=pl-en>join</span><span class=pl-kos>(</span><span class=pl-s>&#39;/&#39;</span><span class=pl-kos>)</span><span class=pl-kos>}</span></span>&quot;</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L15" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="15"></td>
          <td id="file-optimized_presigned_s3-rb-LC15" class="blob-code blob-code-inner js-file-line"><span class=pl-k>end</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L16" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="16"></td>
          <td id="file-optimized_presigned_s3-rb-LC16" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L17" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="17"></td>
          <td id="file-optimized_presigned_s3-rb-LC17" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L18" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="18"></td>
          <td id="file-optimized_presigned_s3-rb-LC18" class="blob-code blob-code-inner js-file-line"><span class=pl-c># not yet handling custom query params eg for content-disposition</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L19" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="19"></td>
          <td id="file-optimized_presigned_s3-rb-LC19" class="blob-code blob-code-inner js-file-line"><span class=pl-k>def</span> <span class=pl-en>direct_aws_sig4_signer</span><span class=pl-kos>(</span><span class=pl-s1>url</span><span class=pl-kos>)</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L20" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="20"></td>
          <td id="file-optimized_presigned_s3-rb-LC20" class="blob-code blob-code-inner js-file-line">  <span class=pl-c1>AWS_SIG4_SIGNER</span><span class=pl-kos>.</span><span class=pl-en>presign_url</span><span class=pl-kos>(</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L21" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="21"></td>
          <td id="file-optimized_presigned_s3-rb-LC21" class="blob-code blob-code-inner js-file-line">            <span class=pl-pds>http_method</span>: <span class=pl-s>&quot;GET&quot;</span><span class=pl-kos>,</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L22" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="22"></td>
          <td id="file-optimized_presigned_s3-rb-LC22" class="blob-code blob-code-inner js-file-line">            <span class=pl-pds>url</span>: <span class=pl-s1>url</span><span class=pl-kos>,</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L23" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="23"></td>
          <td id="file-optimized_presigned_s3-rb-LC23" class="blob-code blob-code-inner js-file-line">            <span class=pl-pds>headers</span>: <span class=pl-kos>{</span><span class=pl-kos>}</span><span class=pl-kos>,</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L24" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="24"></td>
          <td id="file-optimized_presigned_s3-rb-LC24" class="blob-code blob-code-inner js-file-line">            <span class=pl-pds>body_digest</span>: <span class=pl-s>&#39;UNSIGNED-PAYLOAD&#39;</span><span class=pl-kos>,</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L25" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="25"></td>
          <td id="file-optimized_presigned_s3-rb-LC25" class="blob-code blob-code-inner js-file-line">            <span class=pl-pds>expires_in</span>: <span class=pl-c1>900</span><span class=pl-kos>,</span> <span class=pl-c># seconds</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L26" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="26"></td>
          <td id="file-optimized_presigned_s3-rb-LC26" class="blob-code blob-code-inner js-file-line">            <span class=pl-pds>time</span>: <span class=pl-c1>nil</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L27" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="27"></td>
          <td id="file-optimized_presigned_s3-rb-LC27" class="blob-code blob-code-inner js-file-line">  <span class=pl-kos>)</span><span class=pl-kos>.</span><span class=pl-en>to_s</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L28" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="28"></td>
          <td id="file-optimized_presigned_s3-rb-LC28" class="blob-code blob-code-inner js-file-line"><span class=pl-k>end</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L29" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="29"></td>
          <td id="file-optimized_presigned_s3-rb-LC29" class="blob-code blob-code-inner js-file-line">
</td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L30" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="30"></td>
          <td id="file-optimized_presigned_s3-rb-LC30" class="blob-code blob-code-inner js-file-line"><span class=pl-en>direct_aws_sig4_signer</span><span class=pl-kos>(</span> <span class=pl-en>naive_with_uri_escape_escaping</span><span class=pl-kos>(</span> <span class=pl-en>shrine_uploaded_file</span> <span class=pl-kos>)</span> <span class=pl-kos>)</span></td>
        </tr>
        <tr>
          <td id="file-optimized_presigned_s3-rb-L31" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="31"></td>
          <td id="file-optimized_presigned_s3-rb-LC31" class="blob-code blob-code-inner js-file-line"><span class=pl-c># =&gt; presigned S3 url</span></td>
        </tr>
  </table>
</div>


    </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/jrochkind/72865bdefd72048bb09bc9ae048613d9/raw/a60ba920eb10a7be671e8889d8650685727a1148/optimized_presigned_s3.rb" style="float:right">view raw</a>
        <a href="https://gist.github.com/jrochkind/72865bdefd72048bb09bc9ae048613d9#file-optimized_presigned_s3-rb">
          optimized_presigned_s3.rb
        </a>
        hosted with &#10084; by <a href="https://github.com">GitHub</a>
      </div>
    </div>
</div>




<h3>Yes, it&#8217;s much faster!</h3>



<p>Bingo!  Now I measure <strong>1200 URLs in 170-220ms</strong>, around 25% of the time. Still too slow to want to do 1200 of them on a single page, and around 4x slower than SDK public_url. </p>



<p>Interestingly, while we expect the cryptographic signature to take some extra time&#8230; that seems to be at most 10% of the overhead that the logic to sign a URL was adding?  We experimented with re-using an Aws::Sigv4::Signer vs instantiating one each time; and applying URI-escaping or not. These did make noticeable differences, but not astounding ones. </p>



<p>This optimized version would have to be enhanced to be able to handle additional query param options such as specified <code>content-disposition</code>, I optimistically hope that can be done without changing the performance characteristics  much. </p>



<p>Could it be optimized even more, by profiling within the Aws::Sigv4::Signer implementation? Maybe, but it doesn&#8217;t really seem worth it &#8212; we are already introducing some fragility into our code by using lower-level APIs and hoping they will remain valid even if AWS changes some things in the future. I don&#8217;t really want to re-implement Aws::Sigv4::Signer, just glad to have it available as a tool I can use like this already. </p>



<h3>The Numbers</h3>



<p>The script I used to compare performance in different ways of creating presigned S3 URLs (with a couple public URLs for comparison) is <a href="https://gist.github.com/jrochkind/b3789d5ee7414c2fc64d45b25e9ffb65">available in a gist</a>, and here is the output of one run:</p>



<style>.gist table { margin-bottom: 0; }</style><div style="tab-size: 8" id="gist105045110" class="gist">
    <div class="gist-file" translate="no">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-gistfile1-txt" class="file my-2">
    
    <div itemprop="text" class="Box-body p-0 blob-wrapper data type-text  ">

        
<div class="js-check-bidi js-blob-code-container blob-code-content">

  <template class="js-file-alert-template">
  <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
  
    <span>
      This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
      <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
    </span>


  <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">    Show hidden characters
</a>
</div>
</div></template>
<template class="js-line-alert-template">
  <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="line-alert tooltipped tooltipped-e">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
</svg>
</span></template>

  <table data-hpc class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip data-tagsearch-lang="Text" data-tagsearch-path="gistfile1.txt">
        <tr>
          <td id="file-gistfile1-txt-L1" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="1"></td>
          <td id="file-gistfile1-txt-LC1" class="blob-code blob-code-inner js-file-line">                                                                                            user     system      total        real</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L2" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="2"></td>
          <td id="file-gistfile1-txt-LC2" class="blob-code blob-code-inner js-file-line">sdk public_url                                                                          0.054114   0.000335   0.054449 (  0.054802)</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L3" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="3"></td>
          <td id="file-gistfile1-txt-LC3" class="blob-code blob-code-inner js-file-line">naive S3 public url                                                                     0.004575   0.000009   0.004584 (  0.004582)</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L4" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="4"></td>
          <td id="file-gistfile1-txt-LC4" class="blob-code blob-code-inner js-file-line">naive S3 public url with URI.escape                                                     0.009892   0.000090   0.009982 (  0.011209)</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L5" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="5"></td>
          <td id="file-gistfile1-txt-LC5" class="blob-code blob-code-inner js-file-line">sdk presigned_url                                                                       0.756642   0.005855   0.762497 (  0.789622)</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L6" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="6"></td>
          <td id="file-gistfile1-txt-LC6" class="blob-code blob-code-inner js-file-line">re-use instantiated SDK Presigner                                                       0.817595   0.005955   0.823550 (  0.859270)</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L7" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="7"></td>
          <td id="file-gistfile1-txt-LC7" class="blob-code blob-code-inner js-file-line">use inline instantiated Aws::Sigv4::Signer directly for presigned url (with escaping)   0.216338   0.001941   0.218279 (  0.226991)</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L8" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="8"></td>
          <td id="file-gistfile1-txt-LC8" class="blob-code blob-code-inner js-file-line">Re-use Aws::Sigv4::Signer for presigned url (with escaping)                             0.185855   0.001124   0.186979 (  0.188798)</td>
        </tr>
        <tr>
          <td id="file-gistfile1-txt-L9" class="blob-num js-line-number js-code-nav-line-number js-blob-rnum" data-line-number="9"></td>
          <td id="file-gistfile1-txt-LC9" class="blob-code blob-code-inner js-file-line">Re-use Aws::Sigv4::Signer for presigned url (without escaping)                          0.178457   0.001049   0.179506 (  0.180920)</td>
        </tr>
  </table>
</div>


    </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/jrochkind/85f8dacbe6a9dd7188351d29017c9673/raw/fb3a8c54b641073fe984bc77d54f40d434a8579c/gistfile1.txt" style="float:right">view raw</a>
        <a href="https://gist.github.com/jrochkind/85f8dacbe6a9dd7188351d29017c9673#file-gistfile1-txt">
          gistfile1.txt
        </a>
        hosted with &#10084; by <a href="https://github.com">GitHub</a>
      </div>
    </div>
</div>




<p></p>



<h2>So what to do?</h2>



<p>Possibly there are optimizations that would make sense in the AWS SDK gem itself? But it would actually take a lot more work to be sure what can be done without breaking some use cases. </p>



<p>I <em>think</em> there is no need to use URI.parse in public_url, the URIs can just be treated as strings and concatenated. But is there an edge case I&#8217;m missing? </p>



<p>Using different URI escaping method definitely helps in public_url; but how many other people who aren&#8217;t me care about optimizing public_url; and what escaping method is <em>actually</em> required/expected, is changing it a backwards compat problem; and is it okay maintenance-wise to make the S3 object use a different escaping mechanism than the common SDK Seahorse::Util.uri_escape workhorse, which might be used in places with different escaping requirements?</p>



<p>For presigned_urls, cutting out a lot of the wrapper code and using a <code>Aws::Sigv4::Signer</code> directly seems to have significant performance benefits, but what edge cases get broken there, and do they matter, and can a regression be avoided through alternate performant maintainable code?</p>



<p>Figuring this all out would take a lot more research (and figuring out how to use the test suite for the ruby SDK more facilely than I can write now; it&#8217;s a test suite for the <em>whole</em> SDK, and it&#8217;s a bear to run the whole thing). </p>



<p>Although if any Amazon maintainers of the ruby SDK, or other experts in it&#8217;s internals, see this and have an opinion, I am curious as to their thoughts. </p>



<p>But I am a lot more confident that some of these optimizations will work fine for <em>my</em> use cases. One of the benefits of using shrine is that all of my code already accesses S3 URL generation via shrine API. So I could easily swap in a locally optimized version, either with a shrine plugin, or just a local sub-class of the shrine S3 storage class. So I may consider doing that. </p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2020/08/26/speeding-up-s3-url-generation-in-ruby/feed/</wfw:commentRss>
			<slash:comments>10</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>A terrible Github UI — accidentally shadow a tag with a branch</title>
		<link>https://bibwild.wordpress.com/2019/04/30/a-terrible-github-ui-accidentally-shadow-a-tag-with-a-branch/</link>
					<comments>https://bibwild.wordpress.com/2019/04/30/a-terrible-github-ui-accidentally-shadow-a-tag-with-a-branch/#respond</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Tue, 30 Apr 2019 16:41:02 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8143</guid>

					<description><![CDATA[So we generally like to tag our releases in git, like v1.0.0 or what have you. Github Web UI has a &#8220;tag/branch switcher&#8221; widget, which lets you look at a particular branch or tag in the Web UI. You can see it has separate tabs for &#8220;branches&#8221; and &#8220;tags&#8221;. Let&#8217;s say you get confused, and type &#8230; <a href="https://bibwild.wordpress.com/2019/04/30/a-terrible-github-ui-accidentally-shadow-a-tag-with-a-branch/" class="more-link">Continue reading <span class="screen-reader-text">A terrible Github UI &#8212; accidentally shadow a tag with a&#160;branch</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[<p>So we generally like to tag our releases in git, like <code>v1.0.0</code> or what have you.</p>
<p>Github Web UI has a &#8220;tag/branch switcher&#8221; widget, which lets you look at a particular branch or tag in the Web UI.</p>
<p><img loading="lazy" data-attachment-id="8144" data-permalink="https://bibwild.wordpress.com/2019/04/30/a-terrible-github-ui-accidentally-shadow-a-tag-with-a-branch/screenshot-2019-04-30-12-27-17/" data-orig-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.27.17.png" data-orig-size="306,207" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2019-04-30 12.27.17" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.27.17.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.27.17.png?w=306" class="alignnone size-full wp-image-8144" src="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.27.17.png" alt="Screenshot 2019-04-30 12.27.17" width="306" height="207" srcset="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.27.17.png 306w, https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.27.17.png?w=150&amp;h=101 150w, https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.27.17.png?w=300&amp;h=203 300w" sizes="(max-width: 306px) 100vw, 306px" /></p>
<p>You can see it has separate tabs for &#8220;branches&#8221; and &#8220;tags&#8221;. Let&#8217;s say you get confused, and type &#8220;v1.0.0&#8221; (a tag) while the &#8220;branches&#8221; tab is selected (<em>under</em> the text box).</p>
<p><img loading="lazy" data-attachment-id="8145" data-permalink="https://bibwild.wordpress.com/2019/04/30/a-terrible-github-ui-accidentally-shadow-a-tag-with-a-branch/screenshot-2019-04-30-12-30-55/" data-orig-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.30.55.png" data-orig-size="309,177" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2019-04-30 12.30.55" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.30.55.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.30.55.png?w=309" class="alignnone size-full wp-image-8145" src="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.30.55.png" alt="Screenshot 2019-04-30 12.30.55" width="309" height="177" srcset="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.30.55.png 309w, https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.30.55.png?w=150&amp;h=86 150w, https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.30.55.png?w=300&amp;h=172 300w" sizes="(max-width: 309px) 100vw, 309px" /></p>
<p>It found no auto-complete for &#8220;v1.0.0&#8221; in &#8220;branches&#8221; (although there <em>is</em> a tag with that name it would have found if &#8220;tags&#8221; tab had been selected), and it &#8220;helpfully&#8221; offers to create a branch with that name.</p>
<p>Now, if you do that, you&#8217;re going to have a new branch, created off master, with the same name as a tag. Which is going to be <em>really confusing</em>. And not what you wanted.</p>
<p>Maybe your muscle memory makes your fingers hit &#8220;enter&#8221; and you wind up there &#8212; but at least it is very clearly identified, it says in fairly big and bold text &#8220;Create branch: v1.0.0 (from master)&#8221;, at least it warned you, although it&#8217;d be easy to miss in a hurry from muscle memory thinking you know what you&#8217;re doing.</p>
<p><strong>That&#8217;s not the really evil UI yet.</strong></p>
<p>Now let&#8217;s go to git&#8217;s &#8220;compare&#8221; UI. At <a href="https://github.com/someorg/someproject/compare" rel="nofollow">https://github.com/someorg/someproject/compare</a></p>
<p>A fairly common thing I at least want to do is look at the compare between two releases, or from last release to master. But the &#8216;compare&#8217; UI doesn&#8217;t have the tabs, it will <em>only</em> list or auto-complete from branches.</p>
<p><img loading="lazy" data-attachment-id="8146" data-permalink="https://bibwild.wordpress.com/2019/04/30/a-terrible-github-ui-accidentally-shadow-a-tag-with-a-branch/screenshot-2019-04-30-12-34-55/" data-orig-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.34.55.png" data-orig-size="472,367" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2019-04-30 12.34.55" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.34.55.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.34.55.png?w=472" class="alignnone size-full wp-image-8146" src="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.34.55.png" alt="Screenshot 2019-04-30 12.34.55" width="472" height="367" srcset="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.34.55.png 472w, https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.34.55.png?w=150&amp;h=117 150w, https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.34.55.png?w=300&amp;h=233 300w" sizes="(max-width: 472px) 100vw, 472px" /></p>
<p>In a hurry, going from muscle memory, you type in &#8220;v1.0.0&#8221; anyway.</p>
<p><img loading="lazy" data-attachment-id="8147" data-permalink="https://bibwild.wordpress.com/2019/04/30/a-terrible-github-ui-accidentally-shadow-a-tag-with-a-branch/screenshot-2019-04-30-12-35-37/" data-orig-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.35.37.png" data-orig-size="387,329" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2019-04-30 12.35.37" data-image-description="" data-image-caption="" data-medium-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.35.37.png?w=300" data-large-file="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.35.37.png?w=387" class="alignnone size-full wp-image-8147" src="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.35.37.png" alt="Screenshot 2019-04-30 12.35.37" width="387" height="329" srcset="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.35.37.png 387w, https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.35.37.png?w=150&amp;h=128 150w, https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.35.37.png?w=300&amp;h=255 300w" sizes="(max-width: 387px) 100vw, 387px" /></p>
<p>It does say &#8220;nothing to show&#8221;. But &#8220;v1.0.0&#8221; shows up in the list anyway. With a pretty obscure icon I&#8217;ve never seen before. Do you know what that icon means? It turns out, apparently, it means &#8220;Create branch: v1.0.0 (from master)&#8221;.</p>
<p>If confused, or in a hurry, or with your muscle memory outpacing your brain, you click on that line &#8212; that&#8217;s what happens.</p>
<p>Now you&#8217;ve got a branch called &#8220;v1.0.0&#8221;, created off current master, along with a tag &#8220;v1.0.0&#8221; pointing at a different SHA.  Because many UI&#8217;s treat branches and tags somewhat interchangeably, this is confusing. If you do a <code>git checkout v1.0.0</code>, are you going to get the branch or the tag?</p>
<p>It turns out if you go to a github <code>compare</code> UI, like `https://github.com/someorg/someproject/compare/v1.0.0..master`, Github is going to compare the <em>new branch</em> you accidentally made, not the existing tag (showing nothing in the diff, if master hasn&#8217;t changed yet). There is no <em>no way</em> to get Github to compare the tag. If you didn&#8217;t realize exactly what you did, you&#8217;re going to be awfully confused about what the heck is going on.</p>
<p>You&#8217;re going to need to figure it out, and delete the branch you just made, which it turns out you can do from the command line with the confusing and dangerous command: ` git push origin :refs/heads/v1.0.0`</p>
<p>And that&#8217;s how I lost a couple hours to figuring out &#8220;what the heck is going on here?&#8221;</p>
<p>What <em>should</em> you do if you want github &#8216;compare&#8217; web UI for a <em>tag</em> rather than a branch? Turns out, as far as I know, you just need to manually enter the the URL <code>https://github.com/org/project/compare/v1.0.0..v1.0.1</code> or what have you. The actual UI widgets will not get you there. They&#8217;ll just get you to a mess.</p>
<p>Am I missing something? That seems like github web UI is not only not providing for what I would think is a pretty common use (comparing tags), but leading you down a path to disaster when you look for it, no?</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2019/04/30/a-terrible-github-ui-accidentally-shadow-a-tag-with-a-branch/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>

		<media:content url="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.27.17.png" medium="image">
			<media:title type="html">Screenshot 2019-04-30 12.27.17</media:title>
		</media:content>

		<media:content url="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.30.55.png" medium="image">
			<media:title type="html">Screenshot 2019-04-30 12.30.55</media:title>
		</media:content>

		<media:content url="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.34.55.png" medium="image">
			<media:title type="html">Screenshot 2019-04-30 12.34.55</media:title>
		</media:content>

		<media:content url="https://bibwild.files.wordpress.com/2019/04/screenshot-2019-04-30-12.35.37.png" medium="image">
			<media:title type="html">Screenshot 2019-04-30 12.35.37</media:title>
		</media:content>
	</item>
		<item>
		<title>very rough benchmarking of Solr update batching performance characteristics</title>
		<link>https://bibwild.wordpress.com/2019/03/27/very-rough-benchmarking-of-solr-update-batching-performance-characteristics/</link>
					<comments>https://bibwild.wordpress.com/2019/03/27/very-rough-benchmarking-of-solr-update-batching-performance-characteristics/#comments</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Wed, 27 Mar 2019 18:07:55 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<category><![CDATA[samver]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8125</guid>

					<description><![CDATA[In figuring out how I want to integrate a synchronized Solr index into my Rails application, I am doing some very rough profiling/benchmarking of batching Solr adds vs not, just to get a general sense of it. (This is all _very rough estimates_ and may depend a lot on your environment and Solr setup, including &#8230; <a href="https://bibwild.wordpress.com/2019/03/27/very-rough-benchmarking-of-solr-update-batching-performance-characteristics/" class="more-link">Continue reading <span class="screen-reader-text">very rough benchmarking of Solr update batching performance&#160;characteristics</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[<p>In figuring out how I want to integrate a synchronized Solr index into my Rails application, I am doing some <em>very</em> rough profiling/benchmarking of batching Solr adds vs not, just to get a general sense of it.</p>
<p>(This is all _very rough estimates_ and may depend a lot on your environment and Solr setup, including how many records you have in Solr, if Solr is being simultaneously used for queries, etc).</p>
<p>One thing some Solr (or ElasticSearch) integration packages sometimes end up concentrating on is <em>batching</em> multiple index-change-needed events into fewer Solr update requests.</p>
<p>Based on my observations, I <em>think</em> it’s not actually the separate HTTP requests that are expensive. (although I’m benchmarking with a solr on localhost).</p>
<p>But the <em>commits</em> are &#8212; if you are doing them. In my benchmarks reindexing a whole bunch of things, if I’m not doing any commits, whether I batch into fewer HTTP update requests to Solr or not has no appreciable effect on speed.</p>
<p>But sending a softCommit per record/update makes it around 2.5x slower.</p>
<p>Sending a (hard) commit per record makes it around 4x slower.</p>
<p>Even without explicit commit directives, if you have your solr setup to autocommit (soft or hard), it may of course occasionally pause to do some commits, so your measured time may depend on if you hit one of those.</p>
<p>So if you don’t care about realtime/near-realtime, you may not have to care about batching. I had already gotten the sense from Solr&#8217;s documentation that Solr will really like it better if the client never sends commits, but just lets Solr&#8217;s <a href="https://lucene.apache.org/solr/guide/6_6/updatehandlers-in-solrconfig.html#UpdateHandlersinSolrConfig-autoCommit">autoCommit/autoSoftCommit/commitWithin</a> configuration to make sure updates become visible within a certain amount of maximum time. The reason to have the client send commits is generally because you need to guarantee that the updates will be visible to queries as soon as your code doing the update is finished.</p>
<p>The reason so many end up caring about batching updates <em>might</em> not because individual http requests to solr are a problem, but because too many _commits_ are. So if for some reason it was more convenient, only sending a commit per X records might be just as good as actually batching http requests &#8212; if you have to send commits from the client at all.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2019/03/27/very-rough-benchmarking-of-solr-update-batching-performance-characteristics/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
		<item>
		<title>Our progress on new digital collections app, and introducing kithe</title>
		<link>https://bibwild.wordpress.com/2019/03/01/our-progress-on-new-digital-collections-app-and-introducing-kithe/</link>
					<comments>https://bibwild.wordpress.com/2019/03/01/our-progress-on-new-digital-collections-app-and-introducing-kithe/#comments</comments>
		
		<dc:creator><![CDATA[jrochkind]]></dc:creator>
		<pubDate>Fri, 01 Mar 2019 15:33:13 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<category><![CDATA[ruby]]></category>
		<category><![CDATA[samvera]]></category>
		<guid isPermaLink="false">http://bibwild.wordpress.com/?p=8099</guid>

					<description><![CDATA[In September, I wrote a post on a &#8220;Proposed Rails-based digital collections developer’s toolkit&#8221; What has happened since then? Yes we decided to go ahead with a rewrite of our digital collections app, with the new app not based on Hyrax or Valkryie, but a persistence layer based on ActiveRecord (making use of postgres-specific features &#8230; <a href="https://bibwild.wordpress.com/2019/03/01/our-progress-on-new-digital-collections-app-and-introducing-kithe/" class="more-link">Continue reading <span class="screen-reader-text">Our progress on new digital collections app, and introducing&#160;kithe</span> <span class="meta-nav">&#8594;</span></a>]]></description>
										<content:encoded><![CDATA[<p>In September, I wrote a post on a <a href="https://bibwild.wordpress.com/2018/09/05/proposed-rails-based-digital-collections-developers-toolkit/">&#8220;Proposed Rails-based digital collections developer’s toolkit&#8221;</a></p>
<p>What has happened since then?</p>
<p><strong>Yes</strong> we decided to go ahead with a rewrite of our digital collections app, with the new app not based on <a href="https://github.com/samvera/hyrax">Hyrax</a> or <a href="https://github.com/samvera-labs/valkyrie">Valkryie</a>, but a persistence layer based on ActiveRecord (making use of postgres-specific features were appropriate), and exposing ActiveRecord models to the app as a whole.</p>
<p><strong>No,</strong> we are not going forward with trying to make that <em>entire</em> <em>&#8220;</em>toolkit&#8221;, with all the components mentioned there.</p>
<p>But <strong>Yes</strong>, unlike <a href="https://bibwild.wordpress.com/2018/09/26/what-just-rails-means-to-the-university-of-alberta-libraries/">Alberta</a>, we are taking <em>some</em> functionality and putting it in a gem that can be shared between institutions and applications. That gem is <a href="https://github.com/sciencehistory/kithe">kithe</a>. It includes some sharable modeling/persistence code, like Valkyrie (but with a very different approach than Valkyrie), but also includes some additional fundamental components too.</p>
<h2>Scaling back the ambition—and abstraction—a bit</h2>
<p>The total architecture outlined in my <a href="https://bibwild.wordpress.com/2018/09/05/proposed-rails-based-digital-collections-developers-toolkit/">original post</a> was starting to feel overwhelming to me. After all, we <em>also</em> need to actually produce and launch an app for ourselves, on a &#8220;reasonable&#8221; timeline, with fairly high chance of success.  I left my conversation with <a href="https://bibwild.wordpress.com/2018/09/26/what-just-rails-means-to-the-university-of-alberta-libraries/">U Alberta</a> (which was quite useful, thank you to the Alberta team!), concerned about potential over-reach and over-abstraction. Abstraction always has a cost and building shared components is harder and more time-consuming than building a custom app.</p>
<p>But, then, also informed by my discussion with Alberta,  I realized we basically just had to <em>build a Rails app</em>, and this is something I knew how to do, and we could, as we progressed, jetison anything that didn&#8217;t seem actually beneficial for that goal or seem feasible <em>at the moment. </em>And, also after discussion with a supportive local team, my anxiety about the project went down quite a bit &#8212; we can do this.</p>
<p>Even when writing the original proposal, I knew that some elements might be traps. Building a generalized <a href="https://en.wikipedia.org/wiki/Access_control_list">ACL</a> permissions system in an rdbms-based web app&#8230; many have tried, many have fallen. :)  Generalized <em>controllers</em> are hard, because they are a piece very tightly tied to your particular app&#8217;s UI flows, which will vary.</p>
<p>So we&#8217;ve scaled back from trying to provide a toolkit which can also be &#8220;scaffolding&#8221; for a <em>complete</em> starter app.  The goals of the original thought-experiment proposal &#8212; a <em>toolkit</em> which provides  <em>pieces</em> developers put together when building their own app &#8212; are better approached, for now, by <em>scaling back</em> and providing fewer shared tools, which we can make really solid.</p>
<p>After all, building <em>shared</em> code is <em>always</em> harder than building code for <em>your app</em>. You have more use cases to figure out and meet, and crucially, shared code is <em>harder to change</em> because it&#8217;s (potentially) got cross-institutional dependents, which you have to not break. For the code I <em>am</em> putting into kithe, I&#8217;m trying to make it solidly constructed and well-<a href="https://schneems.com/2017/03/13/puma-ports-and-polish/">polished</a>. In purely local code,  I&#8217;m more willing to do something experimental and hacky &#8212; it&#8217;s easy enough (comparatively!) to change <em>local app</em> code later.  As with all software, get <em>something</em> out there that works, iterating, using what you learn. (It&#8217;s just that this is a lot harder to do with shared dependencies without pain!)</p>
<p>So, on October 1st, we decided to embark on this project. We&#8217;re willing to show you our fairly informal sketch of a <a href="https://docs.google.com/document/d/1YhJkKWIRI4VP3c75bDs9Py-h_LcVs31b1IY5KeRFyYM/edit?usp=sharing">work plan</a>, if you&#8217;d like to look.</p>
<h2>Introducing <a href="https://github.com/sciencehistory/kithe">kithe</a></h2>
<p>But we&#8217;re not <em>just</em> building a local app, we are also trying to create some shareable components. While the costs and risks of shared code and abstractions are real,  I ultimately decided that &#8220;just Rails&#8221; would not get us to the most maintainable code after all. (And of course nothing is really <em>just</em> Rails, you are always <em>writing code </em>and <em>using non-Rails dependencies; </em>it&#8217;s a matter of degree, how much your app seems like a &#8220;typical&#8221; Rails app to developers).</p>
<p>It&#8217;s just too hard to model the data we ourselves already needed (including nested/compound/repeated models) in &#8220;just&#8221; ActiveRecord, especially in a way that lets you work with it sanely as &#8220;just&#8221; ActiveRecord, and is still performant. (So we use <a href="https://github.com/jrochkind/attr_json">attr_json</a>, which I also developed, for a No-SQLy approach without giving up rdbms or ActiveRecord benefits including real foreign-key-based associations). And in another example, <a href="https://guides.rubyonrails.org/active_storage_overview.html">ActiveStorage</a> was not flexible/powerful enough for our file-handling needs (which are of course at the core of our domain!), and I wasn&#8217;t enthused about <a href="https://github.com/carrierwaveuploader/carrierwave">CarrierWave</a> either &#8212; it makes sense to me to make <em>some</em> solid high-quality components/abstractions for some of our fundamental business/domain concerns, while being aware of the risks/costs.</p>
<p>So I&#8217;ve put into <a href="https://github.com/sciencehistory/kithe">kithe</a> the components I thought seemed appropriate on several considerations:</p>
<ul>
<li>Most valuable to our local development effort</li>
<li>Handling the &#8220;trickiest&#8221; problems, most useful to share</li>
<li>Handling <em>common</em> problems, most likely to be shareable; and it&#8217;s hard to build a suite of things that work together without some modelling/persistence assumptions, so got to start there.</li>
<li>I had enough understanding of the use-cases (local and community) that I thought I <em>could, </em>if I took a <em>reasonable</em> amount of extra time, produce something well-polished, with a good developer experience, and a relatively stable API.</li>
</ul>
<p>That already includes, in maybe not 1.0-production-ready but used in our <a href="https://github.com/sciencehistory/scihist_digicoll/">own in-progress app</a> and released (well-tested and well-documented) in kithe:</p>
<ul>
<li>A <a href="https://github.com/sciencehistory/kithe/blob/master/guides/modelling.md">modeling and persistence layer</a> tightly coupled to ActiveRecord, with some postgres-specific features, and recommending use of <a href="https://github.com/jrochkind/attr_json">attr_json,</a> for convenient &#8220;NoSQL&#8221;-like modelling of your unique business data (in common with existing samvera and valkyrie solutions, you don&#8217;t need to build out a normalized rdbms schema for your data). With models that are samvera/PCDM-<em>ish </em>(also like other community solutions).
<ul>
<li>Including pretty slick handling of <a href="https://github.com/sciencehistory/kithe/blob/master/guides/work_representative.md">&#8220;representatives&#8221;</a>, dealing with the performance issues in figuring out representative to display with constant query time (using some pg-specific SQL to look up and set &#8220;leaf&#8221; representative on save).</li>
<li>Including UUIDs as actual DB pk/fks, but also a <code>friendlier_id</code> feature for shorter public URL identifiers, with logic to automatically create such if you wish.</li>
</ul>
</li>
<li>A nice <a href="https://github.com/sciencehistory/kithe/blob/master/guides/forms.md">helper for building Rails forms</a> with repeatable complex embedded values. Compare to the relevant parts of <a href="https://github.com/samvera/hydra-editor">hydra-editor</a>, but (I think) lighter and more flexible.</li>
<li>A flexible <a href="https://github.com/sciencehistory/kithe/blob/master/guides/file_handling.md">file-handling architecture</a> based on <a href="https://github.com/sciencehistory/kithe/blob/master/guides/file_handling.md">shrine</a> &#8212; meaning transparent cloud-storage support out of the box.
<ul>
<li>Along with a new <a href="https://github.com/sciencehistory/kithe/blob/master/guides/derivatives.md">derivatives</a> architecture, which seems to me to have the right level of abstraction and affordances to provide a &#8220;polished&#8221; experience.</li>
<li>All file-handling support based on assuming expensive things happen in the background, and &#8220;direct upload&#8221; from browser pre-form-submit (possibly to cloud storage)</li>
</ul>
</li>
</ul>
<p>It will eventually include some solr/blacklight support, including a <a href="https://github.com/traject/traject">traject</a>-based indexing setup, and I would like to develop an intervention in blacklight so after solr results are returned, it immediately fetches the &#8220;hit&#8221; records <em>from ActiveRecord</em> (with specified eager-loading), so you can write your view code in terms of your actual AR models, and not need to duplicate data to solr and logic for dealing with it. This latter is taken from the design of <a href="https://github.com/sunspot/sunspot">sunspot</a>.</p>
<p>But before we get there, we&#8217;re going to spend a little bit of time on purely local features, including export/import routines (to get our data into the new app; with some solid testing/auditing to be confident we have), and some locally bespoke workflow support (I think workflow is something that works best <em>just writing the Rails). </em></p>
<p>We do have an application deployed as demo/staging, with a basic more-than-just-MVP-but-not-done-yet back-end management interface (note: <i>it does not use Solr/Blacklight at all </i>which I consider a <i>feature</i>), but not yet any non-logged-in end-user search front-end. If you&#8217;d like a guest login to see it, just ask.</p>
<h2>Technical Evaluation So Far</h2>
<p>We&#8217;ve decided to tie our code to Rails and ActiveRecord. Unlike Valkyrie, which provides a data-mapper/repository pattern abstraction, kithe expects the dependent code to <em>use ActiveRecord APIs</em> (along with some standard models and modelling enhancements kithe gives you).</p>
<p>This means, unlike Valkyrie, our solution is not &#8220;persistence-layer agnostic&#8221;. Our app, and any potential kithe apps, are tied to Rails/ActiveRecord, and can&#8217;t use fedora or other persistence mechanisms. We didn&#8217;t have much need/interest in that, we&#8217;re happy tying our <em>application logic</em> <em>and storage </em>to ActiveRecord/postgres, and perhaps later focusing on regularly exporting our <em>data</em> to be stored for preservation purposes in another format, perhaps in <a href="https://ocfl.io/">OCFL</a>.</p>
<p>It&#8217;s worth noting that the data-mapper/repository pattern itself, along the lines valkyrie uses, is favored by some people for reasons other than persistence-swapability. In the Rails and ruby web community at large, there is a contingent that <a href="https://www.thoughtfulcode.com/orm-active-record-vs-data-mapper/">think</a> the data-mapper/repository pattern is <em>better</em> than what Rails gives you, and gives you better architecture for maintainable code. Many of this contingent is <a href="https://ryanbigg.com/2018/03/my-thoughts-on-hanami">big on hanami</a>, and the <a href="https://dry-rb.org/">dry-rb</a> suite.  (I have never been fully persuaded by this contingent).</p>
<p>And to be sure, in building out our approach over the last 4 months, I sometimes ran right into the architectural issues with Rails &#8220;model-based&#8221; architecture and some of what it encourages like <a href="https://spin.atomicobject.com/2018/07/28/rails-callbacks-suppression/">dreaded callbacks</a>.  But often these were <em>hypothetical</em> problems, &#8220;What <em>if</em> someone wanted to do X,&#8221; rather than something I actually needed/wanted to do now. Take a breath, return to agility and &#8220;build our app&#8221;.</p>
<p>And a Rails/ActiveRecord-focused approach has huge advantages too. ActiveRecord associations and <a href="https://guides.rubyonrails.org/active_record_querying.html#eager-loading-associations">eager-loading support</a> are very mature and powerful tools, that when exposed to the app as an API give you very mature, time-tested tools to build your app flexibly and <em>performantly (</em>at least for the architectures our community are used to, where <a href="https://semaphoreci.com/blog/2017/08/09/faster-rails-eliminating-n-plus-one-queries.html">avoiding n+1 queries</a> still sometimes seems like an unsolved problem!).  You have a whole Rails ecosystem to rely on, which kithe-dependent apps can just use, making whatever choices they want (use <a href="https://github.com/trailblazer/reform">reform</a> or not?) as with most any Rails app, without having to work out as many novel approaches or APIs. (To be sure, kithe still provides some constraints and choices and novelty &#8212; it&#8217;s a question of degree).</p>
<p>Trying to build up an alternative based on data-mapper/repository, whether in hanami or valkyrie, I think you have a lot of work to do to be competitive with Rails mature solutions, sometimes reproducing features already in ActiveRecord or it&#8217;s ecosystem. And it&#8217;s not just work that&#8217;s &#8220;time implementing&#8221;, it&#8217;s work <em>figuring out</em> the right APIs and patterns. Hanami, for instance, is probably still <a href="https://rossta.net/blog/what-i-learned-about-hanami.html">not as mature</a>, as Rails, or as easy to use for a newcomer.</p>
<p>By not having to spend time <em>re-inventing</em> things that Rails already has solutions for, I could spend time on our actual (digital collections) domain-specific components that I <em>wasn&#8217;t</em> happy with existing solutions for. Like spending time on creating shareable file handling and derivatives solutions that seem to me to be well-polished, and able to be used for flexible use-cases without feeling like you&#8217;re fighting the system or being surprised by it. Components that <em>hopefuly</em> can be re-used by other apps too.</p>
<p>I think schneem&#8217;s <a href="https://schneems.com/2017/03/13/puma-ports-and-polish/">thoughts on &#8220;polish&#8221;</a> are <em>crucial</em> reading when thinking about the true costs of shared abstractions in our community.  There is a <em>cost</em> to additional abstractions: in initial implementation, ongoing maintenance, developer on-boarding, and just figuring out the right architectures and APIs to provide that polish. <em>Sometimes</em> these costs are worthwhile in delivered benefits, of course.</p>
<p>I&#8217;d consider our kithe-based approach to be somewhere in between U Alberta&#8217;s approach and valkryie, in the dimension of &#8220;how close do we stick to and tie our line to &#8216;standard&#8217; Rails&#8221;.</p>
<p>Unlike Hyrax, we are <em>building our own app</em>, not trying to use a shared app or &#8220;solution bundle&#8221; like Hyrax. I would suggest we share that aspect with both the U Alberta approach as well as the several institutions building valkyrie-not-hyrax apps. But if you&#8217;ve had good experiences with the over-time maintenance costs of Hyrax, you have a use case/context where Hyrax has worked well for you &#8212; then that&#8217;s great, and there&#8217;s never anything wrong with doing what has worked for you.</p>
<p>Overall, 4 months in, while some things have taken longer to implement than I expected, and some unexpected design challenges have been encountered &#8212; I&#8217;m still happy with the approach we are taking.</p>
<p>If you are considering a based-on-valkyrie-no-hyrax approach, I think you might be in a good position to <em>consider</em> a kithe approach too.</p>
<h2>How do we evaluate success?</h2>
<p>Locally,</p>
<p><strong>We want to have a replacement app launched in <em>about</em> a year</strong>.</p>
<p>I think we&#8217;re basically on target, although we might not hit it on the nose, I feel confident at this point that we&#8217;re going to succeed with a solid app, in around that timeline. (knock on wood).</p>
<p>When we were considering alternate approaches before committing to this one, we of course tried to compare how long this would take to various other approaches. <em>This is very hard to predict</em>, because you are trying to compare <em>multiple</em> hypotheticals, but we had to make some ballpark guesses (others may have other estimates).</p>
<p>Is this more or less time than it would have taken to migrate our sufia app to current hyrax? I think it&#8217;s <em>probably</em> taking more time to do it this new way, but I think migrating our sufia app to current hyrax (with all it&#8217;s custom functionality for current features) would <em>not</em> have been easy or quick &#8212; and we weren&#8217;t sure current hyrax was a place we wanted to end up.</p>
<p>Is it going to take more or less time than it would have taken to write an app on valkyrie, including any work we might contribute to valkyrie for features we needed? It&#8217;s always hard to guess these things, but I&#8217;d guess in the same ballpark, although I&#8217;m optimistic the &#8220;kithe&#8221; approach can lead to developer time-savings in the long-run.</p>
<p>(Of course, we hope if someone else wants to follow our path, they can re-use what&#8217;s now worked out in <code>kithe</code> to go quicker).</p>
<p><strong>We want it to be an app whose long-term maintenance and continued development costs are good</strong></p>
<p>In our sufia-based app, <a href="https://bibwild.wordpress.com/2018/08/28/on-the-present-and-future-of-samvera-technical-architectures/">we found</a> it could be difficult and time-consuming to add some of the features we needed. We also spent a lot of time trying to performance-tune to acceptable levels (and <a href="https://pulibrary.github.io/2018-06-05-valkyrie-reimagining-samvera">we weren&#8217;t alone</a>), or figure out and work towards a manageable and cost-efficient cloud deployment architecture.</p>
<p>I am absolutely confident that our &#8220;kithe&#8221; approach will give us something with a lower TCO (&#8220;total cost of ownership&#8221;) than we had with sufia.</p>
<p>Will it be a lower TCO than if we were on the present hyrax (ignoring how to get there), with our custom features we needed? I think so, and that current hyrax isn&#8217;t different enough from sufia we are used to &#8212; but again this is necessarily a guess, and others may disagree. In the end, technical staff just has to make their best predictions based on experience (individual and community).  Hyrax probably will <em>continue</em> to improve under @no-reply&#8217;s steady leadership, but I think we have to make our decisions on what&#8217;s there now, and that potential rosey future also requires continued <em>contribution</em> by the community (like us) if it is to come to fruition, which is real time to be included in TCO too.   I&#8217;m still feeling good about the &#8220;write our own app&#8221; approach vs &#8220;solution bundle&#8221;.</p>
<p>Will we get a lower TCO than if we had a non-hyrax valkyrie-based app? Even harder to say. Valkryie has more abstractions and layers that have real ongoing maintenance costs (that <em>someone</em> has to do), but there&#8217;s an argument that those layers will lower your TCO over the long-term. I&#8217;m not totally persuaded by that argument myself, and when in doubt am inclined to choose the less-new-abstraction path, but it&#8217;s hard to predict the future.</p>
<p>One thing worth noting is the main thing that <strong>forced our hand</strong> in doing <strong>something</strong> with our existing sufia-based app is that it was stuck on an old version of Rails that will soon be out-of-support, and we thought it would have been time-consuming to update, one way or another.  (When Rails 6.0 is released, probably in the next few months, <a href="https://guides.rubyonrails.org/maintenance_policy.html">Rails maintenance policy</a> says nothing before 5.2 will be supported.) Encouragingly, both kithe and attr_json dependency (also by me), are testing green on Rails 6.0 beta releases &#8212; and, I was gratified to see, didn&#8217;t take any code changes to do so, they just passed.  (Valkyrie 1.x requires Rails 5.1, but a soon-to-be-released 2.0 is planned to work fine up to Rails 6; latest hyrax requires Rails 5.1 as well, but the hyrax team would like to add 5.2 and 6 soon).</p>
<p><strong>We want easier on-boarding of new devs for succession planning</strong></p>
<p>All developers will leave eventually (which is one reason I think if you are doing any local development, a one-developer team is a bad idea &#8212; you are guaranteeing that at <em>some</em> point 100% of your dev team will leave at once).</p>
<p>We want it to be easier to on-board new developers. We share U Alberta&#8217;s goal that what we could call a &#8220;typical Rails developer&#8221; should be able to come on and maintain and enhance the app.</p>
<p>Are we there? Well, while our <a href="https://github.com/sciencehistory/scihist_digicoll/">local app</a> is relatively simple rails code (albeit using kithe API&#8217;s), the implementation of  kithe and attr_json, which a dev may have to delve into, can get a bit funky, and didn&#8217;t turn out quite as simple as I would have liked.</p>
<p>But when I get a bit nervous about this, I reassure myself remembering that:</p>
<ul>
<li>a) Our <em>existing</em> sufia-based app is definitely high-barrier for new devs (<a href="https://docs.google.com/presentation/d/1Sg6JGjoV8Ow4LkiHWAHkzhQJ-tKdMTcjGZla9UFPr1w/edit#slide=id.g1373072cad_0_1">an experience not unique to us</a>), I think we can definitely beat that.
<ul>
<li>Also worth pointing out that when we last posted a position, we got no qualified applicants with samvera, or even Rails, experience. We did make a great hire though, someone who knew back-end web dev and knew how to learn new tools; it&#8217;s that kind of person that we ideally need our codebase to be accessible to, and the sufia-based one was <em>not</em>.</li>
</ul>
</li>
<li>b) Recruiting and on-boarding new devs is <em>always</em> a challenge for <em>any</em> small dev shop, especially if your salaries are not seen as competitive.  It&#8217;s just part of the risk and challenge you accept when doing local development as a small shop on <em>any</em> platform. (Whether <em>that</em> is the right choice is out of scope for this post!)</li>
</ul>
<p>I <em>think</em> our code is going to end up more accessible to actually-existing newly onboarded devs  than a customized hyrax-based solution would be. More than Valkyrie? I do think so myself, I think we have fewer layers of &#8220;specialty&#8221; stuff than valkyrie, but it&#8217;s certainly hard to be sure, and everyone must judge for themselves.</p>
<p>I <em>do</em> think any competent Rails consultancy (without previous LAM/samvera expertise) could be hired to deal with our kithe-based app no problem; I can&#8217;t really say if that would be true of a Valkyrie-based app (it might be); I do not personally have confidence it would be true of a hyrax-based app at this point, but others may have other opinions (or experience?).</p>
<h3>Evaluating success with the community?</h3>
<p><em>Ideally, </em>we&#8217;d of course love it if some other institutions eventually developed with the <a href="https://github.com/sciencehistory/kithe">kithe</a> toolkit, with the potential for sharing future maintenance of it.</p>
<p>Even if that doesn&#8217;t happen, I don&#8217;t think we&#8217;re in a <em>terrible</em> place. It&#8217;s worth noting that there has been some non-LAM-community <a href="https://github.com/jrochkind/attr_json/issues?utf8=%E2%9C%93&amp;q=is%3Aissue">Rails dev interest in attr_json</a>, and occasional PRs; I wouldn&#8217;t say it&#8217;s in a <em>confidently sustainable</em> place if I left, but I also think it&#8217;s code someone else <em>could</em> step into and figure out. It&#8217;s just not <em>that</em> many lines of code, it&#8217;s well-tested and well-documented, and and i&#8217;ve tried to be careful with it&#8217;s design &#8212; but <a href="https://github.com/sciencehistory/kithe/">take a look</a> at and decide for yourself!. <b>I can not emphasize enough</b> my belief that if you are doing local development at all (and I think any samvera-based app has always been such), you should have local technical experts doing evaluation before committing to a platform &#8212; hyrax, valkyrie, kithe, entirely homegrown, whatever.</p>
<p>Even if no-one else develops with kithe itself, we&#8217;d consider it a success if some of the <em>ideas</em> from kithe influence the larger samvera and digital collections/repository communities. You are welcome to copy-paste-modify code that looks useful (It&#8217;s MIT licensed, have at it!). And even just take API ideas or architectural concepts from our efforts, if they seem useful.</p>
<p>We do take seriously participating in and giving back to the larger community, and think trying a <em>different</em> approach, so we and others can see how it goes, is part of that. Along with taking the extra time to do it in public and write things up, like this. And we also want to maintain our mutually-beneficial ties to samvera and LAM technologist communities; even if we are using different architectures, we still have lots of use-cases and opportunities for sharing both knowledge and code in common.</p>
<h2>Take a look?</h2>
<p>If you are considering development of a non-Hyrax valkyrie-based app, and have the development team to support that &#8212; I believe you have the development team to support a kithe-based approach too.</p>
<p>I would be quite happy if anyone took a look, and happy to hear feedback and have conversations, regardless of whether you end up using the actual kithe code or not. Kithe is not 1.0, but there&#8217;s definitely enough there to check it out and get a sense of what developing with it might be like, and whether it seems technically sound to you. And I&#8217;ve taken some time to write some good &#8220;guide&#8221; overview docs, both for potential &#8220;onboarding&#8221; of future devs here, and to share with you all.</p>
<p>We have a staging server for our in-development app based on kithe; if you&#8217;d like a guest login so you can check it out, just ask and I can share one with you.</p>
<p>Our local app also should also <em>probably</em> be pretty easy for you to get installed (with dependencies) from a git checkout, and just run it and see how it goes. See: <a href="https://github.com/sciencehistory/scihist_digicoll/">https://github.com/sciencehistory/scihist_digicoll/</a></p>
<p>Hope to hear from you!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://bibwild.wordpress.com/2019/03/01/our-progress-on-new-digital-collections-app-and-introducing-kithe/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
		
		<media:content url="https://0.gravatar.com/avatar/6a13e655e637138f8d571cec3f9cea76?s=96&amp;d=https%3A%2F%2Fs0.wp.com%2Fi%2Fmu.gif" medium="image">
			<media:title type="html">jrochkind</media:title>
		</media:content>
	</item>
	</channel>
</rss>
