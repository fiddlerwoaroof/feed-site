<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Sam Saffron</title>
    <link>https://samsaffron.com/posts.rss</link>
    <description>Sam Saffron's blog</description>
    <language>en-us</language>
    <item>
      <title>Debugging hidden memory leaks in Ruby</title>
      <description>
&lt;p&gt;In 2015 I wrote about some of the tooling Ruby provides for &lt;a href=&quot;https://samsaffron.com/archive/2015/03/31/debugging-memory-leaks-in-ruby&quot;&gt;diagnosing managed memory leaks&lt;/a&gt;. The article mostly focused on the easy managed leaks.&lt;/p&gt;
&lt;p&gt;This article covers tools and tricks you can use to attack leaks that you can not easily introspect in Ruby. In particular I will discuss mwrap, heaptrack, iseq_collector and chap.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/9/921e3b91465bbbb906d535676b1d1b89d154c80f.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/921e3b91465bbbb906d535676b1d1b89d154c80f&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/9/921e3b91465bbbb906d535676b1d1b89d154c80f_2_690x286.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;kQCu0aBea6Wzy5u52K6j9Bm7lin&quot; width=&quot;690&quot; height=&quot;286&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/9/921e3b91465bbbb906d535676b1d1b89d154c80f_2_690x286.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/9/921e3b91465bbbb906d535676b1d1b89d154c80f_2_1035x429.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/9/921e3b91465bbbb906d535676b1d1b89d154c80f_2_1380x572.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/9/921e3b91465bbbb906d535676b1d1b89d154c80f_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1787×742 230 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;an-unmanaged-memory-leak-1&quot; class=&quot;anchor&quot; href=&quot;#an-unmanaged-memory-leak-1&quot;&gt;&lt;/a&gt;An unmanaged memory leak&lt;/h3&gt;
&lt;p&gt;This little program leaks memory by calling malloc directly. It starts off consuming 16MB and finishes off consuming 118MB of RSS. The code allocates 100k blocks of 1024 bytes and de-allocates 50 thousand of them.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;
require 'fiddle'
require 'objspace'

def usage
  rss = `ps -p #{Process.pid} -o rss -h`.strip.to_i * 1024
  puts &quot;RSS: #{rss / 1024} ObjectSpace size #{ObjectSpace.memsize_of_all / 1024}&quot;
end

def leak_memory
  pointers = []
  100_000.times do
    i = Fiddle.malloc(1024)
    pointers &amp;lt;&amp;lt; i
  end

  50_000.times do
    Fiddle.free(pointers.pop)
  end
end

usage
# RSS: 16044 ObjectSpace size 2817

leak_memory

usage
# RSS: 118296 ObjectSpace size 3374

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even though our RSS is 118MB, our Ruby object space is only aware of 3MB, introspection wise we have very little visibility of this very large memory leak.&lt;/p&gt;
&lt;p&gt;A real world example of such a leak is &lt;a href=&quot;http://www.be9.io/2015/09/21/memory-leak/&quot;&gt;documented by Oleg Dashevskii&lt;/a&gt;, it is an excellent article worth reading.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;enter-mwrap-2&quot; class=&quot;anchor&quot; href=&quot;#enter-mwrap-2&quot;&gt;&lt;/a&gt;Enter Mwrap&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://80x24.org/mwrap/README.html&quot;&gt;Mwrap&lt;/a&gt; is a memory profiler for Ruby that keeps track of all allocations by intercepting malloc and family calls. It does so by intercepting the real calls that allocate and free memory using  &lt;a href=&quot;https://blog.jessfraz.com/post/ld_preload/&quot;&gt;LD_PRELOAD&lt;/a&gt;. It uses &lt;a href=&quot;https://liburcu.org/&quot;&gt;liburcu&lt;/a&gt; for bookkeeping and is able to keep track of allocation and de-allocation counts per call-site for both C code and Ruby. It is reasonably lightweight and will approximately double the RSS for the program being profiled and approximately halve the speed.&lt;/p&gt;
&lt;p&gt;It differs from many other libraries in that it is very lightweight and Ruby aware. It track locations in Ruby files and is not limited to C level backtrackes valgrind+masif and similar profilers show. This makes isolating actual sources of an issue much simpler.&lt;/p&gt;
&lt;p&gt;Usage involves running an application via the mwrap wrapper, it inject the LD_PRELOAD environment and execs the Ruby binary.&lt;/p&gt;
&lt;p&gt;Let’s append mwrap to our above script:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;require 'mwrap'

def report_leaks
  results = []
  Mwrap.each do |location, total, allocations, frees, age_total, max_lifespan|
    results &amp;lt;&amp;lt; [location, ((total / allocations.to_f) * (allocations - frees)), allocations, frees]
  end
  results.sort! do |(_, growth_a), (_, growth_b)|
    growth_b &amp;lt;=&amp;gt; growth_a
  end

  results[0..20].each do |location, growth, allocations, frees|
    next if growth == 0
    puts &quot;#{location} growth: #{growth.to_i} allocs/frees (#{allocations}/#{frees})&quot;
  end
end

GC.start
Mwrap.clear

leak_memory

GC.start

# Don't track allocations for this block
Mwrap.quiet do
  report_leaks
end

Mwrap.dump
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we will launch our script with the mwrap wrapper&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;% gem install mwrap
% mwrap ruby leak.rb
leak.rb:12 growth: 51200000 allocs/frees (100000/50000)
leak.rb:51 growth: 4008 allocs/frees (1/0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mwrap correctly detected the leak in the above script (50,000 * 1024). Not only it detected it, it isolated the actual line in the script (&lt;code&gt; i = Fiddle.malloc(1024)&lt;/code&gt; ) which caused the leak. It correctly accounted for the &lt;code&gt;Fiddle.free&lt;/code&gt; calls.&lt;/p&gt;
&lt;p&gt;It is important to note we are dealing with estimates here, mwrap keeps track of &lt;strong&gt;total&lt;/strong&gt; memory allocated at the call-site and then keeps track of de-allocations. However, if you have a single call-site that is allocating memory blocks of different sizes the results can be skewed, we have access to the estimate: &lt;code&gt;((total / allocations) * (allocations - frees))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Additionally, to make tracking down leaks easier mwrap keeps track of &lt;code&gt;age_total&lt;/code&gt; which is the sum of the lifespans of every object that was freed, and &lt;code&gt;max_lifespan&lt;/code&gt; which is the lifespan of the oldest object in the call-site. If &lt;code&gt;age_total / frees&lt;/code&gt; is high, it means the memory growth survives many garbage collections.&lt;/p&gt;
&lt;p&gt;Mwrap has a few helpers that can help you reduce noise. &lt;code&gt;Mwrap.clear&lt;/code&gt; will clear all the internal storage. &lt;code&gt;Mwrap.quiet {}&lt;/code&gt; will suppress Mwrap tracking for a block of code.&lt;/p&gt;
&lt;p&gt;Another neat feature Mwrap has is that it keeps track of total allocated bytes and total freed bytes. If we remove the clear from our script and run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;usage
puts &quot;Tracked size: #{(Mwrap.total_bytes_allocated - Mwrap.total_bytes_freed) / 1024}&quot;

# RSS: 130804 ObjectSpace size 3032
# Tracked size: 91691
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is very interesting cause even though our RSS is 130MB, Mwrap is only seeing 91MB, this demonstrates we have bloated our process. Running without mwrap shows that the process would normally be 118MB so in this simple case accounting is a mere 12MB, the pattern of allocation / deallocation caused fragmentation. Knowing about fragmentation can be quite powerful, in some cases with untuned glibc malloc processes can fragment so much that a very large amount memory consumed in RSS is actually free.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;could-mwrap-isolate-the-old-redcarpet-leak-3&quot; class=&quot;anchor&quot; href=&quot;#could-mwrap-isolate-the-old-redcarpet-leak-3&quot;&gt;&lt;/a&gt;Could Mwrap isolate the old redcarpet leak?&lt;/h3&gt;
&lt;p&gt;In &lt;a href=&quot;http://www.be9.io/2015/09/21/memory-leak/&quot;&gt;Oleg’s article&lt;/a&gt; he discussed a very thorough way he isolated a very subtle leak in redcarpet. There is lots of detail there. It is critical that you &lt;strong&gt;have instrumentation&lt;/strong&gt;. If you are not graphing process RSS you have very little chance at attacking any memory leak.&lt;/p&gt;
&lt;p&gt;Let’s step into a time machine and demonstrate how much easier it can be to use Mwrap for such leaks.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;def red_carpet_leak
  100_000.times do

    markdown = Redcarpet::Markdown.new(Redcarpet::Render::HTML, extensions = {})
    markdown.render(&quot;hi&quot;)
  end
end

GC.start
Mwrap.clear

red_carpet_leak

GC.start

# Don't track allocations for this block
Mwrap.quiet do
  report_leaks
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Redcarpet version 3.3.2&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;redcarpet.rb:51 growth: 22724224 allocs/frees (500048/400028)
redcarpet.rb:62 growth: 4008 allocs/frees (1/0)
redcarpet.rb:52 growth: 634 allocs/frees (600007/600000)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Redcarpet version 3.5.0&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;redcarpet.rb:51 growth: 4433 allocs/frees (600045/600022)
redcarpet.rb:52 growth: 453 allocs/frees (600005/600000)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Provided you can afford for a process to run at half speed simply re-launching it in production with Mwrap and logging Mwrap output once in a while to a file can identify a broad spectrum of memory leaks.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;a-mysterious-memory-leak-4&quot; class=&quot;anchor&quot; href=&quot;#a-mysterious-memory-leak-4&quot;&gt;&lt;/a&gt;A mysterious memory leak&lt;/h3&gt;
&lt;p&gt;Recently we upgraded Rails to version 6 at Discourse. Overall the experience was extremely positive, performance remained more or less the same, Rails 6 includes some very nice features we get to use (like &lt;a href=&quot;https://medium.com/@fxn/zeitwerk-a-new-code-loader-for-ruby-ae7895977e73&quot;&gt;Zeitwerk&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Rails amended the way templates are rendered which required a few backwards compatible changes.&lt;/p&gt;
&lt;p&gt;Fast forward a few days after our upgrade and we noticed RSS for our Sidekiq job runner was climbing.&lt;/p&gt;
&lt;p&gt;Mwrap kept on reporting a sharp incline in memory due to memory being allocated at:&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot; data-onebox-src=&quot;https://github.com/rails/rails/blob/94fe2430da93daf52f63dbc248dcbdc8e8de2c31/actionview/lib/action_view/template.rb#L341&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;

      &lt;a href=&quot;https://github.com/rails/rails/blob/94fe2430da93daf52f63dbc248dcbdc8e8de2c31/actionview/lib/action_view/template.rb#L341&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;

  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/rails/rails/blob/94fe2430da93daf52f63dbc248dcbdc8e8de2c31/actionview/lib/action_view/template.rb#L341&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;rails/rails/blob/94fe2430da93daf52f63dbc248dcbdc8e8de2c31/actionview/lib/action_view/template.rb#L341&lt;/a&gt;&lt;/h4&gt;



    &lt;pre class=&quot;onebox&quot;&gt;&lt;code class=&quot;lang-rb&quot;&gt;
      &lt;ol class=&quot;start lines&quot; start=&quot;331&quot; style=&quot;counter-reset: li-counter 330 ;&quot;&gt;
          &lt;li&gt;  source.encode!&lt;/li&gt;
          &lt;li&gt;
          &lt;/li&gt;
&lt;li&gt;  # Now, validate that the source we got back from the template&lt;/li&gt;
          &lt;li&gt;  # handler is valid in the default_internal. This is for handlers&lt;/li&gt;
          &lt;li&gt;  # that handle encoding but screw up&lt;/li&gt;
          &lt;li&gt;  unless source.valid_encoding?&lt;/li&gt;
          &lt;li&gt;    raise WrongEncodingError.new(source, Encoding.default_internal)&lt;/li&gt;
          &lt;li&gt;  end&lt;/li&gt;
          &lt;li&gt;
          &lt;/li&gt;
&lt;li&gt;  begin&lt;/li&gt;
          &lt;li class=&quot;selected&quot;&gt;    mod.module_eval(source, identifier, 0)&lt;/li&gt;
          &lt;li&gt;  rescue SyntaxError&lt;/li&gt;
          &lt;li&gt;    # Account for when code in the template is not syntactically valid; e.g. if we're using&lt;/li&gt;
          &lt;li&gt;    # ERB and the user writes &amp;lt;%= foo( %&amp;gt;, attempting to call a helper `foo` and interpolate&lt;/li&gt;
          &lt;li&gt;    # the result into the template, but missing an end parenthesis.&lt;/li&gt;
          &lt;li&gt;    raise SyntaxErrorInTemplate.new(self, original_source)&lt;/li&gt;
          &lt;li&gt;  end&lt;/li&gt;
          &lt;li&gt;end&lt;/li&gt;
          &lt;li&gt;
          &lt;/li&gt;
&lt;li&gt;def handle_render_error(view, e)&lt;/li&gt;
          &lt;li&gt;  if e.is_a?(Template::Error)&lt;/li&gt;
      &lt;/ol&gt;
    &lt;/code&gt;&lt;/pre&gt;



  &lt;/article&gt;

  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;

  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;We initially found this very confusing and kept thinking to ourselves, why is Mwrap complaining? Could it be broken?&lt;/p&gt;
&lt;p&gt;During the period where memory was climbing the Ruby heaps were not growing in size in a significant manner.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/c/c1926ed0e9422d702e41c9e86e6d579d21a1d0ca.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/c1926ed0e9422d702e41c9e86e6d579d21a1d0ca&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/c/c1926ed0e9422d702e41c9e86e6d579d21a1d0ca_2_690x574.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;rCpSJqmRXgVaxNUrv8Wnw3moXO2&quot; width=&quot;690&quot; height=&quot;574&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/c/c1926ed0e9422d702e41c9e86e6d579d21a1d0ca_2_690x574.png, https://discuss.samsaffron.com/uploads/default/original/2X/c/c1926ed0e9422d702e41c9e86e6d579d21a1d0ca.png 1.5x, https://discuss.samsaffron.com/uploads/default/original/2X/c/c1926ed0e9422d702e41c9e86e6d579d21a1d0ca.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/c/c1926ed0e9422d702e41c9e86e6d579d21a1d0ca_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1031×858 66.9 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;2 million slots in the heap are a meager 78MB (40 bytes per slot), strings and arrays can take up more space, but this simply did not explain the enormous memory usage we were seeing. This was confirmed when I ran &lt;code&gt;rbtrace -p SIDEKIQ_PID -e ObjectSpace.memsize_of_all&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Where did all the memory go?&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;heaptrack-5&quot; class=&quot;anchor&quot; href=&quot;#heaptrack-5&quot;&gt;&lt;/a&gt;Heaptrack&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/KDE/heaptrack&quot;&gt;Heaptrack&lt;/a&gt; is a memory heap profiler for Linux.&lt;/p&gt;
&lt;p&gt;Milian Wolff does a great job explaining what it is and how it came to be &lt;a href=&quot;https://milianw.de/blog/heaptrack-a-heap-memory-profiler-for-linux.html&quot;&gt;on his blog&lt;/a&gt;. He also has several talks about it (&lt;a href=&quot;https://www.youtube.com/watch?v=myDWLPBiHn0&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=YB0QoWI-g8E&quot;&gt;2&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=-8cOWt7lvUQ&quot;&gt;3&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;In essence it is an incredibly efficient native heap profiler that gathers backtraces from a profiled applications using &lt;a href=&quot;https://www.nongnu.org/libunwind/&quot;&gt;libunwind&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is significantly faster than &lt;a href=&quot;http://valgrind.org/docs/manual/ms-manual.html&quot;&gt;Valgrind/Massif&lt;/a&gt; and has a feature that makes is much more suitable for &lt;strong&gt;temporary&lt;/strong&gt; production profiling.&lt;/p&gt;
&lt;p&gt;It can attach to an already running process!&lt;/p&gt;
&lt;p&gt;As with most heap profilers, when every single malloc family function is called it needs to do some accounting. This accounting certainly slows down the process a bit.&lt;/p&gt;
&lt;p&gt;The design, in my mind, is  the best possible design for this type of program. It intercepts using an LD_PRELOAD trick or a &lt;a href=&quot;https://milianw.de/blog/heaptrack-attaching-to-running-process&quot;&gt;GDB trick&lt;/a&gt; to load up the profiler. It ships the data out of the profiled process as quickly as possibly using a &lt;a href=&quot;https://linux.die.net/man/3/mkfifo&quot;&gt;FIFO special file&lt;/a&gt;. The wrapper &lt;a href=&quot;https://github.com/KDE/heaptrack/blob/983cc35dd000a8219e0d5713ab0a0d298af59c97/src/track/heaptrack.sh.cmake&quot;&gt;&lt;code&gt;heaptrack&lt;/code&gt;&lt;/a&gt; is a simple shell script, something that makes troubleshooting simple. A second process runs to read from the FIFO and compress the tracking data on the fly. Since heaptrack operates in “chunks” you can start looking at the profiled information seconds after you start profiling, mid way through a profiling session. Simply copy the profile file to another location and run the heaptrack gui.&lt;/p&gt;
&lt;p&gt;This &lt;a href=&quot;https://gitlab.com/gitlab-org/gitlab-foss/issues/49702&quot;&gt;ticket at GitLab&lt;/a&gt; alerted me to the possibility of running heaptrack. Since they were able to run it, I knew it was a possibility for me.&lt;/p&gt;
&lt;p&gt;We run our application in a container, I needed to relaunch our container with &lt;code&gt;--cap-add=SYS_PTRACE&lt;/code&gt; which allows GDB to use &lt;a href=&quot;https://en.wikipedia.org/wiki/Ptrace&quot;&gt;ptrace&lt;/a&gt; which we needed so heaptrack can inject itself. Additionally, I needed a &lt;a href=&quot;https://github.com/KDE/heaptrack/pull/22&quot;&gt;small hack&lt;/a&gt; on the shell file to allow &lt;code&gt;root&lt;/code&gt; to profile a non &lt;code&gt;root&lt;/code&gt; process (we run our Discourse application under a restricted account in the container).&lt;/p&gt;
&lt;p&gt;Once this was done it was as simple as running &lt;code&gt;heaptrack -p PID&lt;/code&gt; and waiting for results to stream in.&lt;/p&gt;
&lt;p&gt;The UX of heaptrack is fantastic and extremely rich, it was very easy to follow what was happening with my memory leak.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/6/692199b4589d173c373edccea8c0abd0400f72e0.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/692199b4589d173c373edccea8c0abd0400f72e0&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/692199b4589d173c373edccea8c0abd0400f72e0_2_690x404.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;f027CzVKR9bfbrWW04uJ9FOpBCw&quot; width=&quot;690&quot; height=&quot;404&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/692199b4589d173c373edccea8c0abd0400f72e0_2_690x404.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/6/692199b4589d173c373edccea8c0abd0400f72e0_2_1035x606.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/6/692199b4589d173c373edccea8c0abd0400f72e0_2_1380x808.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/692199b4589d173c373edccea8c0abd0400f72e0_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1555×911 356 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;At a top level I could see two jumps, one was due to &lt;code&gt;cppjieba&lt;/code&gt; and the other was originating from Ruby &lt;code&gt;objspace_xmalloc0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I knew about &lt;a href=&quot;https://github.com/fantasticfears/cppjieba_rb&quot;&gt;cppjieba&lt;/a&gt;, segmenting Chinese is expensive, large dictionaries are needed, it was not leaking.&lt;/p&gt;
&lt;p&gt;But why was ruby allocating memory and further more, not telling me about it?&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/2/2e4109dc8c97cc11cc6e478b65623c1f92eed8b7.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/2e4109dc8c97cc11cc6e478b65623c1f92eed8b7&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/2/2e4109dc8c97cc11cc6e478b65623c1f92eed8b7_2_690x325.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;6Bbj64hwTXdVhJ3zkwqeej2nfJd&quot; width=&quot;690&quot; height=&quot;325&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/2/2e4109dc8c97cc11cc6e478b65623c1f92eed8b7_2_690x325.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/2/2e4109dc8c97cc11cc6e478b65623c1f92eed8b7_2_1035x487.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/2/2e4109dc8c97cc11cc6e478b65623c1f92eed8b7_2_1380x650.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/2/2e4109dc8c97cc11cc6e478b65623c1f92eed8b7_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1846×871 333 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;The largest increase was coming from &lt;code&gt;iseq_set_sequence&lt;/code&gt; in &lt;code&gt;compile.c&lt;/code&gt;. So it follows that we were leaking instruction sequences.&lt;/p&gt;
&lt;p&gt;This made the leak Mwrap detected make sense. &lt;code&gt;mod.module_eval(source, identifier, 0)&lt;/code&gt; was causing a leak cause it was creating instruction sequences that were never being removed.&lt;/p&gt;
&lt;p&gt;In retrospect if I carefully analyzed a heap dump from Ruby I should have seen all these IMEMOs, cause they are included in heap dumps, just invisible from in-process introspection.&lt;/p&gt;
&lt;p&gt;From here on debugging was pretty simple, I tracked down all calls to the module eval and dumped out what it was evaluating. I discovered we kept on appending methods over and over to a big class.&lt;/p&gt;
&lt;p&gt;Simplified, this is the bug we were seeing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;require 'securerandom'
module BigModule; end

def leak_methods
  10_000.times do
    method = &quot;def _#{SecureRandom.hex}; #{&quot;sleep;&quot; * 100}; end&quot;
    BigModule.module_eval(method)
  end
end

usage
# RSS: 16164 ObjectSpace size 2869

leak_methods

usage
# RSS: 123096 ObjectSpace size 5583
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ruby has a class to contain instruction sequences called: &lt;code&gt;RubyVM::InstructionSequence&lt;/code&gt;. However, Ruby is lazy about creating these wrapping objects, cause it is inefficient to have them around unless needed.&lt;/p&gt;
&lt;p&gt;Interestingly &lt;a href=&quot;http://www.atdot.net/~ko1/&quot;&gt;Koichi Sasada&lt;/a&gt; created the &lt;a href=&quot;https://github.com/ko1/iseq_collector&quot;&gt;iseq_collector&lt;/a&gt; gem. If we add this snippet we can now find our hidden memory:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;require 'iseq_collector'
puts &quot;#{ObjectSpace.memsize_of_all_iseq / 1024}&quot;
# 98747
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ObjectSpace.memsize_of_all_iseq&lt;/code&gt; will materialize every instruction sequence, which can introduce slight process memory growth and slightly more GC work.&lt;/p&gt;
&lt;p&gt;If we, for example, count the number of ISEQs before and after running the collector we will notice that after running &lt;code&gt;ObjectSpace.memsize_of_all_iseq&lt;/code&gt; our &lt;code&gt;RubyVM::InstructionSequence&lt;/code&gt; class count grows from 0 to 11128 in the example above:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;def count_iseqs
  ObjectSpace.each_object(RubyVM::InstructionSequence).count
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These wrappers will stay around for the life of a method and need to be visited when a full GC runs.&lt;/p&gt;
&lt;p&gt;For those curious, our fix to our issue was reusing the class responsible for rendering email templates. (&lt;a href=&quot;https://review.discourse.org/t/perf-reuse-renderer-when-rendering-email-templates/6010&quot;&gt;fix 1&lt;/a&gt;, &lt;a href=&quot;https://review.discourse.org/t/fix-during-concurrent-emails-generation-renderer-should-not-be-reused/6097&quot;&gt;fix 2&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;chap-6&quot; class=&quot;anchor&quot; href=&quot;#chap-6&quot;&gt;&lt;/a&gt;chap&lt;/h3&gt;
&lt;p&gt;During my debugging I came across a very interesting tool.&lt;/p&gt;
&lt;p&gt;Tim Boddy, extracted an internal tool used at VMWare for analysis of memory leaks and open sourced it a few years ago. The only video I can find about it &lt;a href=&quot;https://www.youtube.com/watch?v=EZ2n3kGtVDk&quot;&gt;is here&lt;/a&gt;. Unlike most tools out there this tool has zero impact on a running process. It can simply run against core dump files, as long as the allocator being used is glibc (no support for jemalloc/tcmalloc etc)&lt;/p&gt;
&lt;p&gt;The initial leak I had can be very easily detected using chap. Not many distros include a binary for chap, but you can easily &lt;a href=&quot;https://github.com/vmware/chap&quot;&gt;build it from source&lt;/a&gt;. It is very actively maintained.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;# 444098 is the `Process.pid` of the leaking process I had
sudo gcore -p 444098

chap core.444098
chap&amp;gt; summarize leaked
Unsigned allocations have 49974 instances taking 0x312f1b0(51,573,168) bytes.
   Unsigned allocations of size 0x408 have 49974 instances taking 0x312f1b0(51,573,168) bytes.
49974 allocations use 0x312f1b0 (51,573,168) bytes.

chap&amp;gt; list leaked
...
Used allocation at 562ca267cdb0 of size 408
Used allocation at 562ca267d1c0 of size 408
Used allocation at 562ca267d5d0 of size 408
...


chap&amp;gt; summarize anchored 
....
Signature 7fbe5caa0500 has 1 instances taking 0xc8(200) bytes.
23916 allocations use 0x2ad7500 (44,922,112) bytes.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Chap can use signatures to find where various memory is allocated and can complement GDB. When it comes to debugging Ruby it can do a great job helping you finding out what the actual memory is in use for a process. &lt;code&gt;summarize used&lt;/code&gt; gives the actual memory, sometimes glibc malloc can fragment so much that the &lt;code&gt;used&lt;/code&gt; number is enormously different to the actual RSS. See: &lt;a href=&quot;https://bugs.ruby-lang.org/issues/14759&quot; class=&quot;inline-onebox&quot;&gt;Feature #14759: [PATCH] set M_ARENA_MAX for glibc malloc - Ruby master - Ruby Issue Tracking System&lt;/a&gt; for more discussion. Chap can correctly account for all memory usage and provide deep analysis around memory allocation behaviors.&lt;/p&gt;
&lt;p&gt;Additionally chap can be integrated into build pipelines to automatically detect leaks and flag builds that are leaking.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;future-work-7&quot; class=&quot;anchor&quot; href=&quot;#future-work-7&quot;&gt;&lt;/a&gt;Future work&lt;/h3&gt;
&lt;p&gt;This round of debugging did prompt me to raise a few issues with our supporting tool-sets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I would love to see heaptrack support grabbing call-stack frames from Ruby. Milian is interested in this problem as well: &lt;a href=&quot;https://bugs.kde.org/show_bug.cgi?id=412929&quot; class=&quot;inline-onebox&quot;&gt;412929 – Can we grab a frame from Ruby land?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I would love Ruby to support richer introspection: &lt;a href=&quot;https://bugs.ruby-lang.org/issues/16245&quot;&gt;https://bugs.ruby-lang.org/issues/16245&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I would love to see Mwrap be a little bit easier to use in production. &lt;a href=&quot;https://80x24.org/mwrap-public/CAAtdryNmPFAEDhf9ctEiCsGioX50h9JzOn4CusU76th+Oj_7vw@mail.gmail.com/T/#t&quot;&gt;Tracked here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;
&lt;a name=&quot;summary-8&quot; class=&quot;anchor&quot; href=&quot;#summary-8&quot;&gt;&lt;/a&gt;Summary&lt;/h3&gt;
&lt;p&gt;Our existing tooling for debugging very complex memory leaks in 2019 is vastly superior to what we had 4 years ago! Mwrap, heaptrack and chap provide us with very powerful tools for attacking memory related issues both in development and production.&lt;/p&gt;
&lt;p&gt;If you are hunting a simple memory leak in Ruby, I recommend &lt;a href=&quot;https://samsaffron.com/archive/2015/03/31/debugging-memory-leaks-in-ruby&quot;&gt;my earlier article&lt;/a&gt; from 2015, most of it still holds.&lt;/p&gt;
&lt;p&gt;I hope that next time you are stuck debugging a complex native memory leak you have an easier time!&lt;/p&gt;
&lt;p&gt;If you have any interesting battle stories or tools I have forgotten to mention you would like to share, please post a comment!&lt;/p&gt;</description>
      <pubDate>Tue, 15 Oct 2019 05:18:18 +0000</pubDate>
      <link>https://samsaffron.com/archive/2019/10/08/debugging-unmanaged-and-hidden-memory-leaks-in-ruby</link>
    </item>
    <item>
      <title>Tests that sometimes fail - flaky test tips</title>
      <description>
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/f/fdb9a669356ca19b0275aa03c9a8fa068202c61a.jpeg&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/fdb9a669356ca19b0275aa03c9a8fa068202c61a&quot; title=&quot;The boy who cried wolf&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/f/fdb9a669356ca19b0275aa03c9a8fa068202c61a_2_517x419.jpeg&quot; alt=&quot;The boy who cried wolf&quot; data-base62-sha1=&quot;Acyyji9bVutVCtF6feqyriyldRo&quot; width=&quot;517&quot; height=&quot;419&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/f/fdb9a669356ca19b0275aa03c9a8fa068202c61a_2_517x419.jpeg, https://discuss.samsaffron.com/uploads/default/original/2X/f/fdb9a669356ca19b0275aa03c9a8fa068202c61a.jpeg 1.5x, https://discuss.samsaffron.com/uploads/default/original/2X/f/fdb9a669356ca19b0275aa03c9a8fa068202c61a.jpeg 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/f/fdb9a669356ca19b0275aa03c9a8fa068202c61a_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;The boy who cried wolf&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;695×564 286 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikisource.org/wiki/The_Shepherd%27s_Boy_and_the_Wolf&quot;&gt; A liar will not be believed, even when he speaks the truth.&lt;/a&gt; : Aesop&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once you have a project that is a few years old with a large test suite an ugly pattern emerges.&lt;/p&gt;
&lt;p&gt;Some tests that used to always work, start “sometimes” working. This starts slowly, “oh that test, yeah it sometimes fails, kick the build off again”. If left unmitigated it can very quickly snowball and paralyze an entire test suite.&lt;/p&gt;
&lt;p&gt;Most developers know about this problem and call these tests “non deterministic tests”, “flaky tests”,“random tests”, “erratic tests”, “brittle tests”, “flickering tests” or even “heisentests”.&lt;/p&gt;
&lt;p&gt;Naming is hard, it seems that this toxic pattern does not have a well established unique and standard name. Over the years at Discourse we have called this many things, for the purpose of this article I will call them flaky tests, it seems to be the most commonly adopted name.&lt;/p&gt;
&lt;p&gt;Much has been written about why flaky tests are a problem.&lt;/p&gt;
&lt;p&gt;Martin Fowler &lt;a href=&quot;https://martinfowler.com/articles/nonDeterminism.html&quot;&gt;back in 2011&lt;/a&gt; wrote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Non-deterministic tests have two problems, firstly they are useless, secondly they are a virulent infection that can completely ruin your entire test suite.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To this I would like to add that flaky tests are an incredible cost to businesses. They are very expensive to repair often requiring hours or even days to debug and they jam the continuous deployment pipeline making shipping features slower.&lt;/p&gt;
&lt;p&gt;I would like to disagree a bit with Martin. Sometimes I find flaky tests are useful at finding underlying flaws in our application. In some cases when fixing a flaky test, the fix is in the app, not in the test.&lt;/p&gt;
&lt;p&gt;In this article I would like to talk about patterns we observed at &lt;a href=&quot;https://www.discourse.org&quot;&gt;Discourse&lt;/a&gt; and mitigation strategies we have adopted.&lt;/p&gt;
&lt;h2&gt;
&lt;a name=&quot;patterns-that-have-emerged-at-discourse-1&quot; class=&quot;anchor&quot; href=&quot;#patterns-that-have-emerged-at-discourse-1&quot;&gt;&lt;/a&gt;Patterns that have emerged at Discourse&lt;/h2&gt;
&lt;p&gt;A few months back we introduced a game.&lt;/p&gt;
&lt;p&gt;We created a topic on our development Discourse instance. Each time the test suite failed due to a flaky test we would assign the topic to the developer who originally wrote the test. Once fixed the developer who sorted it out would post a quick post morterm.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/4/4670d162127844b65fe7f821ddecfd3ff3e0c60a.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/4670d162127844b65fe7f821ddecfd3ff3e0c60a&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4670d162127844b65fe7f821ddecfd3ff3e0c60a_2_489x700.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;a398jLeN9h6WgD6UhvZqobtbc38&quot; width=&quot;489&quot; height=&quot;700&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4670d162127844b65fe7f821ddecfd3ff3e0c60a_2_489x700.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4670d162127844b65fe7f821ddecfd3ff3e0c60a_2_733x1050.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4670d162127844b65fe7f821ddecfd3ff3e0c60a_2_978x1400.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4670d162127844b65fe7f821ddecfd3ff3e0c60a_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1245×1779 203 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;This helped us learn about approaches we can take to fix flaky tests and raised visibility of the problem. It was a very important first step.&lt;/p&gt;
&lt;p&gt;Following that I started cataloging the flaky tests we found with the fixes at: &lt;a href=&quot;https://review.discourse.org/tags/heisentest&quot;&gt;https://review.discourse.org/tags/heisentest&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Recently, we built a system that continuously re-runs our test suite on an instance at digital ocean and flags any flaky tests (which we temporarily disable).&lt;/p&gt;
&lt;p&gt;Quite a few interesting patterns leading to flaky tests have emerged which are worth sharing.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;hard-coded-ids-2&quot; class=&quot;anchor&quot; href=&quot;#hard-coded-ids-2&quot;&gt;&lt;/a&gt;Hard coded ids&lt;/h3&gt;
&lt;p&gt;Sometimes to save doing work in tests we like pretending.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;user.avatar_id = 1
user.save!

# then amend the avatar
user.upload_custom_avatar!

# this is a mistake, upload #1 never existed, so for all we know
# the legitimate brand new avatar we created has id of 1. 
assert(user.avatar_id != 1)  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is more or less &lt;a href=&quot;https://github.com/discourse/discourse/commit/a84aaf197a4d2767b85e76cb2a9d06aaab944747&quot;&gt;this example here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Postgres often uses &lt;a href=&quot;https://www.postgresql.org/docs/current/sql-createsequence.html&quot;&gt;sequences&lt;/a&gt; to decide on the id new records will get. They start at one and keep increasing.&lt;/p&gt;
&lt;p&gt;Most test frameworks like to rollback a database transaction after test runs, however the rollback &lt;strong&gt;does not&lt;/strong&gt; roll back sequences.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;ActiveRecord::.transaction do
   puts User.create!.id
   # 1
   raise ActiveRecord::Rollback
puts 

puts User.create!.id
# 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This has caused us a fair amount of flaky tests.&lt;/p&gt;
&lt;p&gt;In an ideal world the “starting state” should be pristine and 100% predictable. However this feature of Postgres and many other DBs means we need to account for slightly different starting conditions.&lt;/p&gt;
&lt;p&gt;This is the reason you will almost never see a test like this when the DB is involved:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;t = Topic.create!
assert(t.id == 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another great, simple example &lt;a href=&quot;https://review.discourse.org/t/dev-correct-test-that-assumed-group-123-did-not-exist/3699&quot;&gt;is here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;random-data-3&quot; class=&quot;anchor&quot; href=&quot;#random-data-3&quot;&gt;&lt;/a&gt;Random data&lt;/h3&gt;
&lt;p&gt;Occasionally flaky tests can highlight legitimate application flaws. An &lt;a href=&quot;https://review.discourse.org/t/correct-short-url-decoding-for-sha1s-leading-with-zero/3430?u=samsaffron&quot;&gt;example of such a test&lt;/a&gt; is here.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;data = SecureRandom.hex
explode if data[0] == &quot;0&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course nobody would ever write such code. However, in some rare cases the bug itself may be deep in the application code, in an odd conditional.&lt;/p&gt;
&lt;p&gt;If the test suite is generating random data it may expose such flaws.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;making-bad-assumptions-about-db-ordering-4&quot; class=&quot;anchor&quot; href=&quot;#making-bad-assumptions-about-db-ordering-4&quot;&gt;&lt;/a&gt;Making bad assumptions about DB ordering&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;create table test(a int)
insert test values(1)
insert test values(2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have seen many times over the years cases where developers (including myself) incorrectly assumed that if you select the first row from the example above you are guaranteed to get &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;select a from test limit 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of the SQL above can be &lt;code&gt;1&lt;/code&gt; or it can be &lt;code&gt;2&lt;/code&gt; depending on a bunch of factors. If one would like guaranteed ordering then use:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;select a from test order by a limit 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This problem assumption can sometimes cause flaky tests, in some cases the tests themselves can be “good” but the underlying code works by fluke most of the time.&lt;/p&gt;
&lt;p&gt;An example of this &lt;a href=&quot;https://review.discourse.org/t/fix-delete-duplicate-invites-earlier-in-the-process/3521&quot;&gt;is here&lt;/a&gt; another one &lt;a href=&quot;https://review.discourse.org/t/fix-randomly-failing-spec/3458?u=samsaffron&quot;&gt;is here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A wonderful way of illustrating this is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;[8] pry(main)&amp;gt; User.order('id desc').find_by(name: 'sam').id
  User Load (7.6ms)  SELECT  &quot;users&quot;.* FROM &quot;users&quot; WHERE &quot;users&quot;.&quot;name&quot; = 'sam' ORDER BY id desc LIMIT 1
=&amp;gt; 25527
[9] pry(main)&amp;gt; User.order('id').find_by(name: 'sam').id
  User Load (1.0ms)  SELECT  &quot;users&quot;.* FROM &quot;users&quot; WHERE &quot;users&quot;.&quot;name&quot; = 'sam' ORDER BY id LIMIT 1
=&amp;gt; 2498
[10] pry(main)&amp;gt; User.find_by(name: 'sam').id
  User Load (0.6ms)  SELECT  &quot;users&quot;.* FROM &quot;users&quot; WHERE &quot;users&quot;.&quot;name&quot; = 'sam' LIMIT 1
=&amp;gt; 9931
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even if the clustered index primary key is on &lt;code&gt;id&lt;/code&gt; you are not guaranteed to retrieve stuff in id order unless you explicitly order.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;incorrect-assumptions-about-time-5&quot; class=&quot;anchor&quot; href=&quot;#incorrect-assumptions-about-time-5&quot;&gt;&lt;/a&gt;Incorrect assumptions about time&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;My test suite is not flaky, excepts from 11AM UTC till 1PM UTC.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A very interesting thing used to happen with some very specific tests we had.&lt;/p&gt;
&lt;p&gt;If I ever checked in code around 9:50am, the test suite would sometimes fail. The problem was that 10am in Sydney is 12am in UTC time (daylight savings depending). That is exactly the time that the clock shifted in some reports causing some data to be in the “today” bucket and other data in the “yesterday” bucket.&lt;/p&gt;
&lt;p&gt;This meant that if we chucked data into the database and asked the reports to “bucket” it the test would return incorrect numbers at very specific times during the day. This is incredibly frustrating and not particularly fair on Australia that have to bear the brunt.&lt;/p&gt;
&lt;p&gt;An example &lt;a href=&quot;https://review.discourse.org/t/dev-correct-heisentest-run-report-at-consistent-time/1857&quot;&gt;is here&lt;/a&gt; (though the same code went through multiple iterations previously to battle this).&lt;/p&gt;
&lt;p&gt;The general solution we have for the majority of these issues is simply to play pretend with time. Test pretends it is 1PM UTC in 2018, then does something, winds clock forward a bit and so on. We use our &lt;a href=&quot;https://github.com/discourse/discourse/blob/master/spec/rails_helper.rb#L332-L368&quot;&gt;freeze time&lt;/a&gt; helper in Ruby and &lt;a href=&quot;https://sinonjs.org/&quot;&gt;Sinon.JS&lt;/a&gt; in JavaScript. Many other solutions exist including &lt;a href=&quot;https://github.com/travisjeffery/timecop&quot;&gt;timecop&lt;/a&gt;, the fascinating &lt;a href=&quot;https://github.com/wolfcw/libfaketime&quot;&gt;libfaketime&lt;/a&gt; and many more.&lt;/p&gt;
&lt;p&gt;Other examples I have seen are cases where &lt;code&gt;sleep&lt;/code&gt; is involved:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;sleep 0.001
assert(elapsed &amp;lt; 1) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It may seem obvious that that I slept for 1 millisecond, clearly less than 1 second passed. But this obvious assumption can be incorrect sometimes. Machines can be under extreme load causing CPU scheduling holdups.&lt;/p&gt;
&lt;p&gt;Another time related issue we have experienced is insufficient timeouts, this has plagued our JS test suite. Many integration tests we have rely on sequences of events; click button, then check for element on screen. As a safeguard we like introducing some sort of timeout so the JS test suite does not hang forever waiting for an element to get rendered in case of bugs. Getting the actual timeout duration right is tricky. On a super taxed AWS instance that Travis CI provides much longer timeouts are needed. This issue sometimes is intertwined with other factors, a resource leak may cause JS tests to slowly require longer and longer time.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;leaky-global-state-6&quot; class=&quot;anchor&quot; href=&quot;#leaky-global-state-6&quot;&gt;&lt;/a&gt;Leaky global state&lt;/h3&gt;
&lt;p&gt;For tests to work consistently they often rely on pristine initial state.&lt;/p&gt;
&lt;p&gt;If a test amends global variables and does not reset back to the original state it can cause flakiness.&lt;/p&gt;
&lt;p&gt;An example of such a spec &lt;a href=&quot;https://review.discourse.org/t/fix-prevents-other-tests-from-leaking-modified-theme-color-7051/1837&quot;&gt;is here&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;class Frog
   cattr_accessor :total_jumps
   attr_accessor :jumps

   def jump
     Frog.total_jumps = (Frog.total_jumps || 0) + 1
     self.jumps = (self.jumps || 0) + 1
   end
end

# works fine as long as this is the first test
def test_global_tracking
   assert(Frog.total_jumps.nil?)
end

def test_jumpy
   frog = Frog.new
   frog.jump
   assert(frog.jumps == 1)
end 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run &lt;code&gt;test_jumpy&lt;/code&gt; first and then &lt;code&gt;test_global_tracking&lt;/code&gt; fails. Other way around works.&lt;/p&gt;
&lt;p&gt;We tend to hit these types of failures due to distributed caching we use and various other global registries that the tests interact with. It is a balancing act cause on one hand we want our application to be fast so we cache a lot of state and on the other hand we don’t want an unstable test suite or a test suite unable to catch regressions.&lt;/p&gt;
&lt;p&gt;To mitigate we always run our test suite in random order (which makes it easy to pick up order dependent tests). We have lots of common clean up code to avoid the situations &lt;a href=&quot;https://github.com/discourse/discourse/blob/678a9a61c425d52b4a1cd317b36f994bed824461/spec/rails_helper.rb#L101-L118&quot;&gt;developers hit most frequently&lt;/a&gt;.  There is a balancing act, our clean up routines can not become so extensive that they cause major slowdown to our test suite.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;bad-assumptions-about-the-environment-7&quot; class=&quot;anchor&quot; href=&quot;#bad-assumptions-about-the-environment-7&quot;&gt;&lt;/a&gt;Bad assumptions about the environment&lt;/h3&gt;
&lt;p&gt;It is quite unlikely you would have a test like this in your test suite.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;def test_disk_space
   assert(free_space_on('/') &amp;gt; 1.gigabyte)
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That said, hidden more deeply in your code you could have routines that behaves slightly differently depending on specific machine state.&lt;/p&gt;
&lt;p&gt;A specific example we had &lt;a href=&quot;https://review.discourse.org/t/correct-flaky-spec/3434?u=samsaffron&quot;&gt;is here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We had a test that was checking the internal implementation of our process for downloading images from a remote source. However, we had a safeguard in place that ensured this only happened if there was ample free space on the machine. Not allowing for this in the test meant that if you ran our test suite on a machine strained for disk space tests would start failing.&lt;/p&gt;
&lt;p&gt;We have various safeguards in our code that could depend on environment and need to make sure we account for them when writing tests.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;concurrency-8&quot; class=&quot;anchor&quot; href=&quot;#concurrency-8&quot;&gt;&lt;/a&gt;Concurrency&lt;/h3&gt;
&lt;p&gt;Discourse contains a few subsystems that depend on threading. The &lt;a href=&quot;https://github.com/SamSaffron/message_bus&quot;&gt;MessageBus&lt;/a&gt; that powers live updates on the site, cache synchronization and more uses a background thread to listen on a Redis channel. Our short lived &lt;a href=&quot;https://github.com/discourse/discourse/blob/b98b994fe76593599c88f00e2723f93232c67158/lib/scheduler/defer.rb&quot;&gt;“defer”&lt;/a&gt; queue powers extremely short lived non-critical tasks that can run between requests and hijacked controller actions that tend to wait long times on IO (a single unicorn worker can sometimes serve 10s or even 100s of web requests in our setup). Our &lt;a href=&quot;https://github.com/discourse/mini_scheduler&quot;&gt;background scheduler&lt;/a&gt; handles recurring jobs.&lt;/p&gt;
&lt;p&gt;An example &lt;a href=&quot;https://review.discourse.org/t/correct-erratic-spec/3442?u=samsaffron&quot;&gt;would be here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Overall, this category is often extremely difficult to debug. In some cases we simply disable components in test mode to ensure consistency, the defer queue runs inline. We also evict threaded component out of our big monolith. I find it significantly simpler to work through and repair a concurrent test suite for a gem that takes 5 seconds to run vs repairing a sub-section in a giant monolith that has a significantly longer run time.&lt;/p&gt;
&lt;p&gt;Other tricks I have used is simulating an event loop, pulsing it in tests simulating multiple threads in a single thread. Joining threads that do work and waiting for them to terminate and &lt;a href=&quot;https://tenderlovemaking.com/2016/02/05/i-am-a-puts-debuggerer.html&quot;&gt;lots of &lt;code&gt;puts&lt;/code&gt; debugging&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;resource-leaks-9&quot; class=&quot;anchor&quot; href=&quot;#resource-leaks-9&quot;&gt;&lt;/a&gt;Resource leaks&lt;/h3&gt;
&lt;p&gt;Our JavaScript test suite integration tests have been amongst the most difficult tests to stabilise. They cover large amounts of code in the application and require Chrome web driver to run. If you forget to properly clean up a few event handlers, over thousands of tests this can lead to leaks that make fast tests gradually become very slow or even break inconsistently.&lt;/p&gt;
&lt;p&gt;To work through these issues we look at using v8 heap dumps after tests, monitoring memory usage of chrome after the test suite runs.&lt;/p&gt;
&lt;p&gt;It is important to note that often these kind of problems can lead to a confusing state where tests consistently work on production CI yet consistently fail on resource strained Travis CI environment.&lt;/p&gt;
&lt;h2&gt;
&lt;a name=&quot;mitigation-patterns-10&quot; class=&quot;anchor&quot; href=&quot;#mitigation-patterns-10&quot;&gt;&lt;/a&gt;Mitigation patterns&lt;/h2&gt;
&lt;p&gt;Over the years we have learned quite a few strategies you can adopt to help grapple with this problem. Some involve coding, others involve discussion. Arguably the most important first step is admitting you have a problem, and as a team, deciding how to confront it.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;start-an-honest-discussion-with-your-team-11&quot; class=&quot;anchor&quot; href=&quot;#start-an-honest-discussion-with-your-team-11&quot;&gt;&lt;/a&gt;Start an honest discussion with your team&lt;/h3&gt;
&lt;p&gt;How should you deal with flaky tests? You could keep running them until they pass. You could delete them. You could quarantine and fix them. You could ignore this is happening.&lt;/p&gt;
&lt;p&gt;At Discourse we opted to quarantine and fix. Though to be completely honest, at some points we ignored and we considered just deleting.&lt;/p&gt;
&lt;p&gt;I am not sure there is a perfect solution here.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/wastebasket.png?v=12&quot; title=&quot;:wastebasket:&quot; class=&quot;emoji&quot; alt=&quot;:wastebasket:&quot; loading=&quot;lazy&quot; width=&quot;20&quot; height=&quot;20&quot;&gt;  &lt;strong&gt;“Deleting and forgetting”&lt;/strong&gt; can save money at the expense of losing a bit of test coverage and potential app bug fixes. If your test suite gets incredibly erratic, this kind of approach could get you back to happy state. As developers we are often quick to judge and say “delete and forget” is a terrible approach, it sure is drastic and some would judge this to be lazy and dangerous. However, if budgets are super tight this may be the only option you have. I think there is a very strong argument to say a test suite of 100 tests that passes 100% of the time when you rerun it against the same code base is better than a test suite of 200 tests where passing depends on a coin toss.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/recycle.png?v=12&quot; title=&quot;:recycle:&quot; class=&quot;emoji&quot; alt=&quot;:recycle:&quot; loading=&quot;lazy&quot; width=&quot;20&quot; height=&quot;20&quot;&gt;  &lt;strong&gt;“Run until it passes”&lt;/strong&gt; is another approach. It is an attempt to have the cake and eat it at the same time. You get to keep your build “green” without needing to fix flaky tests. Again, it can be considered somewhat “lazy”. The downside is that this approach may leave broken application code in place and make the test suite slower due to repeat test runs. Also, in some cases, “run until it passes” may fail on CI consistently and work on local consistently. How many retries do you go for? 2? 10?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/man_shrugging/4.png?v=12&quot; title=&quot;:man_shrugging:t4:&quot; class=&quot;emoji&quot; alt=&quot;:man_shrugging:t4:&quot; loading=&quot;lazy&quot; width=&quot;20&quot; height=&quot;20&quot;&gt;   &lt;strong&gt;“Do nothing”&lt;/strong&gt; which sounds shocking to many, is actually surprisingly common. It is super hard to let go of tests you spent time carefully writing. &lt;a href=&quot;https://en.wikipedia.org/wiki/Loss_aversion&quot;&gt;Loss aversion&lt;/a&gt; is natural and means for many the idea of losing a test may just be too much to cope with. Many just say “the build is a flake, it sometimes fails” and kick it off again. I have done this in the past. Fixing flaky tests can be very very hard. In some cases where there is enormous amounts of environment at play and huge amounts of surface area, like large scale full application integration tests hunting for the culprit is like searching for a needle in a haystack.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/biohazard.png?v=12&quot; title=&quot;:biohazard:&quot; class=&quot;emoji&quot; alt=&quot;:biohazard:&quot; loading=&quot;lazy&quot; width=&quot;20&quot; height=&quot;20&quot;&gt;  &lt;strong&gt;“Quarantine and fix”&lt;/strong&gt; is my favourite general approach. You “skip” the test and have the test suite keep reminding you that a test was skipped. You lose coverage temporarily until you get around to fixing the test.&lt;/p&gt;
&lt;p&gt;There is no, one size fits all. Even at Discourse we sometimes live between the worlds of “Do nothing” and “Quarantine and fix”.&lt;/p&gt;
&lt;p&gt;That said, having an internal discussion about what you plan to do with flaky tests is &lt;strong&gt;critical&lt;/strong&gt;. It is possible you are doing something now you don’t even want to be doing, it could be behaviour that evolved.&lt;/p&gt;
&lt;p&gt;Talking about the problem gives you a fighting chance.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;if-the-build-is-not-green-nothing-gets-deployed-12&quot; class=&quot;anchor&quot; href=&quot;#if-the-build-is-not-green-nothing-gets-deployed-12&quot;&gt;&lt;/a&gt;If the build is not green nothing gets deployed&lt;/h3&gt;
&lt;p&gt;At Discourse we adopted continuous deployment many years ago. This is our final shield. Without this shield our test suite could have gotten so infected it would likely be useless now.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;always-run-tests-in-random-order-13&quot; class=&quot;anchor&quot; href=&quot;#always-run-tests-in-random-order-13&quot;&gt;&lt;/a&gt;Always run tests in random order&lt;/h3&gt;
&lt;p&gt;From the very early days of Discourse we opted to run our tests in random order, this exposes order dependent flaky tests. By logging the random seed used to randomise the tests you can always reproduce a failed test suite that is order dependent.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;sadly-rspec-bisect-has-been-of-limited-value-14&quot; class=&quot;anchor&quot; href=&quot;#sadly-rspec-bisect-has-been-of-limited-value-14&quot;&gt;&lt;/a&gt;Sadly &lt;code&gt;rspec bisect&lt;/code&gt; has been of limited value&lt;/h3&gt;
&lt;p&gt;One assumption that is easy to make when presented with flaky tests, is that they are all order dependent. Order dependent flaky tests are pretty straightforward to reproduce. You do a binary search reducing the amount of tests you run but maintain order until you find a minimal reproduction. Say test &lt;span class=&quot;hashtag&quot;&gt;#1200&lt;/span&gt; fails with seed 7, after a bit of automated magic you can figure out that the sequence &lt;span class=&quot;hashtag&quot;&gt;#22&lt;/span&gt;,&lt;span class=&quot;hashtag&quot;&gt;#100&lt;/span&gt;,&lt;span class=&quot;hashtag&quot;&gt;#1200&lt;/span&gt; leads to this failure. In theory this works great but there are 2 big pitfalls to watch out for.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;You may have not unrooted all your flaky tests, if the binary search triggers a different non-order dependent test failure, the whole process can fail with very confusing results.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;From our experience with our code base the majority of our flaky tests are not order dependent. So this is usually an expensive wild goose chase.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;
&lt;a name=&quot;continuously-hunt-for-flaky-tests-15&quot; class=&quot;anchor&quot; href=&quot;#continuously-hunt-for-flaky-tests-15&quot;&gt;&lt;/a&gt;Continuously hunt for flaky tests&lt;/h3&gt;
&lt;p&gt;Recently &lt;a href=&quot;https://github.com/romanrizzi&quot;&gt;Roman Rizzi&lt;/a&gt; introduced a new system to hunt for flaky tests at Discourse. We run our test suite in a tight loop, over and over again on a cloud server. Each time tests fail we flag them and at the end of a week of continuous running we mark flaky specs as “skipped” pending repair.&lt;/p&gt;
&lt;p&gt;This mechanism increased test suite stability. Some flaky specs may only show up 1 is 1000 runs. At snail pace, when running tests once per commit, it can take a very long time to find these rare flakes.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;quarantine-flaky-tests-16&quot; class=&quot;anchor&quot; href=&quot;#quarantine-flaky-tests-16&quot;&gt;&lt;/a&gt;Quarantine flaky tests&lt;/h3&gt;
&lt;p&gt;This brings us to one of the most critical tools at your disposal. “Skipping” a flaky spec is a completely reasonable approach. There are though a few questions you should explore:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Is the environment flaky and not the test? Maybe you have a memory leak and the test that failed just hit a threshold?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Can you decide with confidence using some automated decision metric that a test is indeed flaky&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is a bit of “art” here and much depends on your team and your comfort zone. My advice here though would be to be more aggressive about quarantine. There are quite a few tests over the years I wish we quarantined earlier, which cause repeat failures.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;run-flaky-tests-in-a-tight-loop-randomizing-order-to-debug-17&quot; class=&quot;anchor&quot; href=&quot;#run-flaky-tests-in-a-tight-loop-randomizing-order-to-debug-17&quot;&gt;&lt;/a&gt;Run flaky tests in a tight loop randomizing order to debug&lt;/h3&gt;
&lt;p&gt;One big issue with flaky tests is that quite often they are very hard to reproduce. To accelerate a repro I tend to try running a flaky test in a loop.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;100.times do
   it &quot;should not be a flake&quot; do
      yet_it_is_flaky
   end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This simple technique can help immensely finding all sorts of flaky tests. Sometimes it makes sense to have multiple tests in this tight loop, sometimes it makes sense to drop the database and Redis and start from scratch prior to running the tight loop.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;invest-in-a-fast-test-suite-18&quot; class=&quot;anchor&quot; href=&quot;#invest-in-a-fast-test-suite-18&quot;&gt;&lt;/a&gt;Invest in a fast test suite&lt;/h3&gt;
&lt;p&gt;For years at Discourse we have invested in speeding up to our test suite. There is a balancing act though, on one hand the best tests you have are integration tests that cover large amounts of application code. You do not want the quest for speed to compromise the quality of your test suite. That said there is often large amount of pointless repeat work that can be eliminated.&lt;/p&gt;
&lt;p&gt;A fast test suite means&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is faster for you to find flaky tests&lt;/li&gt;
&lt;li&gt;It is faster for you to debug flaky tests&lt;/li&gt;
&lt;li&gt;Developers are more likely to run the full test suite while building pieces triggering flaky tests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the moment Discourse has 11,000 or so Ruby tests it takes them 5m40s to run single threaded on my PC and 1m15s or so to run tests concurrently.&lt;/p&gt;
&lt;p&gt;Getting to this speed involves a regular amount of “speed maintenance”. Some very interesting recent things we have done:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/danielwaterworth&quot;&gt;Daniel Waterworth&lt;/a&gt; introduced &lt;a href=&quot;https://github.com/palkan/test-prof&quot;&gt;test-prof&lt;/a&gt; into our test suite and refined a large amount of tests to use: the &lt;a href=&quot;https://github.com/palkan/test-prof/blob/master/docs/let_it_be.md&quot;&gt;let_it_be&lt;/a&gt; helper it provides (&lt;a href=&quot;https://github.com/discourse/discourse/pull/7414&quot;&gt;which we call &lt;code&gt;fab!&lt;/code&gt;&lt;/a&gt; cause it is awesome and it fabricates). Prefabrication can provide many of the speed benefits you get from fixtures without inheriting the many of the limitations fixtures prescript.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/davidtaylorhq&quot;&gt;David Taylor&lt;/a&gt; introduced the &lt;a href=&quot;https://github.com/grosser/parallel_tests&quot;&gt;parallel tests&lt;/a&gt; gem which we use to run our test suite concurrently saving me 4 minutes or so each time I run the full test suite. Built-in parallel testing is coming to Rails 6 thanks to work by &lt;a href=&quot;https://twitter.com/eileencodes&quot;&gt;Eileen M. Uchitelle&lt;/a&gt; and the Rails core team.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On top of this the entire team have committed numerous improvements to the test suite with the purpose of speeding it up. It remains a priority.&lt;/p&gt;
&lt;h3&gt;
&lt;a name=&quot;add-purpose-built-diagnostic-code-to-debug-flaky-tests-you-can-not-reproduce-19&quot; class=&quot;anchor&quot; href=&quot;#add-purpose-built-diagnostic-code-to-debug-flaky-tests-you-can-not-reproduce-19&quot;&gt;&lt;/a&gt;Add purpose built diagnostic code to debug flaky tests you can not reproduce&lt;/h3&gt;
&lt;p&gt;A final trick I tend to use when debugging flaky tests is adding debug code.&lt;/p&gt;
&lt;p&gt;An &lt;a href=&quot;https://review.discourse.org/t/dev-add-diagnostics-to-erratic-test/3087?u=samsaffron&quot;&gt;example is here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Sometimes, I have no luck reproducing locally no matter how hard I try. Diagnostic code means that if the flaky test gets triggered again I may have a fighting chance figuring out what state caused it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;def test_something
   make_happy(user)
   if !user.happy
      STDERR.puts &quot;#{user.inspect}&quot;
   end
    assert(user.happy)
end
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;
&lt;a name=&quot;lets-keep-the-conversation-going-20&quot; class=&quot;anchor&quot; href=&quot;#lets-keep-the-conversation-going-20&quot;&gt;&lt;/a&gt;Let’s keep the conversation going!&lt;/h2&gt;
&lt;p&gt;Do you have any interesting flaky test stories? What is your team’s approach for dealing with the problem? I would love to hear more so please join the discussion on this blog post.&lt;/p&gt;
&lt;h2&gt;
&lt;a name=&quot;extra-reading-21&quot; class=&quot;anchor&quot; href=&quot;#extra-reading-21&quot;&gt;&lt;/a&gt;Extra reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://martinfowler.com/articles/nonDeterminism.html&quot;&gt; Eradicating Non-Determinism in Tests&lt;/a&gt; by Martin Fowler&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://testing.googleblog.com/2017/04/where-do-our-flaky-tests-come-from.html&quot;&gt;Google: Where do our flaky tests come from?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;http://mir.cs.illinois.edu/marinov/publications/LuoETAL14FlakyTestsAnalysis.pdf&quot;&gt;An Empirical Analysis of Flaky Tests (pdf)&lt;/a&gt; - Qingzhou Luo, Farah Hariri, Lamyaa Eloussi, Darko Marinov&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/devops/learn/devops-at-microsoft/eliminating-flaky-tests&quot;&gt;Microsoft: Eliminating Flaky tests&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.gitlab.com/ee/development/testing_guide/flaky_tests.html&quot;&gt;Flaky tests at GitLab&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;http://taoxie.cs.illinois.edu/publications/icst19-idflakies.pdf&quot;&gt;iDFlakies: A Framework for Detecting and Partially Classifying Flaky Tests&lt;/a&gt; by Wing Lam, Reed Oei, August Shi, Darko Marinov, Tao Xie&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
      <pubDate>Tue, 28 May 2019 06:54:25 +0000</pubDate>
      <link>https://samsaffron.com/archive/2019/05/15/tests-that-sometimes-fail</link>
    </item>
    <item>
      <title>My i3 window manager setup</title>
      <description>
&lt;p&gt;I have been a long time &lt;a href=&quot;https://i3wm.org/&quot;&gt;i3 window manager&lt;/a&gt; user. But not really.&lt;/p&gt;
&lt;p&gt;My old &lt;a href=&quot;https://samsaffron.com/archive/2019/03/31/why-i-stuck-with-windows-for-6-years-while-developing-discourse&quot;&gt;Windows 10&lt;/a&gt; based setup involved doing all my console work in an Ubuntu VM running i3. However, the lion’s share of the non console work was still done in Windows, including browsing and more.&lt;/p&gt;
&lt;p&gt;For multiple years now I only partially experienced i3, it showed. My i3 setup was almost vanilla.&lt;/p&gt;
&lt;p&gt;My move to &lt;a href=&quot;https://www.archlinux.org/&quot;&gt;Arch Linux&lt;/a&gt; changed everything.&lt;/p&gt;
&lt;p&gt;This move completely shifted the way I think about my relationship with my desktop environment. Previously, my relationship with Windows was very simplistic. Windows works the way it works,  I simply adapted to that. Sometimes I learned a new shortcut, but the majority of my Windows day-to-day involved dragging windows around, reaching Firefox window and tab saturation, closing windows with the mouse and so on.&lt;/p&gt;
&lt;p&gt;I am not a great example of a Windows ninja some users go down a &lt;a href=&quot;https://github.com/fuhsjr00/bug.n&quot;&gt;far more custom path&lt;/a&gt;. I do feel I am pretty typical though of a developer using Windows or Mac. I was given a menu, I learned a tiny bit of it, then I simply threw away the menu and reached for the mouse.&lt;/p&gt;
&lt;p&gt;In this blog post I would like to talk about what my 3.5 week adventure has looked like and where I am today!&lt;/p&gt;
&lt;h2&gt;Opening moves&lt;/h2&gt;
&lt;p&gt;When I moved to Linux I did not know much of the current state of Linux on the desktop but I did know 2 things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I would be using Arch Linux&lt;/li&gt;
&lt;li&gt;I would be using the i3 tiling window manager&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I opted for Arch cause I love not having to worry about upgrading my system every 6-12 months to another major release, I think &lt;a href=&quot;https://wiki.archlinux.org/index.php/Pacman&quot;&gt;pacman&lt;/a&gt; and the package library on Arch is amazing, if I ever am missing tiny bits from the official library it is trivial for me to just &lt;a href=&quot;https://github.com/Jguer/yay&quot;&gt;grab a package&lt;/a&gt; from the very comprehensive &lt;a href=&quot;https://aur.archlinux.org/&quot;&gt;AUR&lt;/a&gt;. I also think the documentation in the Arch wiki is fantastic and it helped me enormously.&lt;/p&gt;
&lt;p&gt;I opted for i3 cause I wanted to fully experience the window manager, not treat it as a glorified &lt;a href=&quot;https://github.com/tmux/tmux&quot;&gt;tmux&lt;/a&gt; like I was for years.&lt;/p&gt;
&lt;p&gt;A day or so into my move I was uncomfortable with the way my stock install looked and acted, I quickly learned about the &lt;a href=&quot;https://www.reddit.com/r/unixporn/&quot;&gt;r/unixporn reddit&lt;/a&gt; and this movement called “&lt;a href=&quot;https://www.reddit.com/r/unixporn/comments/3iy3wd/stupid_question_what_is_ricing/&quot;&gt;Ricing&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;During the first few days I watched a fair bit of youtube to see what others are doing.&lt;/p&gt;
&lt;p&gt;I can recommend:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&quot;https://www.youtube.com/watch?v=ARKIwOlazKI&amp;amp;t=1042s&quot;&gt;3 part series&lt;/a&gt; by code cast on i3. Especially the last one.&lt;/li&gt;
&lt;li&gt;Ethan Schoonover &lt;a href=&quot;https://www.youtube.com/watch?v=70IxjLEmomg&quot;&gt;excellent xmonad demo&lt;/a&gt; - If you have not seen this yet I recommend you stop reading and go watch it.&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;https://www.youtube.com/watch?v=Api6dFMlxAA&quot;&gt;Aline Abler course&lt;/a&gt; on tiling window managers&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;My basic ricing&lt;/h2&gt;
&lt;p&gt;I totally get that lots of people love &lt;a href=&quot;https://wiki.archlinux.org/index.php/Dmenu&quot;&gt;dmenu&lt;/a&gt; people get it to do all sorts of amazing things like mount drives, select monitors and pick files. It is a very powerful and in true suckless fashion minimal tool.&lt;/p&gt;
&lt;p&gt;I opted to swap out my dmenu with &lt;a href=&quot;https://github.com/davatorium/rofi&quot;&gt;rofi&lt;/a&gt; which I seem to like a bit more. It looks like this:&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/e/e702770f8a6e824d5967b4ac7133d8be4dddc9ba.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/e702770f8a6e824d5967b4ac7133d8be4dddc9ba&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/e/e702770f8a6e824d5967b4ac7133d8be4dddc9ba_2_690x146.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;wXBzMjyiVhFT9VpHzyupkh5dxc6&quot; width=&quot;690&quot; height=&quot;146&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/e/e702770f8a6e824d5967b4ac7133d8be4dddc9ba_2_690x146.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/e/e702770f8a6e824d5967b4ac7133d8be4dddc9ba_2_1035x219.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/e/e702770f8a6e824d5967b4ac7133d8be4dddc9ba_2_1380x292.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/e/e702770f8a6e824d5967b4ac7133d8be4dddc9ba_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1919×407 31.4 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;I prefer the positioning and really like the combi menu that allows me to also navigate through my open windows. rofi works in a dmenu mode as well so I can just use it interchangeably.&lt;/p&gt;
&lt;p&gt;I also used &lt;a href=&quot;https://www.archlinux.org/packages/community/x86_64/lxappearance/&quot;&gt;LXApperance&lt;/a&gt;  for some very rudimentary themeing in particular I do like the &lt;a href=&quot;https://aur.archlinux.org/packages/otf-san-francisco/&quot;&gt;Apple San Fransico font&lt;/a&gt; that I use for my window titles:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/6/6feb9489e12a15031f5fb073c8658b2d2be85e0d.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;fY5J6DlB7Au45tWQqtSTpY5imYJ&quot; width=&quot;192&quot; height=&quot;49&quot;&gt;&lt;/p&gt;
&lt;p&gt;I also set up a basic &lt;a href=&quot;https://github.com/morhetz/gruvbox&quot;&gt;gruvbox&lt;/a&gt; theme for my urxvt terminal and was careful to grab &lt;a href=&quot;https://aur.archlinux.org/packages/rxvt-unicode-truecolor/&quot;&gt;the fork with 24 bit color support&lt;/a&gt; so everything looks just right. Initially I tried out &lt;a href=&quot;https://wiki.archlinux.org/index.php/Terminator&quot;&gt;terminator&lt;/a&gt; but find urxvt a bit “lighter” that said, I may try out &lt;a href=&quot;https://wiki.archlinux.org/index.php/St&quot;&gt;st&lt;/a&gt; next.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/3/3f5f64fc7e1f4aa1e04f8c86d511fb07ca53ea37.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/3f5f64fc7e1f4aa1e04f8c86d511fb07ca53ea37&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/3/3f5f64fc7e1f4aa1e04f8c86d511fb07ca53ea37_2_517x267.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;92CsFklgziGkJt4F8xgbofLwCkT&quot; width=&quot;517&quot; height=&quot;267&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/3/3f5f64fc7e1f4aa1e04f8c86d511fb07ca53ea37_2_517x267.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/3/3f5f64fc7e1f4aa1e04f8c86d511fb07ca53ea37_2_775x400.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/3/3f5f64fc7e1f4aa1e04f8c86d511fb07ca53ea37_2_1034x534.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/3/3f5f64fc7e1f4aa1e04f8c86d511fb07ca53ea37_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1273×659 75.8 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Finally I swapped out &lt;a href=&quot;https://github.com/i3/i3status&quot;&gt;i3status&lt;/a&gt; with &lt;a href=&quot;https://github.com/greshake/i3status-rust&quot;&gt;i3status-rust&lt;/a&gt;. It shows me weather, volume, network and cpu speed and pending update count. I really enjoy it.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/d/df4b48a851cc47bce137d4c5a7636ee21bcca2a1.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/df4b48a851cc47bce137d4c5a7636ee21bcca2a1&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/d/df4b48a851cc47bce137d4c5a7636ee21bcca2a1_2_690x17.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;vRlLMKBJZlsIQ1nQuVM5KMHORYB&quot; width=&quot;690&quot; height=&quot;17&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/d/df4b48a851cc47bce137d4c5a7636ee21bcca2a1_2_690x17.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/d/df4b48a851cc47bce137d4c5a7636ee21bcca2a1_2_1035x25.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/d/df4b48a851cc47bce137d4c5a7636ee21bcca2a1_2_1380x34.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/d/df4b48a851cc47bce137d4c5a7636ee21bcca2a1_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1959×50 13.5 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;My ricing is very basic, I don’t like wallpapers, I don’t like transparency and am unsure if I would even like to try gaps or not.&lt;/p&gt;
&lt;h2&gt;A tiny note on mod keys&lt;/h2&gt;
&lt;p&gt;A large amount of i3 configuration relies on using a &lt;code&gt;mod&lt;/code&gt; key. The &lt;code&gt;mod&lt;/code&gt; key is mapped by end users to an appropriate key that &lt;em&gt;does not get in the way&lt;/em&gt; with other keyboard bindings other programs use.&lt;/p&gt;
&lt;p&gt;In my case I map &lt;code&gt;mod&lt;/code&gt; to both the &lt;code&gt;Windows&lt;/code&gt; key and the right &lt;code&gt;Menu&lt;/code&gt; key. I do the menu key mapping by running &lt;code&gt;exec_always --no-startup-id xmodmap -e &quot;keysym Menu = Super_R&quot;&lt;/code&gt; in my config file.&lt;/p&gt;
&lt;p&gt;The tool I used for displaying keys on this blog post (the amazing &lt;a href=&quot;https://gitlab.com/wavexx/screenkey&quot;&gt;screenkey&lt;/a&gt;) calls the Windows key &lt;code&gt;Super&lt;/code&gt; which is the Linuxey name. I can rename it to mod, but I am already multiple screenshots in.&lt;/p&gt;
&lt;p&gt;For the purpose of this blog post. &lt;code&gt;Mod&lt;/code&gt; == &lt;code&gt;Super&lt;/code&gt; == &lt;code&gt;Windows Keyboard key&lt;/code&gt;. I will be calling this key &lt;code&gt;Super&lt;/code&gt; from here downwards.&lt;/p&gt;
&lt;h2&gt;Easy editing of Discourse&lt;/h2&gt;
&lt;p&gt;When I moved to i3 proper I set myself the goal to eliminate trivialities. I observed things that I kept on doing inefficiently and optimized my setup.&lt;/p&gt;
&lt;p&gt;I found that in the past every time I wanted to hack on Discourse I would&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open a terminal&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd Source/discourse&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;open nvim&lt;/li&gt;
&lt;li&gt;split the window&lt;/li&gt;
&lt;li&gt;open nerdtree&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This flow involved lots of steps which can easily be automated:&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/1/1a930d04eefe3ec11db6f42940f80cd3f8ed50c3.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/1a930d04eefe3ec11db6f42940f80cd3f8ed50c3&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/1/1a930d04eefe3ec11db6f42940f80cd3f8ed50c3_2_517x291.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;3N5t5KJMjyLc1EghLkmkuJfe6pZ&quot; width=&quot;517&quot; height=&quot;291&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/1/1a930d04eefe3ec11db6f42940f80cd3f8ed50c3_2_517x291.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/1/1a930d04eefe3ec11db6f42940f80cd3f8ed50c3_2_775x436.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/1/1a930d04eefe3ec11db6f42940f80cd3f8ed50c3_2_1034x582.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/1/1a930d04eefe3ec11db6f42940f80cd3f8ed50c3_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;3840×2160 79.9 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;I now hit &lt;code&gt;Super&lt;/code&gt; + &lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;D&lt;/code&gt; and tada Discourse opens.&lt;/p&gt;
&lt;p&gt;This is done by adding this to my i3 config:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bindsym $mod+Shift+d exec &quot;i3-sensible-terminal -e '/home/sam/.i3/edit_discourse'&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And this tiny shell script&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;sam@arch .i3 % cat edit_discourse 
#!/bin/zsh

cd /home/sam/Source/discourse
exec nvim -c ':NERDTree|:wincmd w|:vsplit'
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Smart window centering&lt;/h2&gt;
&lt;p&gt;Even though i3 is a “tiled” window manager. Some windows… I prefer in floating mode. In particular I like having Firefox in floating mode.&lt;/p&gt;
&lt;p&gt;I like having Firefox in the middle of my center monitor at very particular dimensions. I do sometimes drag it around but it is nice to “reset” the position.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/b/bd35e9b2b3dee39d926eb9112024862e2a4fbf18.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/bd35e9b2b3dee39d926eb9112024862e2a4fbf18&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/b/bd35e9b2b3dee39d926eb9112024862e2a4fbf18_2_345x194.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;qZPKtYCm94O0EIQ72WZX8XEsq3S&quot; width=&quot;345&quot; height=&quot;194&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/b/bd35e9b2b3dee39d926eb9112024862e2a4fbf18_2_345x194.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/b/bd35e9b2b3dee39d926eb9112024862e2a4fbf18_2_517x291.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/b/bd35e9b2b3dee39d926eb9112024862e2a4fbf18_2_690x388.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/b/bd35e9b2b3dee39d926eb9112024862e2a4fbf18_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;3840×2160 34.8 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/5/5f6a7e7746ad39ebaf403e4d9cee6fe203655001.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/5f6a7e7746ad39ebaf403e4d9cee6fe203655001&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/5/5f6a7e7746ad39ebaf403e4d9cee6fe203655001_2_345x194.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;dC5wmLtYXgIl4EFZShDtPA29oVX&quot; width=&quot;345&quot; height=&quot;194&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/5/5f6a7e7746ad39ebaf403e4d9cee6fe203655001_2_345x194.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/5/5f6a7e7746ad39ebaf403e4d9cee6fe203655001_2_517x291.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/5/5f6a7e7746ad39ebaf403e4d9cee6fe203655001_2_690x388.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/5/5f6a7e7746ad39ebaf403e4d9cee6fe203655001_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;3840×2160 45.5 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Sometimes I like it a bit wider, so I hit &lt;code&gt;Super&lt;/code&gt; + &lt;code&gt;c&lt;/code&gt; again.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/f/feee7a767513e0cade4c26e42b5b2fd7e1d0e9b2.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/feee7a767513e0cade4c26e42b5b2fd7e1d0e9b2&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/f/feee7a767513e0cade4c26e42b5b2fd7e1d0e9b2_2_345x194.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;AnedkDl4izhHEORLoZ0v4Jw0Wc2&quot; width=&quot;345&quot; height=&quot;194&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/f/feee7a767513e0cade4c26e42b5b2fd7e1d0e9b2_2_345x194.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/f/feee7a767513e0cade4c26e42b5b2fd7e1d0e9b2_2_517x291.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/f/feee7a767513e0cade4c26e42b5b2fd7e1d0e9b2_2_690x388.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/f/feee7a767513e0cade4c26e42b5b2fd7e1d0e9b2_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;3840×2160 44.8 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;And sometimes I like it a tiny bit wider, so I hit &lt;code&gt;Super+c&lt;/code&gt; again.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/6/6b881ce40badc3f3496a4857f5330712192d11c1.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/6b881ce40badc3f3496a4857f5330712192d11c1&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/6b881ce40badc3f3496a4857f5330712192d11c1_2_345x194.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;flgI0ptmShgWKzaoExu4FB1qmY1&quot; width=&quot;345&quot; height=&quot;194&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/6b881ce40badc3f3496a4857f5330712192d11c1_2_345x194.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/6/6b881ce40badc3f3496a4857f5330712192d11c1_2_517x291.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/6/6b881ce40badc3f3496a4857f5330712192d11c1_2_690x388.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/6b881ce40badc3f3496a4857f5330712192d11c1_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;3840×2160 45 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;If I hit &lt;code&gt;Super&lt;/code&gt; + &lt;code&gt;c&lt;/code&gt; yet again it is back to square one and window is small centered.&lt;/p&gt;
&lt;p&gt;I achieve this by having this in my i3 file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;bindsym $mod+c exec &quot;/home/sam/.i3/i3-plus smart_center 1830x2100,2030x2100,2230x2100&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The little &lt;code&gt;i3-plus&lt;/code&gt; utility is a work-in-progress Ruby utility I have that interacts with the &lt;a href=&quot;https://i3wm.org/docs/ipc.html&quot;&gt;i3 IPC&lt;/a&gt; so it can make smart decisions about what to do. You can find the source for it &lt;a href=&quot;https://github.com/samsaffron/dotfiles&quot;&gt;in my dotfiles&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The basic logic being:&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://github.com/SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L185-L200&quot; target=&quot;_blank&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L185-L200&quot; target=&quot;_blank&quot;&gt;SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L185-L200&lt;/a&gt;&lt;/h4&gt;
&lt;pre class=&quot;onebox&quot;&gt;&lt;code class=&quot;lang-&quot;&gt;&lt;ol class=&quot;start lines&quot; start=&quot;185&quot; style=&quot;counter-reset: li-counter 184 ;&quot;&gt;
&lt;li&gt;if focused_window&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;  index = sizes.map(&amp;amp;:first).index do |width|&lt;/li&gt;
&lt;li&gt;    (focused_window.rect.width.to_i - width).abs &amp;lt; 15&lt;/li&gt;
&lt;li&gt;  end&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;  index = -1 if !is_floating&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;  width, height = sizes[((index || -1) + 1) % sizes.length]&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;  if is_floating&lt;/li&gt;
&lt;li&gt;    @i3.command(&quot;resize set width #{width} px; resize set height #{height} px; move position center; move up 5 px&quot;)&lt;/li&gt;
&lt;li&gt;  else&lt;/li&gt;
&lt;li&gt;    @i3.command(&quot;floating enable; resize set width #{width} px; resize set height #{height} px; move position center; move up 5 px;&quot;)&lt;/li&gt;
&lt;li&gt;  end&lt;/li&gt;
&lt;li&gt;end&lt;/li&gt;
&lt;/ol&gt;&lt;/code&gt;&lt;/pre&gt;


  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;This config also allows me to quickly zoom a tiled panel to the middle of the screen, size it right and once I am done with focused work I can ship it back to the tile with &lt;code&gt;Super&lt;/code&gt;+&lt;code&gt;Shift&lt;/code&gt;+&lt;code&gt;Enter&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Easy terminal arrangement&lt;/h2&gt;
&lt;p&gt;One issue I had with i3 for quite a while was needing to remember to flip the way I split windows in tiling mode. I would hit &lt;code&gt;Super&lt;/code&gt;+&lt;code&gt;Enter&lt;/code&gt; to open a terminal, then hit it again and open a terminal to the right.&lt;/p&gt;
&lt;p&gt;And then I hit a problem.&lt;/p&gt;
&lt;p&gt;My brain simply did not consistently remember if I had to hit &lt;code&gt;Super&lt;/code&gt;+&lt;code&gt;v&lt;/code&gt; for a vertical split or &lt;code&gt;Super&lt;/code&gt; + &lt;code&gt;h&lt;/code&gt; for a horizontal split. Is splitting vertically splitting the vertical window in half or is splitting horizontally splitting tall window at the horizon.&lt;/p&gt;
&lt;p&gt;Clearly, I could work around my brain glitch by using a different shortcut that was easier for me to associate. Or just tough it up and train myself properly. But what I observed here is that I was just repeating a pointless task.&lt;/p&gt;
&lt;p&gt;I like my tiled windows arranged “just so” and in a specific order. i3 &lt;strong&gt;by design&lt;/strong&gt; is not a “just so” tiler, all tiling is manual not automatic like &lt;a href=&quot;https://xmonad.org/&quot;&gt;xmonad&lt;/a&gt; and &lt;a href=&quot;https://dwm.suckless.org/&quot;&gt;dwm&lt;/a&gt;. This is an explicit design goal of the project.&lt;/p&gt;
&lt;p&gt;Michael Stapelberg &lt;a href=&quot;https://github.com/i3/i3/issues/674#issuecomment-72824466&quot;&gt;explains&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Actually, now that I think of it, what you describe is how automatic tiling WMs work (like DWM, awesome, etc.). If you really need that, you might be better off using one of these. i3 is (and will stay) a manual tiling WM.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That said… this is &lt;strong&gt;my&lt;/strong&gt; Window Manager, and I can make it do what I want. Unlike my life in Windows and Mac, when I dislike a behavior I can amend it. I am encouraged to amend it. i3 will not merge in dynamic tiling which is a way they manage bloat and complexity, but I can have a bodged up dynamic tiling system that works for my workflows with i3.&lt;/p&gt;
&lt;p&gt;So, I have this standard behavior:&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/8/8538eec546f9885e1502c42e08ec9f3352e685e1.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/8538eec546f9885e1502c42e08ec9f3352e685e1&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/8/8538eec546f9885e1502c42e08ec9f3352e685e1_2_345x194.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;j0xtQa84EW8BJpuN1ONdccn1WY9&quot; width=&quot;345&quot; height=&quot;194&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/8/8538eec546f9885e1502c42e08ec9f3352e685e1_2_345x194.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/8/8538eec546f9885e1502c42e08ec9f3352e685e1_2_517x291.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/8/8538eec546f9885e1502c42e08ec9f3352e685e1_2_690x388.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/8/8538eec546f9885e1502c42e08ec9f3352e685e1_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;3840×2160 30 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Followed by this … non standard behavior. (notice how I never had to hit &lt;code&gt;Super+v&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/4/4cd0737b9d5f742701e077280d730937d34a9aaf.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/4cd0737b9d5f742701e077280d730937d34a9aaf&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4cd0737b9d5f742701e077280d730937d34a9aaf_2_345x194.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;aXwTjz5MtpcKEMREhwf2wcrarmf&quot; width=&quot;345&quot; height=&quot;194&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4cd0737b9d5f742701e077280d730937d34a9aaf_2_345x194.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4cd0737b9d5f742701e077280d730937d34a9aaf_2_517x291.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4cd0737b9d5f742701e077280d730937d34a9aaf_2_690x388.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/4/4cd0737b9d5f742701e077280d730937d34a9aaf_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;3840×2160 34.9 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;What more it gets better cause then next &lt;code&gt;Super+enter&lt;/code&gt; switches panels, no matter what terminal I am on.&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/6/67a2188caa3139b173fb19e1c59ca1632fab8f4c.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/67a2188caa3139b173fb19e1c59ca1632fab8f4c&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/67a2188caa3139b173fb19e1c59ca1632fab8f4c_2_345x194.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;eMMt2bZGqMDOpfqOmUey8PHjIIY&quot; width=&quot;345&quot; height=&quot;194&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/67a2188caa3139b173fb19e1c59ca1632fab8f4c_2_345x194.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/6/67a2188caa3139b173fb19e1c59ca1632fab8f4c_2_517x291.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/6/67a2188caa3139b173fb19e1c59ca1632fab8f4c_2_690x388.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/6/67a2188caa3139b173fb19e1c59ca1632fab8f4c_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;3840×2160 36.6 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;My system is somewhat glitchy, I have only been doing this for a few weeks, but it scratches my itch big time.&lt;/p&gt;
&lt;p&gt;As an added bonus I made it so when I am on my right most monitor I start tiling vertically in the left column instead of right.&lt;/p&gt;
&lt;p&gt;My work in progress code to make this happen is at my i3-plus file in &lt;a href=&quot;https://github.com/SamSaffron/dotfiles&quot;&gt;my dotfiles&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the moment layout is hardcoded and I simply run:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bindsym $mod+Return exec /home/sam/.i3/i3-plus layout_exec i3-sensible-terminal&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Tweaks to multi monitor focus&lt;/h2&gt;
&lt;p&gt;I tend to keep a floating window around on my left monitor for chat. I found that I tended to get trapped on my left monitor after hitting &lt;code&gt;Super + Left&lt;/code&gt;. i3 has a behavior where it cycles between floating windows on a monitor. This got in the way of my workflows.&lt;/p&gt;
&lt;p&gt;After raising raising this at &lt;a href=&quot;https://github.com/i3/i3/issues/3661&quot;&gt;GitHub&lt;/a&gt; airblader fairly concluded that this is a minor annoyance with a clear workaround but was worried about adding any more complexity to focus behavior. This is fair.&lt;/p&gt;
&lt;p&gt;But… this is my Window Manager and &lt;a href=&quot;https://github.com/SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L100-L152&quot;&gt;I get to call the shots on my computer&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So now my focus never gets trapped on a monitor. My &lt;code&gt;Super + Right&lt;/code&gt; key works the way I want it to.&lt;/p&gt;
&lt;h2&gt;Tweaks to move&lt;/h2&gt;
&lt;p&gt;Out-of-the-box i3s example file binds &lt;code&gt;Super + Shift + Right/Left&lt;/code&gt; to the i3 command &lt;code&gt;move&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What this does is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In tiled mode moves the tile to left or right&lt;/li&gt;
&lt;li&gt;In floating mode moves the window a few pixels to the left or right.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The behavior in tiled mode worked for me, but I found that I am not really into positioning floating windows using arrows and instead find it far more useful to “throw” a floated window to the right or left monitor.&lt;/p&gt;
&lt;p&gt;From what I can tell (and I may be wrong) I could not find a way to tell i3 to run a certain command in floating mode and another in tiled mode. However using the ipc interface &lt;a href=&quot;https://github.com/SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L157-L165&quot;&gt;this was trivial&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;  def move(dir)
    if is_floating?
      @i3.command(&quot;mark _last&quot;)
      @i3.command(&quot;move to output #{dir}&quot;)
      @i3.command('[con_mark=&quot;_last&quot;] focus')
    else
      @i3.command(&quot;move #{dir}&quot;)
    end
  end
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;A keyboard friendly exit&lt;/h2&gt;
&lt;p&gt;The i3 sample config spins up &lt;a href=&quot;https://build.i3wm.org/docs/i3-nagbar.html&quot;&gt;a nagbar&lt;/a&gt; prior to attempting to exit the windows manager. I found the position of this nagbar not ideal and did not like that I needed to reach for the mouse. I &lt;a href=&quot;https://faq.i3wm.org/question/1262/exiting-i3-without-mouse-click.1.html&quot;&gt;am not alone here&lt;/a&gt; but this is really only a common problem when you are heavily tweaking stuff.&lt;/p&gt;
&lt;p&gt;That said I came across this wonderful idea somewhere, which I would love to share:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;mode &quot;exit: [l]ogout, [r]eboot, [s]hutdown&quot; {
  bindsym l exec i3-msg exit
  bindsym r exec systemctl reboot
  bindsym s exec systemctl shutdown
  bindsym Escape mode &quot;default&quot;
  bindsym Return mode &quot;default&quot;
}

bindsym $mod+x mode &quot;exit: [l]ogout, [r]eboot, [s]hutdown&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I now use &lt;code&gt;Super + x&lt;/code&gt; to enter my “exit i3 mode”, which gives me all the goodies I need with a nice UX.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/f/f05597f9af5c1edd7324537e8584dcab6035ec26.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;yi5YxwW4JyqBIvgrcJFkB0V2zsi&quot; width=&quot;311&quot; height=&quot;78&quot;&gt;&lt;/p&gt;
&lt;h2&gt;I love screenshots&lt;/h2&gt;
&lt;p&gt;During my day I tend to take a lot of screenshots. I always struggled with this for a degree. I never had the “right” tool for the job in my Windows days. Now I do.&lt;/p&gt;
&lt;p&gt;I set up my screenshot hotkeys as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;PrtScn&lt;/code&gt; : take a screenshot of a selection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Super + PrtScn&lt;/code&gt; : take a 3 second delayed screenshot of a selection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Super + Shift + PrtScn&lt;/code&gt;: take a screenshot of the current desktop + pass it through &lt;a href=&quot;https://pngquant.org/&quot;&gt;pngquant&lt;/a&gt; and add to clipboard.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(1) in the list here was really easy. I used the &lt;a href=&quot;https://github.com/lupoDharkael/flameshot&quot;&gt;flameshot&lt;/a&gt; tool and simply bound prtscn to it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;exec --no-startup-id flameshot
bindsym Print exec &quot;flameshot gui&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It works a treat. Highly recommend.&lt;/p&gt;
&lt;p&gt;Delayed screenshots (2) is where stuff got tricky.&lt;/p&gt;
&lt;p&gt;Flameshot has a delay option, even if it did not it is trivial to exec &lt;code&gt;sleep 2 &amp;amp;&amp;amp; flameshot gui&lt;/code&gt;. However, I like having a visible reminder on the screen that this thing will happen:&lt;/p&gt;
&lt;div class=&quot;onebox video-onebox&quot;&gt;
  &lt;video width=&quot;100%&quot; height=&quot;100%&quot; controls=&quot;&quot;&gt;
    &lt;source src=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/4/4ba8cb8e7c06921dddac1edd0dff2351a4841013.webm&quot;&gt;
    &lt;a href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/4/4ba8cb8e7c06921dddac1edd0dff2351a4841013.webm&quot;&gt;https://discuss.samsaffron.com/uploads/default/original/2X/4/4ba8cb8e7c06921dddac1edd0dff2351a4841013.webm&lt;/a&gt;
  &lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;To implement this I adapted the countdown script &lt;a href=&quot;https://askubuntu.com/a/762266/265&quot;&gt;from Jacob Vlijm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My &lt;a href=&quot;https://github.com/SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/countdown&quot;&gt;adaptation is here.&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In i3 I have:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;bindsym $mod+Print exec &quot;/bin/bash -c '/home/sam/.i3/countdown 3 &amp;amp;&amp;amp; sleep 0.2 &amp;amp;&amp;amp; flameshot gui'&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Full screen screenshots (3), like the ones further up this blog post was a bit tricky.&lt;/p&gt;
&lt;p&gt;Xwindows screenshot tools like treating all my 3 4k screens as one big panel, not too many tools out there can figure out current focused monitor let alone split up the enormous image.&lt;/p&gt;
&lt;p&gt;To achieve this I rolled my own script that uses the i3 IPC to figure out what display has focus and then tells &lt;a href=&quot;https://www.imagemagick.org/&quot;&gt;ImageMagick&lt;/a&gt; to capture and crop correctly and finally passes throw pngquant and back on to the clipboard in a web past friendly format using &lt;a href=&quot;https://hluk.github.io/CopyQ/&quot;&gt;CopyQ&lt;/a&gt;.&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://github.com/SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L205-L237&quot; target=&quot;_blank&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L205-L237&quot; target=&quot;_blank&quot;&gt;SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L205-L237&lt;/a&gt;&lt;/h4&gt;
&lt;pre class=&quot;onebox&quot;&gt;&lt;code class=&quot;lang-&quot;&gt;&lt;ol class=&quot;start lines&quot; start=&quot;205&quot; style=&quot;counter-reset: li-counter 204 ;&quot;&gt;
&lt;li&gt;def screenshot(args)&lt;/li&gt;
&lt;li&gt;  focused_output = nil&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;  recurse do |n, depth: , focused: , floating:|&lt;/li&gt;
&lt;li&gt;    if n.type == &quot;output&quot;&lt;/li&gt;
&lt;li&gt;      focused_output = n&lt;/li&gt;
&lt;li&gt;    end&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;    if focused&lt;/li&gt;
&lt;li&gt;      break&lt;/li&gt;
&lt;li&gt;    end&lt;/li&gt;
&lt;li&gt;  end&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;  `mkdir -p ~/screenshots`&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;  rect = focused_output.rect&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;  filename = &quot;~/screenshots/desktop-#{Time.now.strftime('%Y%m%d-%H%M%S')}.png&quot;&lt;/li&gt;
&lt;li&gt;  cmd = &quot;import -silent -window root -crop #{rect.width}x#{rect.height}+#{rect.x}+#{rect.y} #{filename}&quot;&lt;/li&gt;
&lt;li&gt;  `#{cmd}`&lt;/li&gt;
&lt;/ol&gt;&lt;/code&gt;&lt;/pre&gt;

  This file has been truncated. &lt;a href=&quot;https://github.com/SamSaffron/dotfiles/blob/3b6f8f102de4ca57e8ad55fa0f7a97eed7b8da59/i3/i3-plus#L205-L237&quot; target=&quot;_blank&quot;&gt;show original&lt;/a&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;This simple binding then takes care of it for me.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;bindsym $mod+Shift+Print exec &quot;/home/sam/.i3/i3-plus screenshot&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Scratchpad&lt;/h2&gt;
&lt;p&gt;i3 has a special desktop that is not visible called “the scratchpad”. If you want to get rid of a window temporarily you can always just ship it there and recall it from there. I like to use it for a couple of things.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;I bind &lt;code&gt;Super + b&lt;/code&gt; to toggle my browser in and out of the scratchpad. No matter which monitor I am on I can summon my browser with this hotkey (and make it go away)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I bind &lt;code&gt;Super + p&lt;/code&gt; to toggle a dedicated terminal. I like to use this dedicated terminal to run stuff like &lt;code&gt;pacman -Syu&lt;/code&gt; that can take a bit, look at a calendar, run a quick calculation and so on.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Similar to both above I like &lt;code&gt;Super + y&lt;/code&gt; to bring up my &lt;a href=&quot;https://www.yubico.com/products/services-software/download/yubico-authenticator/&quot;&gt;yubico authenticator&lt;/a&gt;. (I highly recommend a Yubikey for devs it is a big time saver)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;# terminal that pops up on demand
exec urxvt -name scratch-term
for_window [instance=&quot;scratch-term&quot;] floating enable, move to scratchpad
bindsym $mod+p [instance=&quot;scratch-term&quot;] scratchpad show

exec firefox
for_window [class=&quot;Firefox&quot;] floating enable, move to scratchpad, scratchpad show
bindsym $mod+b [class=&quot;Firefox&quot;] scratchpad show

exec yubioath-desktop
for_window [class=&quot;Yubico Authenticator&quot;] floating enable, move to scratchpad
bindsym $mod+y [class=&quot;Yubico Authenticator&quot;] scratchpad show

&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Other bits and pieces&lt;/h2&gt;
&lt;p&gt;My current .xinitrc looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;eval $(dbus-launch -sh-syntax --exit-with-session)
dbus-update-activation-environment --systemd DISPLAY

xrdb -merge ~/.Xresources

xrandr --output DVI-D-0 --off --output HDMI-1 --off --output HDMI-0 --mode 3840x2160 --pos 0x0 --rotate normal --output DP-3 --off --output DP-2 --primary --mode 3840x2160 --pos 3840x0 --rotate normal --output DP-1 --off --output DP-0 --mode 3840x2160 --pos 7680x0 --rotate normal

eval $(/usr/bin/gnome-keyring-daemon --start --components=gpg,pkcs11,secrets,ssh)
export GNOME_KEYRING_CONTROL GNOME_KEYRING_PID GPG_AGENT_INFO SSH_AUTH_SOCK

exec i3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am not a fan of using &lt;a href=&quot;https://wiki.archlinux.org/index.php/GDM&quot;&gt;Gnome Display Manager&lt;/a&gt; as I feel it introduces more complexity into my setup. Instead, I just run &lt;code&gt;startx&lt;/code&gt; after logging in.&lt;/p&gt;
&lt;p&gt;The two trips here is that I needed a dbus session so gnome type apps work (like skype for example) and needed to spin up my keyring (which skype needed as well)&lt;/p&gt;
&lt;h2&gt;Do I actually get any work done?&lt;/h2&gt;
&lt;p&gt;The i3 sample config file has a wonderful comment at the top.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;# This file has been auto-generated by i3-config-wizard(1).
# It will not be overwritten, so edit it as you like.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;My i3 setup is &lt;strong&gt;my setup&lt;/strong&gt;. It is tailored for my use cases.&lt;/p&gt;
&lt;p&gt;I love that i3 has a single config file, it is very easy to reason about my current desktop environment. If I don’t ever use a shortcut I can remove it. If I need a new shortcut I can add it. If I forget what is “on the menu” I can read the reasonably small file to figure out!&lt;/p&gt;
&lt;p&gt;All of this tweaking does sound like it could be a full time job for multiple weeks but it really was not at all. I hit barriers in my workflow, unblocked them and then moved on. Each barrier I removed made me more efficient.&lt;/p&gt;
&lt;p&gt;The end result has been that I can now jump on a problem and solve it with significantly more focus. My window manager is working for me, I am no longer its slave.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&quot;https://samsaffron.com/archive/2019/03/31/why-i-stuck-with-windows-for-6-years-while-developing-discourse&quot;&gt;my previous blog post&lt;/a&gt; I talked about leaving Windows. The catalyst was performance. What I did not know was what a wonderful experience I would have in my new Linux home.&lt;/p&gt;
&lt;p&gt;Sure, I have the usual niggles of needing to run a &lt;a href=&quot;https://github.com/chjj/compton&quot;&gt;compositor&lt;/a&gt; fight with Nvidia drivers and deal with finding Linux alternatives for Windows tools I was used to using. However, on a fundamental level I am just so much happier now. I feel like I relinquished control over my computer for too long.&lt;/p&gt;
&lt;h2&gt;What you can do?&lt;/h2&gt;
&lt;p&gt;If you wish to do a Linux experiment you can choose the hard mode or the easy mode, there are plenty of alternatives out there. If you want to try out tiling, you can even just pick up Manjaro which has an i3 distribution or &lt;a href=&quot;https://regolith-linux.org/&quot;&gt;Regolith Linux&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As a programmer in any terminal dominated technology stack (like Ruby/Rust/Golang and so on) I strongly recommend trying out a tiling window manager.&lt;/p&gt;
&lt;p&gt;From all my research i3 is the perfect first choice for trying out a tiling window manager, it comes with very sane and complete defaults, the config file is very easy to reason about and it works great!&lt;/p&gt;
&lt;p&gt;If you have any questions or would like any tips feel free to post here and I will reply, but be warned, I am no expert I am just learning.&lt;/p&gt;
&lt;p&gt;Big thank you to &lt;a href=&quot;https://github.com/stapelberg&quot;&gt;Michael Stapelberg&lt;/a&gt; for creating i3, and the very active community (Airblader, Orestis and others) for maintaining i3. Big thank you to all you people putting excellent content out there and making my ride into the Linux world easy.&lt;/p&gt;</description>
      <pubDate>Wed, 10 Apr 2019 02:12:04 +0000</pubDate>
      <link>https://samsaffron.com/archive/2019/04/09/my-i3-window-manager-setup</link>
    </item>
    <item>
      <title>Why I stuck with Windows for 6 years while developing Discourse</title>
      <description>
&lt;p&gt;I made this tweet that got reasonably popular:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We benchmarked how long it takes to run the Ruby test suite for Discourse across our various dev machines. I can not believe what a crazy tax I have paid over the years insisting on sticking with Windows, highlighted results mine.&lt;br&gt;
&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/c/c7c99948f98919d19986be566c1cfa94c9b0f620.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/c7c99948f98919d19986be566c1cfa94c9b0f620&quot; title=&quot;image&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/c/c7c99948f98919d19986be566c1cfa94c9b0f620_2_517x443.png&quot; alt=&quot;image&quot; data-base62-sha1=&quot;svoWhkj3tR1JHDM55w2GjB7002k&quot; width=&quot;517&quot; height=&quot;443&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/c/c7c99948f98919d19986be566c1cfa94c9b0f620_2_517x443.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/c/c7c99948f98919d19986be566c1cfa94c9b0f620_2_775x664.png 1.5x, https://discuss.samsaffron.com/uploads/default/original/2X/c/c7c99948f98919d19986be566c1cfa94c9b0f620.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/c/c7c99948f98919d19986be566c1cfa94c9b0f620_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;824×706 73.7 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/samsaffron/status/1111511735851081728&quot;&gt;https://twitter.com/samsaffron/status/1111511735851081728&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This evoked a lot of extremely strong emotions from various people out there. Ranging from “Sam is a fool what kind of insane benchmark is this”, “the real story is MacOS has bad Ruby perf” to a general “Oh no”.&lt;/p&gt;
&lt;p&gt;The core point I was trying to make was that I was paying a pretty high tax for deciding to “stick with with Windows”. There are a bunch of other points hiding here that are also worth discussing.&lt;/p&gt;
&lt;h3&gt;Why are you running sticking with Windows to run Linux in a VM?&lt;/h3&gt;
&lt;aside class=&quot;onebox twitterstatus&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://twitter.com/shanselman/status/1111538525017530371&quot; target=&quot;_blank&quot;&gt;twitter.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;img src=&quot;https://pbs.twimg.com/profile_images/1133122333290291200/xV9gO-D6_400x400.jpg&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;400&quot; height=&quot;400&quot;&gt;

&lt;h4&gt;&lt;a href=&quot;https://twitter.com/shanselman/status/1111538525017530371&quot; target=&quot;_blank&quot;&gt;Scott Hanselman (shanselman)&lt;/a&gt;&lt;/h4&gt;

&lt;div class=&quot;tweet&quot;&gt; &lt;a href=&quot;https://twitter.com/samsaffron&quot; target=&quot;_blank&quot;&gt;@samsaffron&lt;/a&gt; But your highlights compare running in a VM vs running native, not Win vs Linux. So you’re sticking with Windows...to run Linux in a VM?&lt;/div&gt;

&lt;div class=&quot;date&quot;&gt;
  &lt;a href=&quot;https://twitter.com/shanselman/status/1111538525017530371&quot; target=&quot;_blank&quot;&gt;8:00 AM - 29 Mar 2019&lt;/a&gt;
    &lt;span class=&quot;like&quot;&gt;
      &lt;svg viewbox=&quot;0 0 512 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 65
    &lt;/span&gt;
    &lt;span class=&quot;retweet&quot;&gt;
      &lt;svg viewbox=&quot;0 0 640 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M629.657 343.598L528.971 444.284c-9.373 9.372-24.568 9.372-33.941 0L394.343 343.598c-9.373-9.373-9.373-24.569 0-33.941l10.823-10.823c9.562-9.562 25.133-9.34 34.419.492L480 342.118V160H292.451a24.005 24.005 0 0 1-16.971-7.029l-16-16C244.361 121.851 255.069 96 276.451 96H520c13.255 0 24 10.745 24 24v222.118l40.416-42.792c9.285-9.831 24.856-10.054 34.419-.492l10.823 10.823c9.372 9.372 9.372 24.569-.001 33.941zm-265.138 15.431A23.999 23.999 0 0 0 347.548 352H160V169.881l40.416 42.792c9.286 9.831 24.856 10.054 34.419.491l10.822-10.822c9.373-9.373 9.373-24.569 0-33.941L144.971 67.716c-9.373-9.373-24.569-9.373-33.941 0L10.343 168.402c-9.373 9.373-9.373 24.569 0 33.941l10.822 10.822c9.562 9.562 25.133 9.34 34.419-.491L96 169.881V392c0 13.255 10.745 24 24 24h243.549c21.382 0 32.09-25.851 16.971-40.971l-16.001-16z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 6
    &lt;/span&gt;
&lt;/div&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;What I did not know is the extent of the VM tax I was paying regularly. I never dual booted my computer so I had no proper anchoring point of reference.&lt;/p&gt;
&lt;p&gt;I very strongly believe that many Ruby/Rust/Go/Elixir/Scala and even some Node developers who end up doing the &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/wsl/install-win10&quot;&gt;WSL dance&lt;/a&gt; or run Linux in a VM for development, or use Linux Docker for dev on Windows are not aware of the full extent of the tax.&lt;/p&gt;
&lt;p&gt;On my machine the price of admission for using WSL was 25% slowdown in my day to day running of specs. And a 38% slowdown for using a VMware based VM.&lt;/p&gt;
&lt;p&gt;I am not alone here… other team members have experienced similar slowdowns. Other people out there also experience similar slowdowns.&lt;/p&gt;
&lt;aside class=&quot;onebox twitterstatus&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://twitter.com/stevedesmond_ca/status/1111585969650712578&quot; target=&quot;_blank&quot;&gt;twitter.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;img src=&quot;https://pbs.twimg.com/profile_images/599567103553732608/CjYbKf_G_400x400.jpg&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;&quot; height=&quot;&quot;&gt;

&lt;h4&gt;&lt;a href=&quot;https://twitter.com/stevedesmond_ca/status/1111585969650712578&quot; target=&quot;_blank&quot;&gt;Steve Desmond (stevedesmond_ca)&lt;/a&gt;&lt;/h4&gt;

&lt;div class=&quot;tweet&quot;&gt; &lt;a href=&quot;https://twitter.com/shanselman&quot; target=&quot;_blank&quot;&gt;@shanselman&lt;/a&gt; &lt;a href=&quot;https://twitter.com/samsaffron&quot; target=&quot;_blank&quot;&gt;@samsaffron&lt;/a&gt; Yep, this is just virtualization overhead, in line with benchmarking I've done in the past: 10% for Hyper-V and WSL (obviously virtualizing different things) and 25% for VMWare and VirtualBox.

Have you tried running Ruby natively on Windows?&lt;/div&gt;

&lt;div class=&quot;date&quot;&gt;
  &lt;a href=&quot;https://twitter.com/stevedesmond_ca/status/1111585969650712578&quot; target=&quot;_blank&quot;&gt;11:08 AM - 29 Mar 2019&lt;/a&gt;
    &lt;span class=&quot;like&quot;&gt;
      &lt;svg viewbox=&quot;0 0 512 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 2
    &lt;/span&gt;
&lt;/div&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;What I thought was inside my wonderful wish hat was that the performance hit was minor:&lt;/p&gt;
&lt;aside class=&quot;onebox stackexchange&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://serverfault.com/questions/135431/is-virtual-machine-slower-than-the-underlying-physical-machine/135434#135434&quot; target=&quot;_blank&quot;&gt;serverfault.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
      &lt;a href=&quot;https://serverfault.com/users/37059/tomtom&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;TomTom&quot; src=&quot;https://www.gravatar.com/avatar/5d989ed3c52dbe11e3ae2f537ce717a6?s=128&amp;amp;d=identicon&amp;amp;r=PG&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;128&quot; height=&quot;128&quot;&gt;
  &lt;/a&gt;
&lt;h4&gt;
  &lt;a href=&quot;https://serverfault.com/questions/135431/is-virtual-machine-slower-than-the-underlying-physical-machine/135434#135434&quot; target=&quot;_blank&quot;&gt;Is virtual machine slower than the underlying physical machine?&lt;/a&gt;
&lt;/h4&gt;

&lt;div class=&quot;tags&quot;&gt;
  &lt;strong&gt;virtualization, performance, cloud-computing, benchmark&lt;/strong&gt;
&lt;/div&gt;

&lt;div class=&quot;date&quot;&gt;
  
  answered by
  &lt;a href=&quot;https://serverfault.com/users/37059/tomtom&quot; target=&quot;_blank&quot;&gt;
    TomTom
  &lt;/a&gt;
  on &lt;a href=&quot;https://serverfault.com/questions/135431/is-virtual-machine-slower-than-the-underlying-physical-machine/135434#135434&quot; target=&quot;_blank&quot;&gt;07:25AM - 24 Apr 10 UTC&lt;/a&gt;
&lt;/div&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;blockquote&gt;
&lt;p&gt;Yes. But that is not the question. &lt;strong&gt;The difference is normally negligible (1% to 5%)&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you Google, well that is the general answer you get. VMs are more or less the same as no VM, 5-10% perf tax. My reality was different. Maybe I was missing magic bios turbo settings, maybe I needed to direct mount a volume instead of using a vmdk on my dedicated NVMe Samsung 960 pro, maybe there is some magic I could do to get to this magic 1-5% number. Maybe Hyper-V is better I am not sure. All I know is that I am not alone here.&lt;/p&gt;
&lt;p&gt;WSL is not an option for me cause Ruby likes lots of small files and lots of stats calls, WSL has terrible lots of small file performance &lt;a href=&quot;https://github.com/Microsoft/WSL/issues/873#issuecomment-425272829&quot;&gt;as documented by the WSL team&lt;/a&gt;.  How terrible you ask? As a baseline just running a &lt;code&gt;rails c&lt;/code&gt; console without &lt;a href=&quot;https://github.com/Shopify/bootsnap&quot;&gt;bootsnap&lt;/a&gt; was taking me &lt;a href=&quot;https://meta.discourse.org/t/installation-notes-for-discourse-on-bash-for-windows/48141/3?u=sam&quot;&gt;upwards of 30 seconds&lt;/a&gt;. Same operations takes 4-5 seconds on Linux without bootsnap. Even with all the workarounds we could place this bad IO perf was something that I just noticed too much. In fact I preferred the 38% slowdown cause at least stuff was consistent and not wildly off balance like WSL is. Being able to launch a console or web server quickly is critical during dev. Fuse does not appear to be happening any time soon so you can not work around this using ninja tricks of block mounting a device.&lt;/p&gt;
&lt;p&gt;So, I stuck with a VM cause it was nice not to have to constantly reboot my computer and thought the price I was paying was not that high.&lt;/p&gt;
&lt;p&gt;I like the Windows 10 font rendering, I like the HiDPI support, I like using Lightroom on Windows and playing Rocksmith on Windows. I like the out-of-the-box experience and minimal amount of tweaking needed. I like being able to launch Skype without it segfaulting cause I was LD_PRELOADing jemalloc. I feel Windows 10 as a window manager is on par (for my usage) to my Macbook Pro running MacOS.&lt;/p&gt;
&lt;p&gt;Dual booting is a &lt;strong&gt;compromise&lt;/strong&gt; for me, some stuff I have works best in Windows. I thought the compromise I was making performance wise was worth the comfort of living in a “known OS” that I like.&lt;/p&gt;
&lt;p&gt;I felt that if I start booting to Linux I am going to have to fight with drivers, have stability issues, not have a complete toolset and so on.&lt;/p&gt;
&lt;p&gt;I felt comfortable at home and moving is one of the most stressful life events.&lt;/p&gt;
&lt;h3&gt;Is 2019 the year of Linux on the Desktop?&lt;/h3&gt;
&lt;aside class=&quot;onebox twitterstatus&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://twitter.com/joeneville_/status/1111891763151728640&quot; target=&quot;_blank&quot;&gt;twitter.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;img src=&quot;https://pbs.twimg.com/profile_images/845370375387123717/Tkv2Esar_400x400.jpg&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;400&quot; height=&quot;400&quot;&gt;

&lt;h4&gt;&lt;a href=&quot;https://twitter.com/joeneville_/status/1111891763151728640&quot; target=&quot;_blank&quot;&gt;Joe Neville (joeneville_)&lt;/a&gt;&lt;/h4&gt;

&lt;div class=&quot;tweet&quot;&gt; 2019. I'm gonna say it....Linux on the desktop. &lt;a target=&quot;_blank&quot; href=&quot;https://twitter.com/samsaffron/status/1111511735851081728&quot;&gt;twitter.com/samsaffron/sta…&lt;/a&gt;&lt;div class=&quot;quoted&quot;&gt;
&lt;a class=&quot;quoted-link&quot; href=&quot;https://twitter.com/samsaffron/status/1111511735851081728&quot;&gt;&lt;p class=&quot;quoted-title&quot;&gt;Sam Saffron &lt;span&gt;@samsaffron&lt;/span&gt;&lt;/p&gt;&lt;/a&gt;&lt;div&gt;We benchmarked how long it takes to run the Ruby test suite for Discourse across our various dev machines. I can not believe what a crazy tax I have paid over the years insisting on sticking with Windows, highlighted results mine. https://t.co/mEKzh5ac18&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;date&quot;&gt;
  &lt;a href=&quot;https://twitter.com/joeneville_/status/1111891763151728640&quot; target=&quot;_blank&quot;&gt;7:23 AM - 30 Mar 2019&lt;/a&gt;
    &lt;span class=&quot;like&quot;&gt;
      &lt;svg viewbox=&quot;0 0 512 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 1
    &lt;/span&gt;
&lt;/div&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;The joke goes like this. Every year a bunch of people joke about how LOL this will be the year of Linux on the Desktop. It happens every year. It starts cause someone says “hi Linux is quite good these days, could this be the year of Linux on the Desktop?”. And then a bunch of happy and well meaning trolls, say ha ha … as always you are wrong… this is not the year of Linux on the Desktop.&lt;/p&gt;
&lt;p&gt;And so it goes…&lt;/p&gt;
&lt;p&gt;This banter is usually well meaning and grounded in reality. However it has a very big side effect, which impacts developers in a significant manner. Developers who do not use Linux on the desktop are scared of Linux. They are scared even if their production code only deploys on Linux (and not MacOS or Windows)&lt;/p&gt;
&lt;p&gt;I felt super scared to go down the path of Linux cause I was terrified … about drivers … font rendering… HiDPI support… multi monitor support and the list goes on.&lt;/p&gt;
&lt;p&gt;In fact, I was not wrong to be scared. It is fiddly to get Linux going. I almost gave up after my first 4-8 hours cause Firefox on Linux &lt;a href=&quot;https://bugzilla.mozilla.org/show_bug.cgi?id=594876#c104&quot;&gt;is still stuck on a very sad default&lt;/a&gt; there is no hardware acceleration out of the box, so scrolling is mega jerky. This very simply rectifiable behavior was a deal breaker for me. If I could not get scrolling a web page to be smooth, I am out of here, not going to use Linux. Luckily the issue was resolved after tweaking 1 value in &lt;code&gt;about:config&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;NVIDIA does not have a great story as well, the future of Desktop on Linux is &lt;a href=&quot;https://en.wikipedia.org/wiki/Wayland_(display_server_protocol)&quot;&gt;Wayland&lt;/a&gt;. The windows manager I wanted to try, sway, &lt;a href=&quot;https://drewdevault.com/2017/10/26/Fuck-you-nvidia.html&quot;&gt;only works properly&lt;/a&gt; if you use the open source community provided &lt;a href=&quot;https://nouveau.freedesktop.org/wiki/&quot;&gt;nouveau driver&lt;/a&gt;. Even getting NVIDIA to work nicely involves enabling hardware compositing and fiddling with &lt;a href=&quot;https://xkcd.com/963/&quot;&gt;X11 config&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My position is not that Linux is poised to take over the world in a storm this year. It is a far more humble position. If you want to get the &lt;strong&gt;best bang for buck&lt;/strong&gt; and want to get the best possible performance developing Discourse, or any Ruby on Rails application Linux on the Desktop/Laptop with no VM is your best bet.&lt;/p&gt;
&lt;p&gt;It is also important to note that I opted for medium hard mode when I moved to Linux. I am only 2 neck beards away from installing Linux from scratch.&lt;/p&gt;
&lt;p&gt;            &lt;aside class=&quot;onebox reddit&quot;&gt;
              &lt;header class=&quot;source&quot;&gt;
                &lt;img src=&quot;https://www.redditstatic.com/desktop2x/img/favicon/android-icon-192x192.png&quot; class=&quot;site-icon&quot; width=&quot;16&quot; height=&quot;16&quot;&gt;
                &lt;a href=&quot;https://www.reddit.com/r/ProgrammerHumor/comments/3mun55/evolution_of_linux_neckbeardsxpost/&quot; target=&quot;_blank&quot;&gt;reddit&lt;/a&gt;
              &lt;/header&gt;
              &lt;article class=&quot;onebox-body&quot;&gt;
                &lt;h3&gt;&lt;a href=&quot;https://www.reddit.com/r/ProgrammerHumor/comments/3mun55/evolution_of_linux_neckbeardsxpost/&quot; target=&quot;_blank&quot;&gt;r/ProgrammerHumor - Evolution of Linux neckbeards(xpost r/justneckbeardthings)&lt;/a&gt;&lt;/h3&gt;
                &lt;div class=&quot;aspect-image-full-size&quot; style=&quot;--aspect-ratio:604/453;&quot;&gt;
                  &lt;img src=&quot;https://external-preview.redd.it/d8E1ihyd6DbjdR_xR6ANI-WC3wwegCz3dU6Lk_hybT4.jpg?auto=webp&amp;amp;s=9dbc34e0f49398e1e7f77ca04ae13a55314de7c0&quot; class=&quot;scale-image&quot; width=&quot;604&quot; height=&quot;453&quot;&gt;
                &lt;/div&gt;
                &lt;div class=&quot;description&quot;&gt;&lt;p&gt;742 votes and 135 comments so far on Reddit&lt;/p&gt;&lt;/div&gt;
              &lt;/article&gt;
            &lt;/aside&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.reddit.com/r/ProgrammerHumor/comments/3mun55/evolution_of_linux_neckbeardsxpost/&quot;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My colleagues who went through similar exercises of shifting from Windows/Mac to Linux stuck with Ubuntu and Linux Mint, they tell me they had a very smooth ride.&lt;/p&gt;
&lt;h3&gt;Have you tried running Ruby on Windows?&lt;/h3&gt;
&lt;p&gt;Avdi triggered quite a discussion about this a few days ago:&lt;/p&gt;
&lt;aside class=&quot;onebox twitterstatus&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://twitter.com/avdi/status/1109834294665592834&quot; target=&quot;_blank&quot;&gt;twitter.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;img src=&quot;https://pbs.twimg.com/profile_images/1191164226062163969/C9n-mO6L_400x400.jpg&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;400&quot; height=&quot;400&quot;&gt;

&lt;h4&gt;&lt;a href=&quot;https://twitter.com/avdi/status/1109834294665592834&quot; target=&quot;_blank&quot;&gt;Avdi Grimm (avdi)&lt;/a&gt;&lt;/h4&gt;

&lt;div class=&quot;tweet&quot;&gt; &quot;Why is everyone going to Node instead of Ruby??&quot;

50% of developers primarily use Windows. (&lt;a target=&quot;_blank&quot; href=&quot;https://insights.stackoverflow.com/survey/2018/#technology-developers-primary-operating-systems&quot;&gt;insights.stackoverflow.com/survey/2018/#t…&lt;/a&gt;)

Node works well on Linux, MacOS, and Windows.
Ruby works well on Linux, MacOS, and is (still) a fucking nightmare on Windows.

Do the math.&lt;/div&gt;

&lt;div class=&quot;date&quot;&gt;
  &lt;a href=&quot;https://twitter.com/avdi/status/1109834294665592834&quot; target=&quot;_blank&quot;&gt;3:08 PM - 24 Mar 2019&lt;/a&gt;
    &lt;span class=&quot;like&quot;&gt;
      &lt;svg viewbox=&quot;0 0 512 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 940
    &lt;/span&gt;
    &lt;span class=&quot;retweet&quot;&gt;
      &lt;svg viewbox=&quot;0 0 640 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M629.657 343.598L528.971 444.284c-9.373 9.372-24.568 9.372-33.941 0L394.343 343.598c-9.373-9.373-9.373-24.569 0-33.941l10.823-10.823c9.562-9.562 25.133-9.34 34.419.492L480 342.118V160H292.451a24.005 24.005 0 0 1-16.971-7.029l-16-16C244.361 121.851 255.069 96 276.451 96H520c13.255 0 24 10.745 24 24v222.118l40.416-42.792c9.285-9.831 24.856-10.054 34.419-.492l10.823 10.823c9.372 9.372 9.372 24.569-.001 33.941zm-265.138 15.431A23.999 23.999 0 0 0 347.548 352H160V169.881l40.416 42.792c9.286 9.831 24.856 10.054 34.419.491l10.822-10.822c9.373-9.373 9.373-24.569 0-33.941L144.971 67.716c-9.373-9.373-24.569-9.373-33.941 0L10.343 168.402c-9.373 9.373-9.373 24.569 0 33.941l10.822 10.822c9.562 9.562 25.133 9.34 34.419-.491L96 169.881V392c0 13.255 10.745 24 24 24h243.549c21.382 0 32.09-25.851 16.971-40.971l-16.001-16z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 250
    &lt;/span&gt;
&lt;/div&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;The point he is trying to make is that a Ruby that works well on native Windows will help Ruby adoption a lot and eliminate drain to other frameworks. Installing a whole brand new OS is just too much of a barrier. Just install Linux is not a solution.&lt;/p&gt;
&lt;p&gt;The reality is that running MRI Ruby native on Windows hits 2 big fundamental problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Filesystem performance characteristics of NTFS on Windows are badly suited to the current Ruby design. We love lots of small files, we love lots of stats calls.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is a gigantic effort porting various dependencies to Windows native (and maintaining them), as it stands many of the Discourse dependencies simply do not work on Windows. The gems simply will not install. The fundamental issue is that if you are writing a c extension in a gem it is &lt;strong&gt;extra work&lt;/strong&gt; to get it to work on Windows. Getting stuff to work on MacOS and Linux is no extra work vast majority of the time.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(2) is a tractable problem, but I wonder if it is worth any kind of effort given WSL has far wider compatibility and should offer reasonable performance once a workaround exists for the filesystem problem (which is fundamental and not going to change on Windows native). Discourse works fine on WSL (provided you skip using unicorn) Discourse does not work at all on Ruby on Windows native. The Apple tax is similar in cost to the Windows WSL tax (except for filesystem perf). I feel that once WSL gets a bit more polish and fixes it will be competitive with the current Mac experience.&lt;/p&gt;
&lt;h3&gt;The Apple performance tax&lt;/h3&gt;
&lt;p&gt;One pretty obvious thing from the chart I provided was showing there is a pretty severe Apple performance tax as well.&lt;/p&gt;
&lt;p&gt;When looking at user benchmarks per: &lt;a href=&quot;https://cpu.userbenchmark.com/Compare/Intel-Core-i7-8750H-vs-Intel-Core-i7-8559U/m470418vsm543591&quot; class=&quot;inline-onebox&quot;&gt;UserBenchmark: Intel Core i7-8559U vs i7-8750H&lt;/a&gt;. We expect an 8559U to have faster single core performance (thermal locking withstanding) than the 8750H. Yet this Linux 8750H laptop is clocking a spectacular 9m13s compared to the Macbook  Pro 15m16s. We are seeing poor MacOS performance across the board. And we are not alone:&lt;/p&gt;
&lt;aside class=&quot;onebox twitterstatus&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://twitter.com/dominiksander/status/1111928539580956672&quot; target=&quot;_blank&quot;&gt;twitter.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;img src=&quot;https://pbs.twimg.com/profile_images/567160511/m_400x400.JPG&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;400&quot; height=&quot;400&quot;&gt;

&lt;h4&gt;&lt;a href=&quot;https://twitter.com/dominiksander/status/1111928539580956672&quot; target=&quot;_blank&quot;&gt;Dominik Sander (dominiksander)&lt;/a&gt;&lt;/h4&gt;

&lt;div class=&quot;tweet&quot;&gt; &lt;a href=&quot;https://twitter.com/samsaffron&quot; target=&quot;_blank&quot;&gt;@samsaffron&lt;/a&gt; &lt;a href=&quot;https://twitter.com/ach0w&quot; target=&quot;_blank&quot;&gt;@ach0w&lt;/a&gt; &lt;a href=&quot;https://twitter.com/juux&quot; target=&quot;_blank&quot;&gt;@juux&lt;/a&gt; &lt;a href=&quot;https://twitter.com/codinghorror&quot; target=&quot;_blank&quot;&gt;@codinghorror&lt;/a&gt; On my 9900K hackintosh the suite took 9m1s which matches my experience of macOS, most of the time, being 10-30% slower than Linux doing the same task.&lt;/div&gt;

&lt;div class=&quot;date&quot;&gt;
  &lt;a href=&quot;https://twitter.com/dominiksander/status/1111928539580956672&quot; target=&quot;_blank&quot;&gt;9:49 AM - 30 Mar 2019&lt;/a&gt;
    &lt;span class=&quot;like&quot;&gt;
      &lt;svg viewbox=&quot;0 0 512 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 6
    &lt;/span&gt;
    &lt;span class=&quot;retweet&quot;&gt;
      &lt;svg viewbox=&quot;0 0 640 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M629.657 343.598L528.971 444.284c-9.373 9.372-24.568 9.372-33.941 0L394.343 343.598c-9.373-9.373-9.373-24.569 0-33.941l10.823-10.823c9.562-9.562 25.133-9.34 34.419.492L480 342.118V160H292.451a24.005 24.005 0 0 1-16.971-7.029l-16-16C244.361 121.851 255.069 96 276.451 96H520c13.255 0 24 10.745 24 24v222.118l40.416-42.792c9.285-9.831 24.856-10.054 34.419-.492l10.823 10.823c9.372 9.372 9.372 24.569-.001 33.941zm-265.138 15.431A23.999 23.999 0 0 0 347.548 352H160V169.881l40.416 42.792c9.286 9.831 24.856 10.054 34.419.491l10.822-10.822c9.373-9.373 9.373-24.569 0-33.941L144.971 67.716c-9.373-9.373-24.569-9.373-33.941 0L10.343 168.402c-9.373 9.373-9.373 24.569 0 33.941l10.822 10.822c9.562 9.562 25.133 9.34 34.419-.491L96 169.881V392c0 13.255 10.745 24 24 24h243.549c21.382 0 32.09-25.851 16.971-40.971l-16.001-16z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 2
    &lt;/span&gt;
&lt;/div&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;aside class=&quot;onebox twitterstatus&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://twitter.com/zalesz/status/1111726682115899393&quot; target=&quot;_blank&quot;&gt;twitter.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;img src=&quot;https://pbs.twimg.com/profile_images/1148904654325145600/dPgfy1W__400x400.jpg&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;400&quot; height=&quot;400&quot;&gt;

&lt;h4&gt;&lt;a href=&quot;https://twitter.com/zalesz/status/1111726682115899393&quot; target=&quot;_blank&quot;&gt;Leszek Zalewski (zalesz)&lt;/a&gt;&lt;/h4&gt;

&lt;div class=&quot;tweet&quot;&gt; &lt;a href=&quot;https://twitter.com/ach0w&quot; target=&quot;_blank&quot;&gt;@ach0w&lt;/a&gt; &lt;a href=&quot;https://twitter.com/juux&quot; target=&quot;_blank&quot;&gt;@juux&lt;/a&gt; &lt;a href=&quot;https://twitter.com/samsaffron&quot; target=&quot;_blank&quot;&gt;@samsaffron&lt;/a&gt; &lt;a href=&quot;https://twitter.com/codinghorror&quot; target=&quot;_blank&quot;&gt;@codinghorror&lt;/a&gt; At work we were comparing our test suite on the same MBP hardware MacOS vs Ubuntu - Ubuntu running around 20-30% faster 👌&lt;/div&gt;

&lt;div class=&quot;date&quot;&gt;
  &lt;a href=&quot;https://twitter.com/zalesz/status/1111726682115899393&quot; target=&quot;_blank&quot;&gt;8:27 PM - 29 Mar 2019&lt;/a&gt;
    &lt;span class=&quot;like&quot;&gt;
      &lt;svg viewbox=&quot;0 0 512 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 43
    &lt;/span&gt;
    &lt;span class=&quot;retweet&quot;&gt;
      &lt;svg viewbox=&quot;0 0 640 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M629.657 343.598L528.971 444.284c-9.373 9.372-24.568 9.372-33.941 0L394.343 343.598c-9.373-9.373-9.373-24.569 0-33.941l10.823-10.823c9.562-9.562 25.133-9.34 34.419.492L480 342.118V160H292.451a24.005 24.005 0 0 1-16.971-7.029l-16-16C244.361 121.851 255.069 96 276.451 96H520c13.255 0 24 10.745 24 24v222.118l40.416-42.792c9.285-9.831 24.856-10.054 34.419-.492l10.823 10.823c9.372 9.372 9.372 24.569-.001 33.941zm-265.138 15.431A23.999 23.999 0 0 0 347.548 352H160V169.881l40.416 42.792c9.286 9.831 24.856 10.054 34.419.491l10.822-10.822c9.373-9.373 9.373-24.569 0-33.941L144.971 67.716c-9.373-9.373-24.569-9.373-33.941 0L10.343 168.402c-9.373 9.373-9.373 24.569 0 33.941l10.822 10.822c9.562 9.562 25.133 9.34 34.419-.491L96 169.881V392c0 13.255 10.745 24 24 24h243.549c21.382 0 32.09-25.851 16.971-40.971l-16.001-16z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 6
    &lt;/span&gt;
&lt;/div&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;It appears that people insisting on the &lt;strong&gt;native&lt;/strong&gt; MacOS experience are paying a significant tax for developing Ruby on Rails on a Mac.&lt;/p&gt;
&lt;p&gt;I know that DHH loves his iMac Pro and recommends it enormously.&lt;/p&gt;
&lt;aside class=&quot;onebox twitterstatus&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://twitter.com/dhh/status/940658254501302274&quot; target=&quot;_blank&quot;&gt;twitter.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;img src=&quot;https://pbs.twimg.com/profile_images/975876868455809024/eK7mDppU_400x400.jpg&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;400&quot; height=&quot;400&quot;&gt;

&lt;h4&gt;&lt;a href=&quot;https://twitter.com/dhh/status/940658254501302274&quot; target=&quot;_blank&quot;&gt;DHH (dhh)&lt;/a&gt;&lt;/h4&gt;

&lt;div class=&quot;tweet&quot;&gt; Apple sent me an iMac Pro to play with and not only is it an awesome machine, it looks ace as… &lt;a target=&quot;_blank&quot; href=&quot;https://www.instagram.com/p/BcnPtAwlAKe/&quot;&gt;instagram.com/p/BcnPtAwlAKe/&lt;/a&gt;
&lt;/div&gt;

&lt;div class=&quot;date&quot;&gt;
  &lt;a href=&quot;https://twitter.com/dhh/status/940658254501302274&quot; target=&quot;_blank&quot;&gt;7:02 PM - 12 Dec 2017&lt;/a&gt;
    &lt;span class=&quot;like&quot;&gt;
      &lt;svg viewbox=&quot;0 0 512 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 490
    &lt;/span&gt;
    &lt;span class=&quot;retweet&quot;&gt;
      &lt;svg viewbox=&quot;0 0 640 512&quot; width=&quot;14px&quot; height=&quot;16px&quot; aria-hidden=&quot;true&quot;&gt;
        &lt;path d=&quot;M629.657 343.598L528.971 444.284c-9.373 9.372-24.568 9.372-33.941 0L394.343 343.598c-9.373-9.373-9.373-24.569 0-33.941l10.823-10.823c9.562-9.562 25.133-9.34 34.419.492L480 342.118V160H292.451a24.005 24.005 0 0 1-16.971-7.029l-16-16C244.361 121.851 255.069 96 276.451 96H520c13.255 0 24 10.745 24 24v222.118l40.416-42.792c9.285-9.831 24.856-10.054 34.419-.492l10.823 10.823c9.372 9.372 9.372 24.569-.001 33.941zm-265.138 15.431A23.999 23.999 0 0 0 347.548 352H160V169.881l40.416 42.792c9.286 9.831 24.856 10.054 34.419.491l10.822-10.822c9.373-9.373 9.373-24.569 0-33.941L144.971 67.716c-9.373-9.373-24.569-9.373-33.941 0L10.343 168.402c-9.373 9.373-9.373 24.569 0 33.941l10.822 10.822c9.562 9.562 25.133 9.34 34.419-.491L96 169.881V392c0 13.255 10.745 24 24 24h243.549c21.382 0 32.09-25.851 16.971-40.971l-16.001-16z&quot;&gt;&lt;/path&gt;
      &lt;/svg&gt; 68
    &lt;/span&gt;
&lt;/div&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;Yes, the hardware is real nice, the screen is beautiful, the machine is wonderfully put together. The Window manager is nice. Zero driver problems. However, sadly, there is a significant OS tax being paid sticking on MacOS for Ruby on Rails development.&lt;/p&gt;
&lt;p&gt;I think the Ruby community should explore this problem, document the extent of this problem and see if anything can be done to bring Darwin closer to the numbers the same machine does with Linux. Is this problem rooted in the filesystem? The OS? The llvm compile of Ruby? Security features in MacOS? Something about how Spectre+Meltdown (which is already patched in my Linux)? It is very unclear.&lt;/p&gt;
&lt;p&gt;As it stands I would not be surprised at all if you dual booted a Mac with Windows, installed WSL and got &lt;strong&gt;better&lt;/strong&gt; performance running the Discourse test suite on Mac+Windows+WSL. In fact I am willing to take bets you would.&lt;/p&gt;
&lt;p&gt;So, to all those people who say… oh there is an alternative … just hackintosh your way out of this mess. Not only are you stuck playing Russian roulette every MacOS update, you are also paying a tax which is similar to the tax you are paying on Windows already.&lt;/p&gt;
&lt;h3&gt;What about parallel testing?&lt;/h3&gt;
&lt;p&gt;Rails 6 is just around the corner. This is the first time Rails is going to ship with officially supported and sanctioned parallel testing. When I run the Discourse spec suite on my Linux system CPU barely scratches the 10% mark for the whole 8 minutes the test suite is running, IO is not saturated.&lt;/p&gt;
&lt;p&gt;Here I am freaking out about a measly 38% perf hit when I could be running stuff concurrently and probably be able to run our entire test suite in 2 minutes on my current machine on Windows in a VM.&lt;/p&gt;
&lt;p&gt;It may feel a bit odd to be making such a big deal prior to taking care of the obvious elephant in the room.&lt;/p&gt;
&lt;p&gt;I completely agree, parallel testing is an amazing thing for Rails, this is going to make a lot of developers extremely happy.&lt;/p&gt;
&lt;p&gt;Also, profiling our test suite, eliminating and improving slow tests is super important.&lt;/p&gt;
&lt;p&gt;We are going to adopt parallel testing for our dev environments this year.&lt;/p&gt;
&lt;p&gt;But I guess this was not my point here. My issue is that we I was driving with the hand break on.  Even when our test suite gets faster, the hand break will remain on.&lt;/p&gt;
&lt;h3&gt;Where am I headed?&lt;/h3&gt;
&lt;p&gt;I am feeling significantly happier in my Arch Linux home. In a pretty surprising turn of events not only is stuff much faster for me, I also feel significantly more productive at work due to having a windows manager that works much better for me than my Mac or Windows setups ever did. Yes there are compromises, I need to get my hands far dirtier than I had to in the past. However the payoff has been huge.&lt;/p&gt;
&lt;p&gt;I have been a long time &lt;a href=&quot;https://i3wm.org/&quot;&gt;I3wm&lt;/a&gt; user, however I never got the proper experience being straddled in the middle of 2 windows managers. Now that i3 is my only windows manager I am unlocking tremendous amount of value out of it.&lt;/p&gt;
&lt;p&gt;Why, you ask? Well I plan to write a bit about my experience over the next few weeks. My plan is to try out a different tiling windows manager every month for the next few months to find the flavor that fits me best.&lt;/p&gt;
&lt;p&gt;I stuck with Windows for 6 years developing an application that works best on Linux because I was comfortable in Windows. Habits are incredibly hard to break. I was not fully aware what price I was paying. I can also assure you many other developers are in the same boat as I was.&lt;/p&gt;
&lt;p&gt;If I have one piece of advice here, it is … don’t be afraid to experiment. Linux on the desktop is getting better, it is reasonably straight forward to re-partition a drive and setup a dual booting system. If you are in the same boat as I was, living between 2 worlds, especially if you are on a desktop and not a laptop, take a break and experiment.&lt;/p&gt;
&lt;p&gt;Please feel free to post any of your experiences or benchmarks here, I will try to answer every post on my blog carefully. I am curious to see more benchmarks from more people comparing MacOS to Linux on the same computer or Windows+WSL / VM and Linux.&lt;/p&gt;
&lt;p&gt;And as always … enjoy.&lt;/p&gt;</description>
      <pubDate>Sun, 31 Mar 2019 23:44:35 +0000</pubDate>
      <link>https://samsaffron.com/archive/2019/03/31/why-i-stuck-with-windows-for-6-years-while-developing-discourse</link>
    </item>
    <item>
      <title>Logster and our error logging strategy at Discourse</title>
      <description>
&lt;p&gt;I have always been &lt;a href=&quot;https://stackoverflow.com/questions/124275/does-anyone-know-of-any-cross-platform-gui-log-viewers-for-ruby-on-rails&quot; rel=&quot;nofollow noopener&quot;&gt;somewhat fascinated with logs&lt;/a&gt;. I tend to see the warning and error logs in production as a valuable heartbeat of an application. Proper handling of error logs is a very strong complement to a robust test suite. It shows us what &lt;strong&gt;really happens&lt;/strong&gt; when real world data meets our application.&lt;/p&gt;
&lt;p&gt;9 years ago, at Stack Overflow we had a daily ritual where we would open up our fork of &lt;a href=&quot;https://elmah.github.io/&quot; rel=&quot;nofollow noopener&quot;&gt;ELMAH&lt;/a&gt; every morning and fish through our logs for problems. This had a dramatic positive effect on Stack Overflow.&lt;/p&gt;
&lt;p&gt;Almost 7 years into our journey building Discourse, every single week we find and fix issues in our application thanks to our error logs and Logster. Error logs are the pulse of our application, they let us know immediately if there are any urgent issues and where. Since we host more than 1500 sites running many different code branches, we needed to evolve a sane and robust set of practices and tools.&lt;/p&gt;
&lt;h3&gt;Top level structure of logging and monitoring at Discourse&lt;/h3&gt;
&lt;p&gt;We have lots of logs at Discourse and many systems for dealing with them.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We keep raw Docker, Postgres, Redis, NGINX, Rails and HAProxy and so on in &lt;a href=&quot;https://www.elastic.co/&quot; rel=&quot;nofollow noopener&quot;&gt;Elastic Search&lt;/a&gt; and use &lt;a href=&quot;https://www.elastic.co/products/kibana&quot; rel=&quot;nofollow noopener&quot;&gt;Kibana&lt;/a&gt; for business intelligence.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We have a monitoring system built on &lt;a href=&quot;https://prometheus.io/docs/alerting/alertmanager/&quot; rel=&quot;nofollow noopener&quot;&gt;alertmanager&lt;/a&gt;  and &lt;a href=&quot;https://prometheus.io/&quot; rel=&quot;nofollow noopener&quot;&gt;Prometheus&lt;/a&gt;, with business intelligence in &lt;a href=&quot;https://grafana.com/&quot; rel=&quot;nofollow noopener&quot;&gt;Grafana&lt;/a&gt; and alert escalation in our internal Discourse instance and opsgenie.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We have &lt;code&gt;logster&lt;/code&gt; which we use for web application aka. “Rails / Sidekiq” warnings and errors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I would like to focus on logster and our Rails / Sidekiq portion for this blog post, but think it is worth mentioning other mechanisms cause I don’t want people to think we are not good data hoarders and only have very limited visibility into our systems.&lt;/p&gt;
&lt;h3&gt;About Logster&lt;/h3&gt;
&lt;p&gt;At Discourse we developed a log viewer called &lt;a href=&quot;https://github.com/discourse/logster&quot; rel=&quot;nofollow noopener&quot;&gt;logster&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/discourse/logster&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/4/4fed1ad24f8102e7492b645a18827dc1a747b855.png&quot; alt=&quot;logo-logster-cropped-small&quot; width=&quot;180&quot; height=&quot;93&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Logster is a free and open source tool you can &lt;strong&gt;embed&lt;/strong&gt; into any Ruby on Rails or Rack application in production and development. It runs as Rack middleware and uses Redis as its backend for log storage and analysis.&lt;/p&gt;
&lt;p&gt;It operates in two different modes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In production mode it aggregates similar errors by fingerprinting backtraces listening for warnings/errors and fatal messages. The intention is to display a list of open application problems that can somehow be resolved.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In development mode it provides a full fire-hose of all logs produced by Rails. (debug and up). This has significant advantages over console as you have proper access to backtraces for every log line.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are a few screenshots from logs on this very blog (accessible to admins at &lt;code&gt;https://discuss.samsaffron.com/logs&lt;/code&gt;):&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/5/59a024e066027c4430e36833e6c9210f7127ace5.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/59a024e066027c4430e36833e6c9210f7127ace5&quot; title=&quot;image.png&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/5/59a024e066027c4430e36833e6c9210f7127ace5_2_690x506.png&quot; alt=&quot;image&quot; width=&quot;690&quot; height=&quot;506&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/5/59a024e066027c4430e36833e6c9210f7127ace5_2_690x506.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/5/59a024e066027c4430e36833e6c9210f7127ace5_2_1035x759.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/5/59a024e066027c4430e36833e6c9210f7127ace5_2_1380x1012.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/5/59a024e066027c4430e36833e6c9210f7127ace5_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image.png&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1930×1418 359 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;Each error log has a full backtrace&lt;/small&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/7/7477466858489d1a0ca7b74a866e3d3592ec4a38.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/7477466858489d1a0ca7b74a866e3d3592ec4a38&quot; title=&quot;image.png&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/7/7477466858489d1a0ca7b74a866e3d3592ec4a38_2_690x506.png&quot; alt=&quot;image&quot; width=&quot;690&quot; height=&quot;506&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/7/7477466858489d1a0ca7b74a866e3d3592ec4a38_2_690x506.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/7/7477466858489d1a0ca7b74a866e3d3592ec4a38_2_1035x759.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/7/7477466858489d1a0ca7b74a866e3d3592ec4a38_2_1380x1012.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/7/7477466858489d1a0ca7b74a866e3d3592ec4a38_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image.png&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1928×1414 336 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;Web requests have extensive environment info, including path, ip address and user agent.&lt;/small&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Logster has accumulated a large amount of very useful features over the years, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The ability to suppress errors from the logs until the application is upgraded. (The &lt;code&gt;solve&lt;/code&gt; button)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The ability to protect certain log messages so they are not purged when clear all is clicked.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Advanced filtering, including regex and reverse regex search&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Custom environment (ability to tag current thread with arbitrary metadata)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;JavaScript error and backtrace support&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rich API allowing you to suppress patterns, ship errors from other instances, integrate automatically into Rails and so on.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Logter project is still very much alive, recently our part time developer Osama added a mobile view and upgraded the Ember frontend to latest Ember. We have many exciting new features planned for 2019!&lt;/p&gt;
&lt;h3&gt;Giving up on tail -f logs/development.log&lt;/h3&gt;
&lt;p&gt;I do not remember the last time I tailed logs in development. There are a few reasons this does not happen anymore.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Most of the time when building stuff I use TDD, using our &lt;code&gt;rake autospec&lt;/code&gt; tool. I will focus on one broken test. Every time I save a file it automatically triggers the test to re-run, if I need extra diagnostics I &lt;a href=&quot;https://tenderlovemaking.com/2016/02/05/i-am-a-puts-debuggerer.html&quot; rel=&quot;nofollow noopener&quot;&gt;sprinkle puts statements&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If I am dealing with a specific error on a page I often find working with &lt;a href=&quot;https://github.com/BetterErrors/better_errors&quot; rel=&quot;nofollow noopener&quot;&gt;better_errors&lt;/a&gt; far more effective than reading logs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If I need access to logs I will always prefer using logster in development. It allows me to filter using a text pattern or log level which is a huge time saver. It also provides information that is completely absent from the Rails logs on a per-line basis (environment and backtrace).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;div class=&quot;lightbox-wrapper&quot;&gt;&lt;a class=&quot;lightbox&quot; href=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/1/12f80994d248a17f33b8bec705afde41936a75cb.png&quot; data-download-href=&quot;https://discuss.samsaffron.com/uploads/default/12f80994d248a17f33b8bec705afde41936a75cb&quot; title=&quot;image.png&quot;&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/1/12f80994d248a17f33b8bec705afde41936a75cb_2_690x398.png&quot; alt=&quot;image&quot; width=&quot;690&quot; height=&quot;398&quot; srcset=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/1/12f80994d248a17f33b8bec705afde41936a75cb_2_690x398.png, https://discuss.samsaffron.com/uploads/default/optimized/2X/1/12f80994d248a17f33b8bec705afde41936a75cb_2_1035x597.png 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/1/12f80994d248a17f33b8bec705afde41936a75cb_2_1380x796.png 2x&quot; data-small-upload=&quot;https://discuss.samsaffron.com/uploads/default/optimized/2X/1/12f80994d248a17f33b8bec705afde41936a75cb_2_10x10.png&quot;&gt;&lt;div class=&quot;meta&quot;&gt;
&lt;svg class=&quot;fa d-icon d-icon-far-image svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#far-image&quot;&gt;&lt;/use&gt;&lt;/svg&gt;&lt;span class=&quot;filename&quot;&gt;image.png&lt;/span&gt;&lt;span class=&quot;informations&quot;&gt;1938×1120 303 KB&lt;/span&gt;&lt;svg class=&quot;fa d-icon d-icon-discourse-expand svg-icon&quot; aria-hidden=&quot;true&quot;&gt;&lt;use xlink:href=&quot;#discourse-expand&quot;&gt;&lt;/use&gt;&lt;/svg&gt;
&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;small&gt;I sprinkled &lt;code&gt;Rails.logger.warn(&quot;someone called featured users, I wonder who?&quot;)&lt;/code&gt; and filtered on “featured”&lt;/small&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h3&gt;Death by 10,000 log messages in production&lt;/h3&gt;
&lt;p&gt;Logster attempts to provide some shielding against log floods by grouping based off stack traces. That said, we must be very diligent to keep our logs “under control”.&lt;/p&gt;
&lt;p&gt;For the purpose of our &lt;code&gt;Logster&lt;/code&gt; application logs usage we like to keep the screens focused on “actionable” errors and warnings. Many errors and warnings that get logged by default have no action we can take to resolve. We can deal with these elsewhere (offending IPs can be blocked after N requests and so on).&lt;/p&gt;
&lt;p&gt;Here are a non exhaustive example of some “errors” that we really have no way of dealing with so they do not belong in Logster.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A rogue IP making a web request with corrupt parameter encoding&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A 404 to &lt;code&gt;index.php&lt;/code&gt; which we really do not care about&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rate limiting … for example a user posting too fast or liking too fast&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rogue users making a requests with an unknown HTTP verbs&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another interesting point about our use of Logster is that not all errors that float into our logs mean that we have a broken line of code in our application that needs fixing. In some cases a backup redis or db server can be broken so we will log that fact. In some cases there is data corruption that the application can pick up and log. Sometimes transactions can deadlock.&lt;/p&gt;
&lt;p&gt;Keeping our Logster logs useful is extremely important. If we ignore in-actionable errors for long enough we can end up with a useless error log where all we have is noise.&lt;/p&gt;
&lt;h3&gt;Proactively logging issues&lt;/h3&gt;
&lt;p&gt;Given we have a high visibility place to look at errors. We will sometimes use our error logs to proactively report problems before a disaster hits.&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://github.com/discourse/discourse/blob/a19170a4c2c37bb6f6ae9531fe4f925777f3e8d5/lib/scheduler/defer.rb#L91-L93&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/discourse/discourse/blob/a19170a4c2c37bb6f6ae9531fe4f925777f3e8d5/lib/scheduler/defer.rb#L91-L93&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;discourse/discourse/blob/a19170a4c2c37bb6f6ae9531fe4f925777f3e8d5/lib/scheduler/defer.rb#L91-L93&lt;/a&gt;&lt;/h4&gt;
&lt;pre class=&quot;onebox&quot;&gt;&lt;code class=&quot;lang-rb&quot;&gt;&lt;ol class=&quot;start lines&quot; start=&quot;91&quot; style=&quot;counter-reset: li-counter 90 ;&quot;&gt;
&lt;li&gt;warning_job = @reactor.queue(@timeout) do&lt;/li&gt;
&lt;li&gt;  Rails.logger.error &quot;'#{desc}' is still running after #{@timeout} seconds on db #{db}, this process may need to be restarted!&quot;&lt;/li&gt;
&lt;li&gt;end if !non_block&lt;/li&gt;
&lt;/ol&gt;&lt;/code&gt;&lt;/pre&gt;


  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;In this case we are watching our “defer” queue, which is a special thread we have for light-weight jobs that run between requests on our web workers in a background thread. We need this queue to be serviced quickly if it is taking longer than 30 seconds per job we have a problem… but not necessarily a disaster. By reporting about this early we can correct issues in the job queue early, rather than dealing with the much more complex task of debugging “queue starvation” way down the line. (which we also monitor for)&lt;/p&gt;
&lt;h3&gt;The logs hot potato game &lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/potato.png?v=9&quot; title=&quot;:potato:&quot; class=&quot;emoji&quot; alt=&quot;:potato:&quot;&gt;
&lt;/h3&gt;
&lt;p&gt;Half a year ago or so we introduced a fantastic game within our development team. The idea is very simple. Every developer attempts to correct an issue raised in our error logs and then assigns to the next person on the list.&lt;/p&gt;
&lt;p&gt;We attempted many other patterns in the past, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Having our internal Discourse instance raise a big warning when too many errors are in the logs (which we still use)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Having “log parties” where a single team member triages the logs and assigns issues from the logs to other team members.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Having arbitrary triage and assign.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The “logs game” has proven the most effective at resolving a significant number of issues while keeping the entire team engaged.&lt;/p&gt;
&lt;p&gt;We structure the game by having a dedicated Discourse topic in our internal instance with a list of names.&lt;/p&gt;
&lt;p&gt;When we resolve issues based on log messages we share the resolution with the team. That way as the game progresses more people learn how to play it and more people learn about our application.&lt;/p&gt;
&lt;p&gt;Once resolved, the team member hands the torch to the next person on the list. And so it goes.&lt;/p&gt;
&lt;p&gt;This helps all of us get a holistic picture of our system, if logs are complaining that our backup redis instance can not be contacted, this may be a provisioning bug that needed fixing. For the purpose of the “logs game” fixing system issues is also completely legitimate, even though no line of code was committed to Discourse to fix it.&lt;/p&gt;
&lt;h3&gt;Should my Ruby web app be using Logster?&lt;/h3&gt;
&lt;p&gt;There are many other products for dealing with errors in production. When we started at Discourse we used &lt;a href=&quot;https://github.com/errbit/errbit&quot; rel=&quot;nofollow noopener&quot;&gt;errbit&lt;/a&gt; these days you have many other options such as &lt;a href=&quot;https://sentry.io/&quot; rel=&quot;nofollow noopener&quot;&gt;sentry&lt;/a&gt;, &lt;a href=&quot;https://airbrake.io/&quot; rel=&quot;nofollow noopener&quot;&gt;airbrake&lt;/a&gt; or &lt;a href=&quot;https://raygun.com/&quot; rel=&quot;nofollow noopener&quot;&gt;raygun&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One big advantage Logster has is that it can be embedded so you get to use the same tool in development and production with a very simple setup. Once you add it to your Gemfile you are seconds away from accessing logs at &lt;code&gt;/logs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;On the other hand the for-pay dedicated tools out there have full time development teams building them with 100s of amazing features.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/discourse/logster&quot; rel=&quot;nofollow noopener&quot;&gt;Logster&lt;/a&gt; is designed so it can work side-by-side with other tools, if you find you need other features you could always add an additional error reporter (or submit a PR to Logster).&lt;/p&gt;
&lt;p&gt;Regardless of what you end up choosing, I recommend you choose something, there is enormous value in regular audits of errors and better visibility of real world problems your customers are facing.&lt;/p&gt;</description>
      <pubDate>Wed, 02 Jan 2019 07:11:20 +0000</pubDate>
      <link>https://samsaffron.com/archive/2018/12/27/logster-and-our-logging-strategy-at-discourse</link>
    </item>
    <item>
      <title>Finding where STDOUT/STDERR debug messages are coming from</title>
      <description>
&lt;p&gt;Recently, we have been experiencing “stalls” in the &lt;a href=&quot;https://github.com/puma/puma&quot; rel=&quot;nofollow noopener&quot;&gt;Puma&lt;/a&gt; web server in development, this means that quite often during our dev cycle we would hit &lt;code&gt;CTRL-C&lt;/code&gt; and be stuck waiting many many seconds for Puma to stop. Sometimes needing to fallback to &lt;code&gt;kill -9&lt;/code&gt; on the Puma process.&lt;/p&gt;
&lt;p&gt;We definitely want this Puma issue fixed, however our “web application server of choice” is &lt;a href=&quot;https://bogomips.org/unicorn/&quot; rel=&quot;nofollow noopener&quot;&gt;Unicorn&lt;/a&gt; not Puma. It makes little sense for us to run Puma in development. Our Unicorn configuration is &lt;a href=&quot;https://github.com/discourse/discourse/blob/master/config/unicorn.conf.rb&quot; rel=&quot;nofollow noopener&quot;&gt;very mature&lt;/a&gt; and handles all sorts of magic including automatic forking of our &lt;a href=&quot;https://github.com/mperham/sidekiq&quot; rel=&quot;nofollow noopener&quot;&gt;Sidekiq&lt;/a&gt; job scheduler which is awesome in dev.&lt;/p&gt;
&lt;p&gt;A major problem though is that when we run Puma in dev our console is pristine, run Unicorn in dev and it is noise central.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;127.0.0.1 - - [07/Aug/2018:15:38:59 +1000] &quot;GET /assets/pretty-text-bundle.js?1533620338.6222095 HTTP/1.1&quot; 200 112048 0.0481
127.0.0.1 - - [07/Aug/2018:15:38:59 +1000] &quot;GET /assets/plugin.js?1533620338.6222444 HTTP/1.1&quot; 200 146176 0.0726
127.0.0.1 - - [07/Aug/2018:15:38:59 +1000] &quot;GET /assets/plugin-third-party.js?1533620338.6222594 HTTP/1.1&quot; 200 3364 0.0569
127.0.0.1 - - [07/Aug/2018:15:38:59 +1000] &quot;GET /assets/application.js?1533620338.6222193 HTTP/1.1&quot; 200 3039095 0.2049
127.0.0.1 - - [07/Aug/2018:15:38:59 +1000] &quot;GET /assets/fontawesome-webfont.woff2?http://l.discourse&amp;amp;2&amp;amp;v=4.7.0 HTTP/1.1&quot; 304 - 0.0016
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://tenderlovemaking.com/2016/02/05/i-am-a-puts-debuggerer.html&quot; rel=&quot;nofollow noopener&quot;&gt;I am a puts debugger&lt;/a&gt; and being barred from being a puts debugger in development is a blocking feature for me.&lt;/p&gt;
&lt;p&gt;So, how do we find where these messages are coming from?&lt;/p&gt;
&lt;p&gt;Before we start the little tip here first… if you have not yet… take a break and read _why’s classic &lt;a href=&quot;https://viewsourcecode.org/why/hacking/seeingMetaclassesClearly.html&quot; rel=&quot;nofollow noopener&quot;&gt;seeing metaclasses clearly&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now that you know about metaclasses, time to have some fun, let’s reopen STDERR and glue a little debug method to it that will output caller locations when we invoke write on STDERR (note this will work on STDOUT as well if you want):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;class &amp;lt;&amp;lt; STDERR
  alias_method :orig_write, :write
  def write(x)
    orig_write(caller[0..3].join(&quot;\n&quot;))
    orig_write(x)
  end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;/home/sam/.rbenv/versions/2.5.1/lib/ruby/gems/2.5.0/gems/rack-2.0.5/lib/rack/common_logger.rb:61:in `log'
/home/sam/.rbenv/versions/2.5.1/lib/ruby/gems/2.5.0/gems/rack-2.0.5/lib/rack/common_logger.rb:35:in `block in call'
/home/sam/.rbenv/versions/2.5.1/lib/ruby/gems/2.5.0/gems/rack-2.0.5/lib/rack/body_proxy.rb:23:in `close'
/home/sam/.rbenv/versions/2.5.1/lib/ruby/gems/2.5.0/gems/rack-2.0.5/lib/rack/chunked.rb:34:in `close'
127.0.0.1 - - [07/Aug/2018:15:44:57 +1000] &quot;POST /mini-profiler-resources/results HTTP/1.1&quot; 200 - 0.0109
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, there you have it this line is coming from &lt;a href=&quot;https://www.rubydoc.info/gems/rack/Rack/CommonLogger&quot; rel=&quot;nofollow noopener&quot;&gt;CommonLogger&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However… Discourse does not use the &lt;code&gt;Rack::CommonLogger&lt;/code&gt; middleware… a little bit more hunting we can find out &lt;a href=&quot;https://bogomips.org/unicorn/unicorn_1.html&quot; rel=&quot;nofollow noopener&quot;&gt;that unicorn&lt;/a&gt; will always load &lt;code&gt;Rack::CommonLogger, Rack::ShowExceptions, and Rack::Lint middleware&lt;/code&gt; in development and it has a little command line option of &lt;code&gt;-N&lt;/code&gt; or &lt;code&gt;--no-default-middleware&lt;/code&gt; to disable this behavior.&lt;/p&gt;
&lt;p&gt;This tip is handy for a large number of issues you can encounter, be it stray messages in your test suite or leftover &lt;code&gt;puts&lt;/code&gt; in some gem you upgraded. And as always, enjoy.&lt;/p&gt;</description>
      <pubDate>Tue, 07 Aug 2018 06:06:55 +0000</pubDate>
      <link>https://samsaffron.com/archive/2018/08/07/finding-where-stdout-stderr-debug-messages-are-coming-from</link>
    </item>
    <item>
      <title>Ruby's external malloc problem</title>
      <description>
&lt;p&gt;I have blogged a bit about the &lt;a href=&quot;https://samsaffron.com/archive/2013/11/22/demystifying-the-ruby-gc&quot; rel=&quot;nofollow noopener&quot;&gt;Ruby GC&lt;/a&gt; previously and covered some basics about malloc triggering GC runs. Over the years much in that blog post has been addressed in Ruby including dynamically growing malloc limits that mean we very rarely would need to amend malloc related GC vars.&lt;/p&gt;
&lt;p&gt;As an aside, the only GC var Discourse still overrides is RUBY_GLOBAL_METHOD_CACHE_SIZE for reasons that are specified in the &lt;a href=&quot;https://engineering.shopify.com/17489064-tuning-rubys-global-method-cache&quot; rel=&quot;nofollow noopener&quot;&gt;Shopify blog post&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/planetscott&quot; rel=&quot;nofollow noopener&quot;&gt;Scott Francis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The GC in Ruby can be triggered by 2 different types of conditions.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;We are out of space in our managed heaps.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We detected that data associated with Ruby objects via malloc calls has grown beyond a certain threshold.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this blog post I am covering (2) and demonstrating what happens when Ruby &lt;strong&gt;is not aware&lt;/strong&gt; of malloc calls.&lt;/p&gt;
&lt;h3&gt;Why malloc calls can trigger a GC?&lt;/h3&gt;
&lt;p&gt;When reading through &lt;code&gt;GC.stat&lt;/code&gt; we may be a bit surprised to see the amount of malloc related accounting:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;malloc_increase_bytes
malloc_increase_bytes_limit
oldmalloc_increase_bytes
oldmalloc_increase_bytes_limit
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We keep track of the amount of memory allocated using malloc, if it hits the &lt;code&gt;malloc_increase_bytes_limit&lt;/code&gt; we will trigger a minor GC.&lt;/p&gt;
&lt;p&gt;When we promote an object to the old generation we also try to estimate how much malloc increased since the last major GC. This way when we promote large objects from a young heap to an old heap we have a chance to GC as soon &lt;code&gt;oldmalloc_increase_bytes_limit&lt;/code&gt; is hit.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;oldmalloc_increase_bytes_limit&lt;/code&gt; and &lt;code&gt;malloc_increase_bytes_limit&lt;/code&gt; dynamically size themselves growing as we hit GCs due to malloc limits.&lt;/p&gt;
&lt;h3&gt;Seeing this in action&lt;/h3&gt;
&lt;p&gt;Having this in place allows us to run code like this without bloating memory:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;def count_malloc(desc)
  start = GC.stat[:malloc_increase_bytes]
  yield
  delta = GC.stat[:malloc_increase_bytes] - start
  puts &quot;#{desc} allocated #{delta} bytes&quot;
end

def process_rss
  puts 'RSS is: ' + `ps -o rss -p #{$$}`.chomp.split(&quot;\n&quot;).last
end

def malloc_limits
  s = GC.stat
  puts &quot;malloc limit #{s[:malloc_increase_bytes_limit]}, old object malloc limit #{s[:oldmalloc_increase_bytes_limit]}&quot;
end

puts &quot;start RSS/limits&quot;
process_rss
malloc_limits

count_malloc(&quot;100,000 byte string&quot;) do
  &quot;x&quot; * 100_000
end

x = []
10_000.times do |i|
  x[i%10]  = &quot;x&quot; * 100_000
end

puts &quot;RSS/limits after allocating 10k 100,000 byte string&quot;
malloc_limits
process_rss

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Result is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;start RSS/limits
RSS is: 11692

malloc limit 16777216, old object malloc limit 16777216
100,000 byte string allocated 103296 bytes

RSS/limits after allocating 10k 100,000 byte string
malloc limit 32883343, old object malloc limit 78406160

RSS is: 42316
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key figures to watch here is.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;malloc_increase_bytes_limit&lt;/code&gt; starts at 16MB and moves up to 32MB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;oldmalloc_increase_bytes_limit&lt;/code&gt; starts at 16MB and moves up to 78MB&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RSS moves up from 11MB to 42MB&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To recap this is a fairly well behaved non bloated process, despite allocating pretty gigantic objects (strings that have 100,000 bytes in them) and retaining a handful (10).&lt;/p&gt;
&lt;p&gt;This is what we want and it gets a stamp of approval!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/uploads/default/original/2X/d/d3b835120db32cb42522e7fdc021bb91d721d53d.jpg&quot; alt=&quot;image&quot; width=&quot;112&quot; height=&quot;119&quot;&gt;&lt;/p&gt;
&lt;h3&gt;Where malloc accounting falls over!&lt;/h3&gt;
&lt;p&gt;Ruby does not “monkey patch” the libc malloc function to figure out how much memory got allocated.&lt;/p&gt;
&lt;p&gt;It requires c extension authors to be very careful about how they allocate memory, in particular extension authors are expected to use all sorts of helper macros and functions when allocating and converting memory that will be &lt;strong&gt;tied&lt;/strong&gt; to Ruby objects.&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://github.com/ruby/ruby/blob/96db72ce38b27799dd8e80ca00696e41234db6ba/include/ruby/ruby.h#L1594-L1598&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/ruby/ruby/blob/96db72ce38b27799dd8e80ca00696e41234db6ba/include/ruby/ruby.h#L1594-L1598&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;ruby/ruby/blob/96db72ce38b27799dd8e80ca00696e41234db6ba/include/ruby/ruby.h#L1594-L1598&lt;/a&gt;&lt;/h4&gt;
&lt;pre class=&quot;onebox&quot;&gt;&lt;code class=&quot;lang-h&quot;&gt;&lt;ol class=&quot;start lines&quot; start=&quot;1594&quot; style=&quot;counter-reset: li-counter 1593 ;&quot;&gt;
&lt;li&gt;#define ALLOC_N(type,n) RB_ALLOC_N(type,n)&lt;/li&gt;
&lt;li&gt;#define ALLOC(type) RB_ALLOC(type)&lt;/li&gt;
&lt;li&gt;#define ZALLOC_N(type,n) RB_ZALLOC_N(type,n)&lt;/li&gt;
&lt;li&gt;#define ZALLOC(type) RB_ZALLOC(type)&lt;/li&gt;
&lt;li&gt;#define REALLOC_N(var,type,n) RB_REALLOC_N(var,type,n)&lt;/li&gt;
&lt;/ol&gt;&lt;/code&gt;&lt;/pre&gt;


  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;Unfortunately, some gems that package up c libraries do not use the helpers in some cases. This is often nobody’s explicit fault, but a culmination of a very sad series of coincidences.&lt;/p&gt;
&lt;p&gt;I have been looking at improving Active Record performance recently and was very surprised to see this pattern everywhere:&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://github.com/rails/rails/blob/893ccb3d37c64b28c27c0f7a5790a69c6dc159ba/activerecord/lib/active_record/connection_adapters/postgresql/database_statements.rb#L80-L91&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/rails/rails/blob/893ccb3d37c64b28c27c0f7a5790a69c6dc159ba/activerecord/lib/active_record/connection_adapters/postgresql/database_statements.rb#L80-L91&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;rails/rails/blob/893ccb3d37c64b28c27c0f7a5790a69c6dc159ba/activerecord/lib/active_record/connection_adapters/postgresql/database_statements.rb#L80-L91&lt;/a&gt;&lt;/h4&gt;
&lt;pre class=&quot;onebox&quot;&gt;&lt;code class=&quot;lang-rb&quot;&gt;&lt;ol class=&quot;start lines&quot; start=&quot;80&quot; style=&quot;counter-reset: li-counter 79 ;&quot;&gt;
&lt;li&gt;def exec_query(sql, name = &quot;SQL&quot;, binds = [], prepare: false)&lt;/li&gt;
&lt;li&gt;  execute_and_clear(sql, name, binds, prepare: prepare) do |result|&lt;/li&gt;
&lt;li&gt;    types = {}&lt;/li&gt;
&lt;li&gt;    fields = result.fields&lt;/li&gt;
&lt;li&gt;    fields.each_with_index do |fname, i|&lt;/li&gt;
&lt;li&gt;      ftype = result.ftype i&lt;/li&gt;
&lt;li&gt;      fmod  = result.fmod i&lt;/li&gt;
&lt;li&gt;      types[fname] = get_oid_type(ftype, fmod, fname)&lt;/li&gt;
&lt;li&gt;    end&lt;/li&gt;
&lt;li&gt;    ActiveRecord::Result.new(fields, result.values, types)&lt;/li&gt;
&lt;li&gt;  end&lt;/li&gt;
&lt;li&gt;end&lt;/li&gt;
&lt;/ol&gt;&lt;/code&gt;&lt;/pre&gt;


  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;Every time we are running a piece of SQL and getting a perfectly good &lt;code&gt;PG::Result&lt;/code&gt; back we convert it to an array of arrays that is 100% materialized and manually discard the &lt;code&gt;PG::Result&lt;/code&gt; object. Why is this?&lt;/p&gt;
&lt;p&gt;Turns out, this is there for a very good reason ™&lt;/p&gt;
&lt;p&gt;If we adapt our sample to use the PG gem to allocate the strings we see this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;
require 'bundler/inline'

gemfile do
  source 'https://rubygems.org'
  gem 'pg'
end

require 'pg'

conn = PG.connect(dbname: 'test_db')
sql = &quot;select repeat('x', $1)&quot;

# simulate a Rails app by long term retaining 400_000 objects

puts &quot;start RSS/limits&quot;
process_rss
malloc_limits

count_malloc(&quot;100,000 bytes PG&quot;) do
  conn.exec(sql, [100_000])
end

x = []
10_000.times do |i|
  r = x[i%10] = conn.exec(sql, [100_000])
  r.clear
end

puts &quot;RSS/limits after allocating 10k 100,000 byte strings in libpq (and clearing)&quot;
malloc_limits
process_rss

10_000.times do |i|
  x[i%10] = conn.exec(sql, [100_000])
end

puts &quot;RSS/limits after allocating 10k 100,000 byte strings in libpq (and NOT clearing)&quot;
malloc_limits
process_rss
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We get this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;start RSS/limits
RSS is: 27392
malloc limit 16777216, old object malloc limit 16777216
100,000 bytes PG allocated 960 bytes
RSS/limits after allocating 10k 100,000 byte strings in libpq (and clearing)
malloc limit 16777216, old object malloc limit 16777216
RSS is: 27636
RSS/limits after allocating 10k 100,000 byte strings in libpq (and NOT clearing)
malloc limit 16777216, old object malloc limit 16777216
RSS is: 295500
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/warning.png?v=6&quot; title=&quot;:warning:&quot; class=&quot;emoji&quot; alt=&quot;:warning:&quot;&gt; our RSS just &lt;strong&gt;jumped to 295MB&lt;/strong&gt; when we forgot to run &lt;code&gt;#clear&lt;/code&gt; on the results PG gave us!!!&lt;/p&gt;
&lt;p&gt;Further more we can make the problem WAY worse if we simulate a Rails App by growing our Ruby heaps first with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;$long_term = []
400_000.times do
  $long_term &amp;lt;&amp;lt; +&quot;&quot;
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we run that code first we reach &lt;strong&gt;1GB of RSS&lt;/strong&gt; after “forgetting” to clear our &lt;code&gt;PG::Result&lt;/code&gt; object!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/fearful.png?v=6&quot; title=&quot;:fearful:&quot; class=&quot;emoji&quot; alt=&quot;:fearful:&quot;&gt; We can see PG allocated 100,000 bytes but Ruby was only aware of 960.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/tenderlove&quot; rel=&quot;nofollow noopener&quot;&gt;Aaron Patterson&lt;/a&gt; has been aware of this issue for many years, in fact he has attempted to patch &lt;a href=&quot;https://www.postgresql.org/docs/10/static/libpq.html&quot; rel=&quot;nofollow noopener&quot;&gt;libpq&lt;/a&gt; the library that powers the PG gem so it can handle this exact case gracefully.&lt;/p&gt;
&lt;p&gt;See: &lt;a href=&quot;https://www.postgresql.org/message-id/flat/20170828172834.GA71455%40TC.local#20170828172834.GA71455@TC.local&quot; class=&quot;inline-onebox&quot; rel=&quot;nofollow noopener&quot;&gt;PostgreSQL: Custom allocators in libpq&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;So where does this leave us?&lt;/h3&gt;
&lt;p&gt;At Discourse we notice occasional bloat in our Sidekiq process. This is despite being extremely careful to run a &lt;a href=&quot;https://www.mikeperham.com/2018/04/25/taming-rails-memory-bloat/&quot; rel=&quot;nofollow noopener&quot;&gt;specific version of jemalloc&lt;/a&gt;  that tames memory quite a bit.&lt;/p&gt;
&lt;p&gt;Now that I am aware of this vector I do have my suspicion that some “Raw SQL” helpers we have lurking in Discourse can cause this issue. In particular we have places that &lt;a href=&quot;https://github.com/discourse/discourse/blob/139d0813b4fd8ffff8eb03ae11a4836758e88256/lib/freedom_patches/active_record_base.rb#L4-L8&quot; rel=&quot;nofollow noopener&quot;&gt;return results directly&lt;/a&gt; in a &lt;code&gt;PG::Result&lt;/code&gt; object. In Sidekiq, under heavy concurrency with a very large heap these objects can sneak into the old generation and be retained for way too long leading to process bloat.&lt;/p&gt;
&lt;p&gt;This thorn also makes it very hard for us to tame Active Record memory usage cause we are stuck relying on copying entire result sets so we can stay safe, which is a very high priority for Rails.&lt;/p&gt;
&lt;p&gt;That said, I have not given up quite yet and see quite a few paths forward. (none of which conflict):&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;It would be nice to drive &lt;a href=&quot;https://www.postgresql.org/message-id/flat/20170828172834.GA71455%40TC.local#20170828172834.GA71455@TC.local&quot; rel=&quot;nofollow noopener&quot;&gt;Aaron’s patch&lt;/a&gt; home, if libpq provided better hooks for memory allocation we could nip this problem at the bud.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This would resolve the problem at the source&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Even if this is accepted today it will be many years till people can lean on this, requires a new version of libpq many people run 5 year old versions of it.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;It would be nice to have an API in libpq that allows us to interrogate how many bytes are allocated to a result it returns.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This would resolve the problem at the source.&lt;/li&gt;
&lt;li&gt;A much easier patch to land in libpq.&lt;/li&gt;
&lt;li&gt;Ruby 2.4 and up have &lt;code&gt;rb_gc_adjust_memory_usage&lt;/code&gt;, per &lt;a href=&quot;https://bugs.ruby-lang.org/issues/12690&quot; rel=&quot;nofollow noopener&quot;&gt;#12690&lt;/a&gt;, so it is simple to make this change. (Thanks Eric for the tip)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Same as above, will take many years till people can use it.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;PG gem can add a &lt;code&gt;Lazy&lt;/code&gt; results object.&lt;br&gt;
In this case we simply extend the PG gem API to return a copy of the results provided by libpq that allocates significantly less Ruby objects. Then once we have the copy we can clear the result we get from libpq.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;r = pg.exec('select * from table')
rs = r.result_set
r.clear

# at this point only 2 RVALUEs are allocated. 
# the new ResultSet object has internal c level storage
# pointing at an array of strings, and an API for access where it defer creates
# objects

row = rs[1]

### ResultSetRow is allocated, it also only allocates 1 RVALUE

row[&quot;abc&quot;] # allocates a new RVALUE or returns a cached internal instance 
row[1] # same

rs.get(1,100) # same as above
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;This drops in to ActiveRecord and other ORMs as the best practice for grabbing data if &lt;span class=&quot;hashtag&quot;&gt;#clear&lt;/span&gt; is not guaranteed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reasonably efficient, only allocates a very minimal number of Ruby objects&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We can start using this very soon&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We are forced to make memory copies of results returned via PG, this has a non zero cost (I suspect it is not too high though compared to 1000s of Ruby objects that need to be garbage collected with &lt;code&gt;#values&lt;/code&gt; calls)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Build tooling to detect this problem in production apps! It would be amazing if when we saw a Ruby app that is bloated in memory we could run a simple diagnostic on it to figure out where the bloat is coming from.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Is the bloat there due to &lt;a href=&quot;https://bugs.ruby-lang.org/issues/14718&quot; rel=&quot;nofollow noopener&quot;&gt;glibc arenas&lt;/a&gt;?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Is the bloat there cause Ruby is not aware of a bunch of allocated memory?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Is the bloat there due to a simple managed leak, eg: an ever growing array?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is a hard problem to solve though. jemalloc does provide a lot of internal diagnostics, so we could look at the delta between what jemalloc has allocated and what Ruby knows about!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Would increase visibility of this problem and the family of related problems and allow us to alert various gem authors if they are impacted by it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hard to build and may require a custom startup.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What we are doing?&lt;/h3&gt;
&lt;p&gt;I have invested many hours investigating these issues. &lt;a href=&quot;https://www.discourse.org/&quot; rel=&quot;nofollow noopener&quot;&gt;Discourse&lt;/a&gt; is &lt;strong&gt;actively&lt;/strong&gt; investing in improving the memory story in Ruby. Together with &lt;a href=&quot;https://www.shopify.com&quot; rel=&quot;nofollow noopener&quot;&gt;Shopify&lt;/a&gt; and &lt;a href=&quot;https://www.appfolio.com/&quot; rel=&quot;nofollow noopener&quot;&gt;Appfolio&lt;/a&gt; we are sponsoring Eric Wong to experiment and improve Ruby for the next few months.&lt;/p&gt;
&lt;p&gt;Discourse are also looking to throw more dollars behind a project to heavily improve Active Record for the 6.0 release which I plan to blog about soon. We also plan to extract, improve, formalize and share our built in raw SQL helpers.&lt;/p&gt;
&lt;p&gt;I hope you found this helpful and as always, enjoy!&lt;/p&gt;</description>
      <pubDate>Wed, 13 Jun 2018 04:20:53 +0000</pubDate>
      <link>https://samsaffron.com/archive/2018/06/13/ruby-x27-s-external-malloc-problem</link>
    </item>
    <item>
      <title>An analysis of memory bloat in Active Record 5.2</title>
      <description>
&lt;p&gt;One of the very noble goals the Ruby community which is being spearheaded by Matz is the &lt;a href=&quot;https://blog.heroku.com/ruby-3-by-3&quot;&gt;Ruby 3x3&lt;/a&gt; plan. The idea is that using large amounts of modern optimizations we can make Ruby the interpreter 3 times faster. It is an ambitious goal, which is notable and inspiring. This “movement” has triggered quite a lot of interesting experiments in Ruby core, including a &lt;a href=&quot;https://blog.heroku.com/ruby-mjit&quot;&gt;just-in-time compiler&lt;/a&gt; and action around &lt;a href=&quot;https://bugs.ruby-lang.org/issues/14759&quot;&gt;reducing memory bloat&lt;/a&gt; out-of-the-box. If Ruby gets faster and uses less memory, then everyone gets free performance, which is exactly what we all want.&lt;/p&gt;
&lt;p&gt;A big problem though is that there is only so much magic a faster Ruby can achieve. A faster Ruby is not going to magically fix a “bubble sort” hiding deep in your code. Active Record has tons of internal waste that ought to be addressed which could lead to the vast majority of Ruby applications in the wild getting a lot faster. Rails is the largest consumer of Ruby after all and Rails is underpinned by Active Record.&lt;/p&gt;
&lt;p&gt;Sadly, Active Record performance has not gotten much better since the days of Rails 2, in fact in quite a few cases it got slower or a lot slower.&lt;/p&gt;
&lt;h3&gt;Active Record is very wasteful&lt;/h3&gt;
&lt;p&gt;I would like to start off with a tiny example:&lt;/p&gt;
&lt;p&gt;Say I have a typical 30 column table containing Topics.&lt;/p&gt;
&lt;p&gt;If I run the following, how much will Active Record allocate?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;a = []
Topic.limit(1000).each do |u|
   a &amp;lt;&amp;lt; u.id
end
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;Total allocated: 3835288 bytes (26259 objects)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare this to an equally inefficient “raw version”.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;sql = -&quot;select * from topics limit 1000&quot;
ActiveRecord::Base.connection.raw_connection.async_exec(sql).column_values(0)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;Total allocated: 8200 bytes (4 objects)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This amount of waste is staggering, it translates to deadly combo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extreme levels of memory usage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slower performance&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;But … that is really bad Active Record!&lt;/h3&gt;
&lt;p&gt;An immediate gut reaction here is that I am “cheating” and writing “slow” Active Record code, and comparing it to mega optimized raw code.&lt;/p&gt;
&lt;p&gt;One could argue that I should write:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;a = []
Topic.select(:id).limit(1000).each do |u|
  a &amp;lt;&amp;lt; u.id
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In which you would get:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;Total allocated: 1109357 bytes (11097 objects)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or better still:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;Topic.limit(1000).pluck(:id) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In which I would get&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;Total allocated: 221493 bytes (5098 objects)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time for a quick recap.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The “raw” version allocated &lt;strong&gt;4 objects&lt;/strong&gt;, it was able to return 1000 Integers directly which are not allocated indevidually in the Ruby heaps and are not subject to garbage collection slots.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The “naive” Active Record version allocates &lt;strong&gt;26259&lt;/strong&gt; objects&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The “slightly optimised” Active Record version allocates &lt;strong&gt;11097&lt;/strong&gt; objects&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The “very optimised” Active Record version allocates &lt;strong&gt;5098&lt;/strong&gt; objects&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of those numbers are orders of magnitude larger than &lt;strong&gt;4&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;How many objects does a “naive/lazy” implementation need to allocate?&lt;/h3&gt;
&lt;p&gt;One feature that Active Record touts as a huge advantage over &lt;a href=&quot;https://github.com/jeremyevans/sequel&quot;&gt;Sequel&lt;/a&gt; is the “built-in” laziness.&lt;/p&gt;
&lt;p&gt;ActiveRecord will not bother “casting” a column to a date till you try to use it, so if for any reason you &lt;strong&gt;over select&lt;/strong&gt; ActiveRecord has your back. This deficiency in Sequel is acknowledged and deliberate:&lt;/p&gt;
&lt;aside class=&quot;onebox whitelistedgeneric&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;img src=&quot;https://aws1.discourse-cdn.com/business6/uploads/rubybench/optimized/1X/3cb4d914f350c355660b6e1e6d7ff7eb5b4bb97c_2_32x32.png&quot; class=&quot;site-icon&quot; width=&quot;32&quot; height=&quot;32&quot;&gt;
      &lt;a href=&quot;https://community.rubybench.org/t/can-sequel-be-configured-so-it-defer-materializes/159/2&quot; target=&quot;_blank&quot; title=&quot;07:37PM - 25 August 2017&quot;&gt;RubyBench discussion community – 25 Aug 17&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;div class=&quot;aspect-image&quot; style=&quot;--aspect-ratio:600/671;&quot;&gt;&lt;img src=&quot;https://aws1.discourse-cdn.com/business6/uploads/rubybench/original/1X/4ae23b7eff9a1b039e126f05dd734ab09c8ab4b5.png&quot; class=&quot;thumbnail&quot; width=&quot;600&quot; height=&quot;671&quot;&gt;&lt;/div&gt;

&lt;h3&gt;&lt;a href=&quot;https://community.rubybench.org/t/can-sequel-be-configured-so-it-defer-materializes/159/2&quot; target=&quot;_blank&quot;&gt;Can Sequel be configured so it defer materializes?&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;No. Sequel does not defer typecasting.  Typecasting happens at the dataset-retrieval level, not the model level.  What Sequel offers instead is the lazy_attributes plugin, which does not select the column during the query, but runs a new query on...&lt;/p&gt;


  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;This particular niggle makes it incredibly hard to move to Sequel from ActiveRecord without extremely careful review, despite Sequel being so incredibly fast and efficient.&lt;/p&gt;
&lt;p&gt;We have no “fastest” example out there of an &lt;strong&gt;efficient&lt;/strong&gt; lazy selector. In our case we are consuming 1000 ids so we would expect the &lt;strong&gt;mega&lt;/strong&gt; efficient implementation to allocate 1020 or so objects cause we can not get away without allocating a &lt;code&gt;Topic&lt;/code&gt; object. We do not expect 26 thousand.&lt;/p&gt;
&lt;p&gt;Here is a quick attempt at such an implementation: (note this is just proof of concept of the idea, not a production level system)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;$conn = ActiveRecord::Base.connection.raw_connection

class FastBase

  class Relation
    include Enumerable

    def initialize(table)
      @table = table
    end

    def limit(limit)
      @limit = limit
      self
    end

    def to_sql
      sql = +&quot;SELECT #{@table.columns.join(',')} from #{@table.get_table_name}&quot;
      if @limit
        sql &amp;lt;&amp;lt; -&quot; LIMIT #{@limit}&quot;
      end
      sql
    end

    def each
      @results = $conn.async_exec(to_sql)
      i = 0
      while i &amp;lt; @results.cmd_tuples
        row = @table.new
        row.attach(@results, i)
        yield row
        i += 1
      end
    end

  end

  def self.columns
    @columns
  end

  def attach(recordset, row_number)
    @recordset = recordset
    @row_number = row_number
  end

  def self.get_table_name
    @table_name
  end

  def self.table_name(val)
    @table_name = val
    load_columns
  end

  def self.load_columns
    @columns = $conn.async_exec(&amp;lt;&amp;lt;~SQL).column_values(0)
      SELECT COLUMN_NAME FROM information_schema.columns
      WHERE table_schema = 'public' AND
        table_name = '#{@table_name}'
    SQL

    @columns.each_with_index do |name, idx|
      class_eval &amp;lt;&amp;lt;~RUBY
        def #{name}
          if @recordset &amp;amp;&amp;amp; !@loaded_#{name}
            @loaded_#{name} = true
            @#{name} = @recordset.getvalue(@row_number, #{idx})
          end
          @#{name}
        end

        def #{name}=(val)
          @loaded_#{name} = true
          @#{name} = val
        end
      RUBY
    end
  end

  def self.limit(number)
    Relation.new(self).limit(number)
  end
end

class Topic2 &amp;lt; FastBase
  table_name :topics
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we can measure:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;a = []
Topic2.limit(1000).each do |t|
   a &amp;lt;&amp;lt; t.id
end
a
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;Total allocated: 84320 bytes (1012 objects)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So … we can manage a similar API with &lt;strong&gt;1012 object allocations&lt;/strong&gt; as opposed to &lt;strong&gt;26 thousand objects&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Does this matter?&lt;/h3&gt;
&lt;p&gt;A quick benchmark shows us:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;Calculating -------------------------------------
               magic    256.149  (± 2.3%) i/s -      1.300k in   5.078356s
                  ar     75.219  (± 2.7%) i/s -    378.000  in   5.030557s
           ar_select    196.601  (± 3.1%) i/s -    988.000  in   5.030515s
            ar_pluck      1.407k (± 4.5%) i/s -      7.050k in   5.020227s
                 raw      3.275k (± 6.2%) i/s -     16.450k in   5.043383s
             raw_all    284.419  (± 3.5%) i/s -      1.421k in   5.002106s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our new implementation (that I call magic) does &lt;strong&gt;256&lt;/strong&gt; iterations a second compared to Rails &lt;strong&gt;75&lt;/strong&gt;. It is a considerable improvement over the Rails implementation on multiple counts. It is both much faster and allocates significantly less memory leading to reduced process memory usage. This is despite following the non-ideal practice of over selection. In fact our implementation is so fast, it even beats Rails when it is careful only to select 1 column!&lt;/p&gt;
&lt;p&gt;This is the &lt;strong&gt;Rails 3x3&lt;/strong&gt; we could have today with no changes to Ruby! &lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/confetti_ball.png?v=9&quot; title=&quot;:confetti_ball:&quot; class=&quot;emoji&quot; alt=&quot;:confetti_ball:&quot;&gt;&lt;/p&gt;
&lt;p&gt;Another interesting data point is how much slower &lt;code&gt;pluck&lt;/code&gt;, the turbo boosted version Rails has to offer, is slower that raw SQL. In fact, at Discourse, we &lt;a href=&quot;https://github.com/discourse/discourse/blob/560a950da9c78a479866f990e13c34fc997065a8/lib/freedom_patches/fast_pluck.rb#L45-L73&quot;&gt;monkey patch pluck&lt;/a&gt; exactly for this reason. (I also have a &lt;a href=&quot;https://gist.github.com/SamSaffron/67953e668a6cd67ef6c230a0ad780639&quot;&gt;Rails 5.2 version&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;Why is this bloat happening?&lt;/h3&gt;
&lt;p&gt;Looking at memory profiles I can see multiple reasons all this bloat happens:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Rails is only sort-of-lazy… I can see 1000s of string allocations for columns we never look at. It is not “lazy-allocating” it is partial “lazy-casting”&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Every row allocates 3 additional objects for bookeeping and magic. &lt;code&gt;ActiveModel::Attribute::FromDatabase&lt;/code&gt;, &lt;code&gt;ActiveModel::AttributeSet&lt;/code&gt;, &lt;code&gt;ActiveModel::LazyAttributeHash&lt;/code&gt; . None of this is required and instead a single array could be passed around that holds indexes to columns in the result set.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rails insists on dispatching casts to helper objects even if the data retrieved is already in “the right format” (eg a number) this work generates extra bookkeeping&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Every &lt;strong&gt;column name&lt;/strong&gt; we have is allocated twice per query, this stuff could easily be cached and reused (if the query builder is aware of the column names it selected it does not need to ask the result set for them)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;What should to be done?&lt;/h3&gt;
&lt;p&gt;I feel that we need to carefully review Active Record internals and consider an implementation that allocates significantly less objects per row. We also should start leveraging the PG gem’s native type casting to avoid pulling strings out of the database only to convert them back to numbers.&lt;/p&gt;
&lt;p&gt;You can see the script I used for this evaluation over here:&lt;/p&gt;
&lt;aside class=&quot;onebox githubgist&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://gist.github.com/SamSaffron/409805f6c8447d344e04ad68505ec43f&quot; target=&quot;_blank&quot;&gt;gist.github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://gist.github.com/SamSaffron/409805f6c8447d344e04ad68505ec43f&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/SamSaffron/409805f6c8447d344e04ad68505ec43f&lt;/a&gt;&lt;/h4&gt;
&lt;h5&gt;memory.rb&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&quot;Ruby&quot;&gt;require 'bundler/inline'

gemfile do
  source 'https://rubygems.org'
  gem 'pg'
  gem 'activerecord', '5.2.0'
  gem 'memory_profiler'
  gem 'benchmark-ips'
end
&lt;/code&gt;&lt;/pre&gt;
This file has been truncated. &lt;a href=&quot;https://gist.github.com/SamSaffron/409805f6c8447d344e04ad68505ec43f&quot; target=&quot;_blank&quot;&gt;show original&lt;/a&gt;

&lt;p&gt;
&lt;/p&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;
</description>
      <pubDate>Fri, 01 Jun 2018 07:07:15 +0000</pubDate>
      <link>https://samsaffron.com/archive/2018/06/01/an-analysis-of-memory-bloat-in-active-record-5-2</link>
    </item>
    <item>
      <title>Managing db schema changes without downtime</title>
      <description>
&lt;p&gt;At Discourse we have always been huge fans of &lt;a href=&quot;https://samsaffron.com/archive/2013/02/22/do-you-smoke-test&quot; rel=&quot;nofollow noopener&quot;&gt;continuous deployment&lt;/a&gt;. Every commit we make heads to our continuous integration test suite. If all the tests pass (ui, unit, integration, smoke) we automatically deploy the latest version of our code to &lt;a href=&quot;https://meta.discourse.org&quot; rel=&quot;nofollow noopener&quot;&gt;https://meta.discourse.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This pattern and practice we follow allows the thousands self-installers out there to safely upgrade to the &lt;code&gt;tests-passed&lt;/code&gt; version whenever they feel like it.&lt;/p&gt;
&lt;p&gt;Because we deploy so often we need to take extra care not to have any outages during deployments. One of the most common reasons for outages during application deployment is database schema changes.&lt;/p&gt;
&lt;h3&gt;The problem with schema changes&lt;/h3&gt;
&lt;p&gt;Our current deployment mechanism roughly goes as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Migrate database to new schema&lt;/li&gt;
&lt;li&gt;Bundle up application into a single docker image&lt;/li&gt;
&lt;li&gt;Push to registry&lt;/li&gt;
&lt;li&gt;Spin down old instance, pull new instance, spin up new instance (and repeat)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we ever create an &lt;strong&gt;incompatible&lt;/strong&gt; database schema we risk breaking all the old application instances running older versions of our code. In practice, this can lead to tens of minutes of outage! &lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/boom.png?v=6&quot; title=&quot;:boom:&quot; class=&quot;emoji&quot; alt=&quot;:boom:&quot;&gt;&lt;/p&gt;
&lt;p&gt;In ActiveRecord the situation is particularly dire cause in production the database schema is cached and any changes in schema that drop or rename columns very quickly risk breaking every query to the affected model raising invalid schema exceptions.&lt;/p&gt;
&lt;p&gt;Over the years we have introduced various patterns to overcome this problem and enable us to deploy schema changes safely, minimizing outages.&lt;/p&gt;
&lt;h3&gt;Tracking rich information about migrations&lt;/h3&gt;
&lt;p&gt;ActiveRecord has a table called &lt;code&gt;schema_migrations&lt;/code&gt; where is stores information about migrations that ran.&lt;/p&gt;
&lt;p&gt;Unfortunately the amount of data stored in this table is &lt;strong&gt;extremely limited&lt;/strong&gt;, in fact it boils down to:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;connection.create_table(table_name, id: false) do |t|
  t.string :version, version_options
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The table has a &lt;strong&gt;lonely&lt;/strong&gt; column storing the “version” of migrations that ran.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It does not store when the migration ran&lt;/li&gt;
&lt;li&gt;It does not store how long it took the migration to run&lt;/li&gt;
&lt;li&gt;It has nothing about the version of Rails that was running when the migration ran&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This lack of information, especially, not knowing when stuff ran makes creating clean systems for dealing with schema changes hard to build. Additionally, debugging strange and wonderful issues with migrations is very hard without rich information.&lt;/p&gt;
&lt;p&gt;Discourse, monkey patches Rails to log rich information about migrations:&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/lib/freedom_patches/schema_migration_details.rb&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/lib/freedom_patches/schema_migration_details.rb&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/lib/freedom_patches/schema_migration_details.rb&lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;lang-rb&quot;&gt;module FreedomPatches
  module SchemaMigrationDetails
    def exec_migration(conn, direction)
      rval = nil

      time = Benchmark.measure do
        rval = super
      end

      sql = &amp;lt;&amp;lt;SQL
      INSERT INTO schema_migration_details(
        version,
        hostname,
        name,
        git_version,
        duration,
        direction,
        rails_version,
        created_at
      ) values (
&lt;/code&gt;&lt;/pre&gt;

  This file has been truncated. &lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/lib/freedom_patches/schema_migration_details.rb&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;show original&lt;/a&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;Our patch provides us a very rich details surrounding all the migration circumstances. This really &lt;strong&gt;should be&lt;/strong&gt; in Rails.&lt;/p&gt;
&lt;h3&gt;Defer dropping columns&lt;/h3&gt;
&lt;p&gt;Since we “know” when all previous migrations ran due to our rich migration logging, we are able to “defer drop” columns.&lt;/p&gt;
&lt;p&gt;What this means is that we can guarantee we perform &lt;strong&gt;dangerous&lt;/strong&gt; schema changes after we know that the new code is in place to handle the schema change.&lt;/p&gt;
&lt;p&gt;In practice if we wish to drop a column we &lt;strong&gt;do not&lt;/strong&gt; use migrations for it. Instead our db/seed takes care of defer dropping.&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/db/fixtures/009_users.rb#L36-L62&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/db/fixtures/009_users.rb#L36-L62&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/db/fixtures/009_users.rb#L36-L62&lt;/a&gt;&lt;/h4&gt;
&lt;pre class=&quot;onebox&quot;&gt;&lt;code class=&quot;lang-rb&quot;&gt;&lt;ol class=&quot;start lines&quot; start=&quot;36&quot; style=&quot;counter-reset: li-counter 35 ;&quot;&gt;
&lt;li&gt;Migration::ColumnDropper.drop(&lt;/li&gt;
&lt;li&gt;table: 'users',&lt;/li&gt;
&lt;li&gt;after_migration: 'DropEmailFromUsers',&lt;/li&gt;
&lt;li&gt;columns: %w[&lt;/li&gt;
&lt;li&gt;  email&lt;/li&gt;
&lt;li&gt;  email_always&lt;/li&gt;
&lt;li&gt;  mailing_list_mode&lt;/li&gt;
&lt;li&gt;  email_digests&lt;/li&gt;
&lt;li&gt;  email_direct&lt;/li&gt;
&lt;li&gt;  email_private_messages&lt;/li&gt;
&lt;li&gt;  external_links_in_new_tab&lt;/li&gt;
&lt;li&gt;  enable_quoting&lt;/li&gt;
&lt;li&gt;  dynamic_favicon&lt;/li&gt;
&lt;li&gt;  disable_jump_reply&lt;/li&gt;
&lt;li&gt;  edit_history_public&lt;/li&gt;
&lt;li&gt;  automatically_unpin_topics&lt;/li&gt;
&lt;li&gt;  digest_after_days&lt;/li&gt;
&lt;li&gt;  auto_track_topics_after_msecs&lt;/li&gt;
&lt;li&gt;  new_topic_duration_minutes&lt;/li&gt;
&lt;li&gt;  last_redirected_to_top_at&lt;/li&gt;
&lt;/ol&gt;&lt;/code&gt;&lt;/pre&gt;

  This file has been truncated. &lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/db/fixtures/009_users.rb#L36-L62&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;show original&lt;/a&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;These defer drops will happen at least 30 minutes after the particular migration referenced ran (in the next migration cycle), giving us peace of mind that the new application code is in place.&lt;/p&gt;
&lt;p&gt;If we wish to rename a column we will create a new column, duplicate the value into the new column, mark the old column readonly using a trigger and defer drop old column.&lt;/p&gt;
&lt;p&gt;If we wish to drop or rename a table we follow a similar pattern.&lt;/p&gt;
&lt;p&gt;The logic for defer dropping lives in &lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/lib/migration/column_dropper.rb&quot; rel=&quot;nofollow noopener&quot;&gt;ColumnDropper&lt;/a&gt; and &lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/lib/migration/table_dropper.rb&quot; rel=&quot;nofollow noopener&quot;&gt;TableDropper&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Not trusting ourselves&lt;/h3&gt;
&lt;p&gt;A big problem with spectacular special snowflake per-application practices is enforcement.&lt;/p&gt;
&lt;p&gt;We have great patterns for ensuring safety, however sometimes people forget that we should never drop a column or a table the ActiveRecord migration way.&lt;/p&gt;
&lt;p&gt;To ensure we never make the mistake of committing dangerous schema changes into our migrations, we patch the PG gem to disallow certain statements when we run them in the context of a migration.&lt;/p&gt;
&lt;p&gt;Want to &lt;code&gt;DROP TABLE&lt;/code&gt;? Sorry, an exception will be raised. Want to &lt;code&gt;DROP&lt;/code&gt; a column, an exception will be raised.&lt;/p&gt;
&lt;p&gt;This makes it impractical to commit highly risky schema changes without following our best practices:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-nohighlight&quot;&gt;== 20180321015226 DropRandomColumnFromUser: migrating =========================
-- remove_column(:categories, :name)

WARNING
-------------------------------------------------------------------------------------
An attempt was made to drop or rename a column in a migration
SQL used was: 'ALTER TABLE &quot;categories&quot; DROP &quot;name&quot;'
Please use the deferred pattrn using Migration::ColumnDropper in db/seeds to drop
or rename columns.

Note, to minimize disruption use self.ignored_columns = [&quot;column name&quot;] on your
ActiveRecord model, this can be removed 6 months or so later.

This protection is in place to protect us against dropping columns that are currently
in use by live applications.
rake aborted!
StandardError: An error has occurred, this and all later migrations canceled:

Attempt was made to rename or delete column
/home/sam/Source/discourse/db/migrate/20180321015226_drop_random_column_from_user.rb:3:in `up'
Tasks: TOP =&amp;gt; db:migrate
(See full trace by running task with --trace)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This logic lives in &lt;a href=&quot;https://github.com/discourse/discourse/blob/6a3c8fe69c16ad7360046f145db6689c18e91005/lib/migration/safe_migrate.rb&quot; rel=&quot;nofollow noopener&quot;&gt;safe_migrate.rb&lt;/a&gt;. Since this is a recent pattern we only enforce it for migrations after a certain date.&lt;/p&gt;
&lt;h3&gt;Alternatives&lt;/h3&gt;
&lt;p&gt;Some of what we do is available in gem form and some is not:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ankane/strong_migrations&quot; rel=&quot;nofollow noopener&quot;&gt;Strong Migrations&lt;/a&gt; offers enforcement. It also takes care of a bunch of interesting conditions like nudging you to create indexes concurrently in postgres. Enforcement is done via patching active record migrator, meaning that if anyone does stuff with SQL direct it will not be caught.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/LendingHome/zero_downtime_migrations&quot; rel=&quot;nofollow noopener&quot;&gt;Zero downtime migrations&lt;/a&gt; very similar to strong migrations.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/instructure/outrigger/blob/master/README.md&quot; rel=&quot;nofollow noopener&quot;&gt;Outrigger&lt;/a&gt; allows you to tag migrations. This enables you to amend your deploy process so some migrations run pre-deploy and some run post-deploy. This is the simplest technique for managing migrations in such a way that you can avoid downtimes during deploy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/procore/handcuffs&quot; rel=&quot;nofollow noopener&quot;&gt;Handcuffs&lt;/a&gt;: very similar to outrigger, define phases for your migrations&lt;/p&gt;
&lt;h2&gt;What should you do?&lt;/h2&gt;
&lt;p&gt;Our current pattern for defer dropping columns and tables works for us, but is not yet ideal. Code that is in charge of “seeding” data now is also in charge of amending schema and timing of column drops is not as tightly controlled as it should be.&lt;/p&gt;
&lt;p&gt;On the upside, &lt;code&gt;rake db:migrate&lt;/code&gt; is all you need to run and it works magically all the time. Regardless of how you are hosted and what version your schema is at.&lt;/p&gt;
&lt;p&gt;My recommendation though for what I would consider best practice here is a mixture of a bunch of ideas. All of it belongs in Rails.&lt;/p&gt;
&lt;h3&gt;Enforcement of best practices belongs in Rails&lt;/h3&gt;
&lt;p&gt;I think enforcement of safe schema changes should be introduced into ActiveRecord. This is something everyone should be aware of. It is practical to do zero downtime deploys today with schema changes.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;class RemoveColumn &amp;lt; ActiveRecord::Migration[7.0]
  def up
     # this should raise an error
     remove_column :posts, :name
  end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make it work, &lt;strong&gt;everyone&lt;/strong&gt; should be forced to add the &lt;code&gt;after_deploy&lt;/code&gt; flag to the migration:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;class RemoveColumn &amp;lt; ActiveRecord::Migration[7.0]
  after_deploy! # either this, or disable the option globally 
  def up
     # this should still raise if class Post has no ignored_columns: [:name]
     remove_column :posts, :name
  end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;class RemoveColumn &amp;lt; ActiveRecord::Migration[7.0]
  after_deploy!(force: true)
  def up
     # this should work regardless of ignored_columns
     remove_column :posts, :name
  end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also think the ideal enforcement is via SQL analysis, however it is possible that this is a bit of a can-of-worms at Rails scale. For us it is practical cause we only support one database.&lt;/p&gt;
&lt;h3&gt;
&lt;code&gt;rake db:migrate&lt;/code&gt; should continue to work just as it always did.&lt;/h3&gt;
&lt;p&gt;For backwards compatibility rake db:migrate should run all migrations including &lt;code&gt;after_deploy&lt;/code&gt; migrations. Applications who do not care about “zero downtime deploys” should also be allowed to opt out of the safety.&lt;/p&gt;
&lt;h3&gt;New post and pre migrate rake tasks should be introduced&lt;/h3&gt;
&lt;p&gt;To run all the application code compatible migrations you would run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;rake db:migrate:pre
# runs all migrations without `after_deploy!`
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To run all the destructive operations you would run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;rake db:migrate:post
# runs all migrations with `after_deploy!`
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you are looking to start with “safe” zero downtime deploys today I would recommend:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Amending build process to run pre deploy migrations and post deploy migrations (via &lt;a href=&quot;https://github.com/instructure/outrigger/blob/master/README.md&quot; rel=&quot;nofollow noopener&quot;&gt;Outrigger&lt;/a&gt; or &lt;a href=&quot;https://github.com/procore/handcuffs&quot; rel=&quot;nofollow noopener&quot;&gt;Handcuffs&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Introduce an enforcement piece with &lt;a href=&quot;https://github.com/ankane/strong_migrations&quot; rel=&quot;nofollow noopener&quot;&gt;Strong Migrations&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
      <pubDate>Thu, 22 Mar 2018 06:30:05 +0000</pubDate>
      <link>https://samsaffron.com/archive/2018/03/22/managing-db-schema-changes-without-downtime</link>
    </item>
    <item>
      <title>Reducing String duplication in Ruby</title>
      <description>
&lt;p&gt;One very common problem Ruby and Rails have is memory usage. Often when hosting sites the bottleneck is memory not performance. At &lt;a href=&quot;https://github.com/discourse/discourse&quot;&gt;Discourse&lt;/a&gt; we spend a fair amount of time tuning our application so self hosters can afford to host Discourse on 1GB droplets.&lt;/p&gt;
&lt;p&gt;To help debug memory usage I created the &lt;a href=&quot;https://github.com/SamSaffron/memory_profiler&quot;&gt;memory_profiler&lt;/a&gt; gem, it allows you to easily report on application memory usage. I &lt;strong&gt;highly recommend&lt;/strong&gt; you give it a shot on your Rails app, it is often surprising how much low hanging fruit there is. On unoptimized applications you can often reduce memory usage by 20-30% in a single day of work.&lt;/p&gt;
&lt;p&gt;Memory profiler generates a memory usage report broken into 2 parts:&lt;/p&gt;
&lt;h3&gt;Allocated memory&lt;/h3&gt;
&lt;p&gt;Memory you allocated during the block that was measured.&lt;/p&gt;
&lt;h3&gt;Retained memory&lt;/h3&gt;
&lt;p&gt;Memory that remains in use after the block being measure is executed.&lt;/p&gt;
&lt;p&gt;So, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;def get_obj
   allocated_object1 = &quot;hello &quot;
   allocated_object2 = &quot;world&quot;
   allocated_object1 + allocated_object2
end

retained_object = nil

MemoryProfiler.report do
   retained_object = get_obj
end.pretty_print 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Will be broken up as:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;[a lot more text]
Allocated String Report
-----------------------------------
         1  &quot;hello &quot;
         1  blog.rb:3

         1  &quot;hello world&quot;
         1  blog.rb:5

         1  &quot;world&quot;
         1  blog.rb:4


Retained String Report
-----------------------------------
         1  &quot;hello world&quot;
         1  blog.rb:5

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a general rule we focus on reducing &lt;strong&gt;retained memory&lt;/strong&gt; when we want our process to consume less memory and we focus on reducing &lt;strong&gt;allocated memory&lt;/strong&gt; when optimising hot code paths.&lt;/p&gt;
&lt;p&gt;For the purpose of this blog post I would like to focus on &lt;strong&gt;retained memory&lt;/strong&gt; optimisations and in particular in the String portion of memory retained.&lt;/p&gt;
&lt;h3&gt;How you can get memory profiler report for your Rails app?&lt;/h3&gt;
&lt;p&gt;We use the following script to profile Rails boot time:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;if ENV['RAILS_ENV'] != &quot;production&quot;
  exec &quot;RAILS_ENV=production ruby #{__FILE__}&quot;
end

require 'memory_profiler'

MemoryProfiler.report do
  # this assumes file lives in /scripts directory, adjust to taste...
  require File.expand_path(&quot;../../config/environment&quot;, __FILE__)

  # we have to warm up the rails router
  Rails.application.routes.recognize_path('abc') rescue nil

  # load up the yaml for the localization bits, in master process
  I18n.t(:posts)

  # load up all models so AR warms up internal caches
  (ActiveRecord::Base.connection.tables - %w[schema_migrations versions]).each do |table|
    table.classify.constantize.first rescue nil
  end
end.pretty_print
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see an example of such a report here:&lt;/p&gt;
&lt;aside class=&quot;onebox githubgist&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://gist.github.com/SamSaffron/f84f94fa875a94d432767a1442965458&quot; target=&quot;_blank&quot;&gt;gist.github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://gist.github.com/SamSaffron/f84f94fa875a94d432767a1442965458&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/SamSaffron/f84f94fa875a94d432767a1442965458&lt;/a&gt;&lt;/h4&gt;
&lt;h5&gt;memory_profile.txt&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&quot;Text&quot;&gt;Total allocated: 200134661 bytes (2120673 objects)
Total retained:  33789989 bytes (291785 objects)

allocated memory by gem
-----------------------------------
  72565994  activesupport-5.1.4
  17893868  actionpack-5.1.4
  17293551  psych
  12181501  activerecord-5.1.4
  11900863  activemodel-5.1.4&lt;/code&gt;&lt;/pre&gt;
This file has been truncated. &lt;a href=&quot;https://gist.github.com/SamSaffron/f84f94fa875a94d432767a1442965458&quot; target=&quot;_blank&quot;&gt;show original&lt;/a&gt;

&lt;p&gt;
&lt;/p&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;Very early on in my journey of optimizing memory usage I noticed that Strings are a huge portion of the retained memory. To help cutting down on String usage &lt;a href=&quot;https://github.com/SamSaffron/memory_profiler&quot;&gt;memory_profiler&lt;/a&gt; has a dedicated String section.&lt;/p&gt;
&lt;p&gt;For example in the report above you can see:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;Retained String Report
-----------------------------------
       942  &quot;format&quot;
       940  /home/sam/.rbenv/versions/2.5.0/lib/ruby/gems/2.5.0/gems/actionpack-5.1.4/lib/action_dispatch/journey/nodes/node.rb:83
         1  /home/sam/.rbenv/versions/2.5.0/lib/ruby/gems/2.5.0/gems/actionpack-5.1.4/lib/action_controller/log_subscriber.rb:3
         1  /home/sam/.rbenv/versions/2.5.0/lib/ruby/gems/2.5.0/gems/activemodel-5.1.4/lib/active_model/validations/validates.rb:115

       941  &quot;:format&quot;
       940  /home/sam/.rbenv/versions/2.5.0/lib/ruby/gems/2.5.0/gems/actionpack-5.1.4/lib/action_dispatch/journey/scanner.rb:49
         1  /home/sam/.rbenv/versions/2.5.0/lib/ruby/gems/2.5.0/gems/activesupport-5.1.4/lib/active_support/dependencies.rb:292
... a lot more ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that there are 940 copies of the string &lt;code&gt;&quot;format&quot;&lt;/code&gt; living in my Ruby heaps. These strings are all “rooted” so they just sit there in the heap and never get collected. Rails needs the 940 copies so it can quickly figure out what params my controller should get.&lt;/p&gt;
&lt;p&gt;In Ruby RVALUEs (slots on the Ruby heap / unique object_ids) will consume 40 bytes on x64. The string “format” is quite short so it fits in a single RVALUE without an external pointer or extra malloc. Still, this is 37,600 bytes just to store the single string “format”. &lt;a href=&quot;https://github.com/rails/rails/pull/32016&quot;&gt;That is clearly wasteful, we should send a PR to Rails&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is wasteful on a few counts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Every object in the Ruby heap is going to get scanned every time a full GC runs, from now till the process eventually dies.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Small chunks of memory do not fit perfectly into your process address space, memory fragments over time and the actual impact of a 40 byte RVALUE may end up being more due to gaps between RVALUE heaps.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The larger your Ruby heaps are the faster they grow (out-of-the-box):  &lt;a href=&quot;https://bugs.ruby-lang.org/issues/12967&quot;&gt;https://bugs.ruby-lang.org/issues/12967&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A single RVALUE in a Ruby heap that contains 500 or so RVALUEs can stop it from being reclaimed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;More objects means less efficient CPU caching, more chances of hitting swap and so on.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Techniques for string deduplication&lt;/h3&gt;
&lt;p&gt;I created this Gist to cover quite a bit of the nuance around the techniques you can use for string deduplication in Ruby 2.5 and up, for those feeling brave, I recommend you spend some time reading it carefully:&lt;/p&gt;
&lt;aside class=&quot;onebox githubgist&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://gist.github.com/SamSaffron/11611d25b444487e6d8392b56cfe2019&quot; target=&quot;_blank&quot;&gt;gist.github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://gist.github.com/SamSaffron/11611d25b444487e6d8392b56cfe2019&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/SamSaffron/11611d25b444487e6d8392b56cfe2019&lt;/a&gt;&lt;/h4&gt;
&lt;h5&gt;string_deduplication_demo.rb&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&quot;Ruby&quot;&gt;require &quot;active_support&quot;
require &quot;active_support/core_ext/string/output_safety&quot;
require &quot;objspace&quot;

def assert_same_object(x, y)
  raise unless x.object_id == y.object_id
end

def assert_not_same_object(x, y)
  raise unless x.object_id != y.object_id&lt;/code&gt;&lt;/pre&gt;
This file has been truncated. &lt;a href=&quot;https://gist.github.com/SamSaffron/11611d25b444487e6d8392b56cfe2019&quot; target=&quot;_blank&quot;&gt;show original&lt;/a&gt;

&lt;p&gt;
&lt;/p&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;For those who prefer words, well here are some techniques you can use:&lt;/p&gt;
&lt;h3&gt;Use constants&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;# before
def give_me_something
   &quot;something&quot;
end

# after
SOMETHING = &quot;something&quot;.freeze

def give_me_something
   SOMETHING
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Works in all versions of Ruby&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ugly and verbose&lt;/li&gt;
&lt;li&gt;If you forget the magic “freeze” you may not reuse the string properly Ruby &amp;gt; 2.3&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Use the magic frozen_string_literal: true comment&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;# before
def give_me_something
   &quot;something&quot;
end

# after

# frozen_string_literal: true
def give_me_something
   &quot;something&quot;
end
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ruby 2.3 introduces the &lt;code&gt;frozen_string_literal: true&lt;/code&gt; pragma. When the comment &lt;code&gt;# frozen_string_literal: true&lt;/code&gt; is the first line of your file, Ruby treats the file &lt;strong&gt;differently&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Every &lt;strong&gt;simple&lt;/strong&gt; string literal is frozen and deduplicated.&lt;/p&gt;
&lt;p&gt;Every interpolated string is frozen and &lt;strong&gt;not deduplicated&lt;/strong&gt;. Eg &lt;code&gt;x = &quot;#{y}&quot;&lt;/code&gt; is a frozen non deduplicated string.&lt;/p&gt;
&lt;p&gt;I feel this should be the default for Ruby and many projects are embracing this including Rails. Hopefully this becomes the default for Ruby 3.0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Very easy to use&lt;/li&gt;
&lt;li&gt;Not ugly&lt;/li&gt;
&lt;li&gt;Long term this enables fancier optimisations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can be complicated to apply on existing files, a great test suite is highly recommended.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Pitfalls&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;There are a few cliffs you can fall which you should be careful about. Biggest is the default encoding on &lt;code&gt;String.new&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;buffer = String.new
buffer.encoding =&amp;gt; Encoding::ASCII-8BIT

# vs 

# String @+ is new in Ruby 2.3 and up it allows you to unfreeze
buffer = +&quot;&quot;
buffer.encoding =&amp;gt; Encoding::UTF-8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Usually this nuance will not matter to you at all cause as soon as you append to the String it will switch encoding, however if you are passing refs to 3rd party library of the empty string you created havoc can ensue. So, &lt;code&gt;&quot;&quot;.dup&lt;/code&gt; or &lt;code&gt;+&quot;&quot;&lt;/code&gt; is a good habit.&lt;/p&gt;
&lt;h3&gt;Dynamic string deduplication&lt;/h3&gt;
&lt;p&gt;Ruby 2.5 introduces a &lt;strong&gt;new&lt;/strong&gt; techniques you can use to deduplicate strings. It was introduced in &lt;a href=&quot;https://bugs.ruby-lang.org/issues/13077&quot;&gt;https://bugs.ruby-lang.org/issues/13077&lt;/a&gt; by Eric Wong.&lt;/p&gt;
&lt;p&gt;To quote Matz&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For the time being, let us make -@ to call rb_fstring.&lt;br&gt;
If users want more descriptive name, let’s discuss later.&lt;br&gt;
In my opinion, fstring is not acceptable.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, String’s @- method will allow you to dynamically de-duplicate strings.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;a = &quot;hello&quot;
b = &quot;hello&quot;
puts ((-a).object_id == (-b).object_id) # I am true in Ruby 2.5 (usually) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This syntax exists in &lt;strong&gt;Ruby 2.3&lt;/strong&gt; and up, the optimisation though is only available in Ruby 2.5 and up.&lt;/p&gt;
&lt;p&gt;This technique is safe, meaning that string you deduplicate &lt;strong&gt;still get garbage collected&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;It relies on a facility that has existed in Ruby for quite a while where it maintains a hash table of deduplicated strings:&lt;/p&gt;
&lt;aside class=&quot;onebox githubblob&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;a href=&quot;https://github.com/ruby/ruby/blob/311d499f5e34c9ad65687d241f65c654393ad73b/string.c#L333-L351&quot; target=&quot;_blank&quot;&gt;github.com&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;h4&gt;&lt;a href=&quot;https://github.com/ruby/ruby/blob/311d499f5e34c9ad65687d241f65c654393ad73b/string.c#L333-L351&quot; target=&quot;_blank&quot;&gt;ruby/ruby/blob/311d499f5e34c9ad65687d241f65c654393ad73b/string.c#L333-L351&lt;/a&gt;&lt;/h4&gt;
&lt;pre class=&quot;onebox&quot;&gt;&lt;code class=&quot;lang-c&quot;&gt;&lt;ol class=&quot;start lines&quot; start=&quot;333&quot; style=&quot;counter-reset: li-counter 332 ;&quot;&gt;
&lt;li&gt;static VALUE&lt;/li&gt;
&lt;li&gt;register_fstring(VALUE str)&lt;/li&gt;
&lt;li&gt;{&lt;/li&gt;
&lt;li&gt;    VALUE ret;&lt;/li&gt;
&lt;li&gt;    st_table *frozen_strings = rb_vm_fstring_table();&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;    do {&lt;/li&gt;
&lt;li&gt;	ret = str;&lt;/li&gt;
&lt;li&gt;	st_update(frozen_strings, (st_data_t)str,&lt;/li&gt;
&lt;li&gt;		  fstr_update_callback, (st_data_t)&amp;amp;ret);&lt;/li&gt;
&lt;li&gt;    } while (ret == Qundef);&lt;/li&gt;
&lt;li&gt;
&lt;/li&gt;&lt;li&gt;    assert(OBJ_FROZEN(ret));&lt;/li&gt;
&lt;li&gt;    assert(!FL_TEST_RAW(ret, STR_FAKESTR));&lt;/li&gt;
&lt;li&gt;    assert(!FL_TEST_RAW(ret, FL_EXIVAR));&lt;/li&gt;
&lt;li&gt;    assert(!FL_TEST_RAW(ret, FL_TAINT));&lt;/li&gt;
&lt;li&gt;    assert(RBASIC_CLASS(ret) == rb_cString);&lt;/li&gt;
&lt;li&gt;    return ret;&lt;/li&gt;
&lt;li&gt;}&lt;/li&gt;
&lt;/ol&gt;&lt;/code&gt;&lt;/pre&gt;


  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;The table was used in the past for the &lt;code&gt;&quot;string&quot;.freeze&lt;/code&gt; optimisation and automatic Hash key deduplication. Ruby 2.5 is the first time this feature is exposed to the general public.&lt;/p&gt;
&lt;p&gt;It is incredibly useful when parsing input with duplicate content (like the Rails routes) and &lt;a href=&quot;https://github.com/ruby/ruby/commit/26b3dc49226011469bfe29af0f882b06215388a5&quot;&gt;when generating dynamic lookup tables&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, it is not all &lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/rose.png?v=9&quot; title=&quot;:rose:&quot; class=&quot;emoji&quot; alt=&quot;:rose:&quot;&gt;s&lt;/p&gt;
&lt;p&gt;Firstly, some people’s sense of aesthetics is severely offended by the &lt;strong&gt;ugly&lt;/strong&gt; syntax. Some are offended so much they refuse to use it.&lt;/p&gt;
&lt;p&gt;Additionally this technique has a bunch of pitfalls documented in &lt;a href=&quot;https://gist.github.com/SamSaffron/11611d25b444487e6d8392b56cfe2019&quot;&gt;extreme levels here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Until &lt;a href=&quot;https://bugs.ruby-lang.org/issues/14478&quot;&gt;https://bugs.ruby-lang.org/issues/14478&lt;/a&gt; is fixed you need to “unfreeze” strings prior to deduping&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;yuck = &quot;yuck&quot;
yuck.freeze
yuck_deduped = -+yuck
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;If a string is tainted you can only “partially” dedupe it&lt;/h3&gt;
&lt;p&gt;This means the VM will create a &lt;a href=&quot;https://tenderlovemaking.com/2018/02/12/speeding-up-ruby-with-shared-strings.html&quot;&gt;shared string&lt;/a&gt; for long strings, but will still maintain the RVALUE&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;love = &quot;love&quot;
love.taint
(-love).object_id == love.object_id 

# got to make a copy to dedupe
deduped = -love.dup.untaint
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Trouble is lots of places that want to apply this fix end up trading in tainted strings, a classic example is the postgres adapter for Rails that has 142 copies of &lt;code&gt;&quot;character varying&quot;&lt;/code&gt; in the Discourse report from above. In some cases this limitation means we are stuck with an extra and &lt;strong&gt;pointless&lt;/strong&gt; copy of the string just cause we want to deduplicate (cause untainting may be unacceptable for the 3 people in the universe using the feature).&lt;/p&gt;
&lt;p&gt;Personally, I wish we just nuked all the messy tainting code from Ruby’s codebase &lt;img src=&quot;https://discuss.samsaffron.com/images/emoji/twitter/fire.png?v=9&quot; title=&quot;:fire:&quot; class=&quot;emoji&quot; alt=&quot;:fire:&quot;&gt; , which would make it both simpler, safer and faster.&lt;/p&gt;
&lt;h3&gt;If a string has any instance vars defined you can only partially dedupe&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&quot;lang-auto&quot;&gt;# html_safe sets an ivar on String so it will not be deduplicated
str = -&quot;&amp;lt;html&amp;gt;test&amp;lt;/html&amp;gt;&quot;.html_safe 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This particular limitation is unavoidable and I am not sure there is anything Ruby can do to help us out here. So, if you are looking to deduplicate fragments of html, well, you are in a bind, you can share the string, you can not deduplicate it perfectly.&lt;/p&gt;
&lt;h3&gt;Additional reading:&lt;/h3&gt;
&lt;aside class=&quot;onebox whitelistedgeneric&quot;&gt;
  &lt;header class=&quot;source&quot;&gt;
      &lt;img src=&quot;https://rubytalk.org/uploads/default/optimized/2X/7/74f2816b4bec60b2d07c6b5fd37ea8525c0b0bba_2_32x32.png&quot; class=&quot;site-icon&quot; width=&quot;32&quot; height=&quot;32&quot;&gt;
      &lt;a href=&quot;https://rubytalk.org/t/psa-string-memory-use-reduction-techniques/74477&quot; target=&quot;_blank&quot; title=&quot;01:52AM - 03 January 2018&quot;&gt;Ruby Mailing List Mirror – 3 Jan 18&lt;/a&gt;
  &lt;/header&gt;
  &lt;article class=&quot;onebox-body&quot;&gt;
    &lt;img src=&quot;https://rubytalk.org/uploads/default/original/2X/b/b23c93119f13a69c44c9bb1757a17db7957e9be3.png&quot; class=&quot;thumbnail onebox-avatar&quot; width=&quot;512&quot; height=&quot;512&quot;&gt;

&lt;h3&gt;&lt;a href=&quot;https://rubytalk.org/t/psa-string-memory-use-reduction-techniques/74477&quot; target=&quot;_blank&quot;&gt;PSA: String memory use reduction techniques&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Hopefully some of you are trying and enjoying Ruby 2.5 by now. I figured I’d write about some changes to C Ruby over the years which make it easier to reduce memory use.  String objects are often to blame for high memory usage in Ruby applications. ...&lt;/p&gt;

  &lt;p&gt;&lt;span class=&quot;label1&quot;&gt;Reading time: 5 mins 🕑&lt;/span&gt;
    &lt;span class=&quot;label2&quot;&gt;Likes: 4 ❤&lt;/span&gt;&lt;/p&gt;

  &lt;/article&gt;
  &lt;div class=&quot;onebox-metadata&quot;&gt;
    
    
  &lt;/div&gt;
  &lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;
&lt;/aside&gt;

&lt;p&gt;Good luck, reducing your application’s memory usage, I hope this helps!&lt;/p&gt;</description>
      <pubDate>Fri, 16 Feb 2018 03:59:29 +0000</pubDate>
      <link>https://samsaffron.com/archive/2018/02/16/reducing-string-duplication-in-ruby</link>
    </item>
  </channel>
</rss>
