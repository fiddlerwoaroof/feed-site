{
  "title":"Jack: One Thread Per Core",
  "date":"2021-08-25T10:17:57.000000-07:00",
  "author":null,
  "id":"http://letloop.xyz/notes/2021/jack-one-thread-per-core.html",
  "link":"http://letloop.xyz/notes/2021/jack-one-thread-per-core.html",
  "content":"2021/08/25 - Jack: One Thread Per Core\nI have being making progress with Babelia on the web user interface,\nIRC interface, and also the backend.\nRegarding the backend, even if Chez Scheme is fast, it is clear even\non the small dataset I have put together, that is around eleven\ngigabytes without compression. I need something like map-reduce [1],\nin LISP world known under the name of for-each-parallel-map.\nIn full-text search, and in a search product like google, they are\ntips, and tricks to avoid to hit the worst case. The worst being a\nquery where the least frequent word is also one of the most frequent\nin the index. Possible workarounds include 0) using AND as the\ndefault operator 1) eliminating most common word (also known as\nstop-words); 2) caching results; 3) approximating results with user\nprofiling...\nAll those workarounds give rise to other problems, or they need a lot\nof work such as profiling users, which is in my opinion not a problem\nwhen that is limited to profiling users' data that are published in\nthe open (unlike tracking search users via their queries, or mail,\netc...).\nAnyway, threads are difficult, so I wanted to give it try. The above\nis trying to explain from where my motivation stems from.\nIt is still unclear whether make-jack works reliably all the time.\nYou tell me.\n\n(make-jack count) â†’ procedure?\nmake-jack initialize a pool of COUNT parallel threads, and return\na possibly endless generator that produces jacks. A jack is made of\ntwo procedure:\n\nThe first procedure is an accumulator that will consume one or more\nthunks. That is how the user request the parallel execution of\nsomething.\n\nThe second procedure will generate the results of the thunks\nsubmitted with the associated accumulator in an unspecified order.\n\n\nExample:\n(call-with-values jack\n   (lambda (consumer producer)\n     ;; submit some work to the pool, the consumer will block\n     ;; if there is too much work already scheduled.\n     (consumer thunks)\n     ;; pull results\n     (let loop ((count (length input)))\n       (unless (fxzero? count)\n         ;; producer will block the current thread until there\n     ;; is something to produce\n         (display (producer))\n     (newline)\n         (loop (fx- count 1))))))\n\nHere are some numbers that backup the claim that it may work as\nexpected, the tests were done with pool of size five. The work, called\nTHUNKS in the above snippet, is the computation of one thousand\ntimes fibonacci of 40:\n\n(time (call-with-values jack ...))\n    no collections\n    0.029955076s elapsed cpu time\n    152.646622367s elapsed real time\n    592688 bytes allocated\n        Command being timed: &quot;scheme --libdirs src/ --program main.scm&quot;\n        User time (seconds): 761.84\n        System time (seconds): 0.04\n        Percent of CPU this job got: 498%\n        Elapsed (wall clock) time (h:mm:ss or m:ss): 2:32.71\n        Average shared text size (kbytes): 0\n        Average unshared data size (kbytes): 0\n        Average stack size (kbytes): 0\n        Average total size (kbytes): 0\n        Maximum resident set size (kbytes): 49624\n        Average resident set size (kbytes): 0\n        Major (requiring I/O) page faults: 0\n        Minor (reclaiming a frame) page faults: 14194\n        Voluntary context switches: 1011\n        Involuntary context switches: 3646\n        Swaps: 0\n        File system inputs: 0\n        File system outputs: 0\n        Socket messages sent: 0\n        Socket messages received: 0\n        Signals delivered: 0\n        Page size (bytes): 4096\n        Exit status: 0\nThe code:\n(define-record-type* "
}