<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Filippo Valsorda]]></title><description><![CDATA[Filippo Valsorda]]></description><link>https://words.filippo.io/</link><image><url>https://words.filippo.io/favicon.png</url><title>Filippo Valsorda</title><link>https://words.filippo.io/</link></image><generator>Ghost 5.22</generator><lastBuildDate>Tue, 15 Nov 2022 15:00:20 GMT</lastBuildDate><atom:link href="https://words.filippo.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[A GC-Friendly Go Interning Cache]]></title><description><![CDATA[Go 1.20 is adding an interning cache for reused certificates. The entries are reference-counted with the help of the garbage collector and finalizers.]]></description><link>https://words.filippo.io/dispatches/certificate-interning/</link><guid isPermaLink="false">6364d03713bbe2003d2efc25</guid><category><![CDATA[dispatches]]></category><category><![CDATA[maintainer]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Wed, 09 Nov 2022 14:28:02 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>I&#x2019;ve seen a little gem pass by in a Go cryptography code review and I want to share it because I think it&#x2019;s a pattern that can be reused.</p>
<p>Let&#x2019;s start with a problem statement: crypto/x509 <code>Certificate</code> values take a bunch of memory, and for every open TLS connection you end up with a copy of the leaf and intermediate certificate, and sometimes of the root too.<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> That&#x2019;s kind of a waste of memory, a big one if you open a lot of connections to the same endpoint or to endpoints that use the same roots.</p>
<p>Ideally, if there was already a parsed copy of a certificate in memory we&#x2019;d just return a pointer to that. An easy way to do that would be to have a <code>map[string]*x509.Certificate</code> somewhere mapping the certificate bytes to the parsed structure, and reuse an old entry if present. This is the concept of <a href="https://en.wikipedia.org/wiki/String_interning">interning</a>, usually used for short strings and other commonly repeated immutable values.</p>
<p>The problem is: how do we evict entries from that cache when they aren&#x2019;t needed anymore? We can&#x2019;t have a client that connects to a lot of endpoints one after the other just grow its memory usage endlessly.</p>
<p>The &#x201C;simplest&#x201D; solution would be to store a reference counter, remember to decrease it when we don&#x2019;t need the certificate anymore, and delete the entry from the map when it reaches zero. How do we decrement it though? The <code>x509.Certificate</code> is needed for as long as the <code>tls.Conn</code> is live, because you can call <code>PeerCertificates</code> on the <code>Conn</code>. Any manual way of doing it is guaranteed to turn out wrong, causing memory leaks.</p>
<p>Some languages have the concept of &#x201C;weak reference&#x201D; for this: a pointer that points to the thing but doesn&#x2019;t keep it live. They are somewhat complicated to implement safely and intuitively, and Go just doesn&#x2019;t have them. You could try to replicate them by casting <code>unsafe.Pointer</code>s to <code>uintptr</code>s but that&#x2019;s also guaranteed to go wrong eventually, and this time instead of a memory leak you end up with memory corruption. It also relies on undocumented properties of the GC, such as the fact that the GC currently doesn&#x2019;t move heap-allocated values.</p>
<p>The solution <a href="https://go-review.googlesource.com/c/go/+/426454/comment/0001ba1b_50f0b59f/">suggested by Russ Cox</a> and <a href="https://go.dev/cl/426454">implemented by Roland Shoemaker</a> uses the garbage collector itself to track when the map entry should be dropped.</p>
<p>It&#x2019;s relatively simple: when you request a certificate from the cache, you get back an <code>x509.Certificate</code> wrapped in an <code>activeCert</code> struct. You&#x2019;re expected to hold on to the <code>activeCert</code> for as long as you need the <code>x509.Certificate</code>. For example, <code>crypto/tls</code> sticks the <code>activeCert</code> in a private field of <code>tls.Conn</code>. The magic is that <code>activeCert</code> has a <a href="https://pkg.go.dev/runtime@go1.19.2#SetFinalizer">finalizer</a> attached to it, so that when it gets garbage-collected it also decrements the reference counter of the certificate in the map. When the counter hits zero, the map entry is deleted.</p>
<p>It&#x2019;s using the GC to keep track of when entries in the cache stop being useful. You can&#x2019;t put the finalizer on the certificate itself because the certificate is the thing kept alive by the map. Instead, you have a distinct <code>activeCert</code> for every place the certificate is used (specifically, for every <code>tls.Conn</code> that needs it), and keep track of when all of them have been garbage-collected.</p>
<p>I like it because it&#x2019;s simple to use&#x2014;you just store the <code>activeCert</code> next to the certificate&#x2014;and because it fails gracefully. If you drop the <code>activeCert</code> while something is still using the certificate, for example if the certificate outlives the <code>Conn</code>, nothing bad happens besides potentially making the cache a little less efficient. The certificate itself will still be kept alive by the GC, even if it&#x2019;s dropped from the cache.</p>
<p><a href="https://crawshaw.io/blog/tragedy-of-finalizers">Finalizers are scary</a> and generally speaking if you use them like destructors you&#x2019;re gonna have a bad time. For example, what if the program runs with <code>GOGC=off</code>?<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> However, this is a good use for them because what we are doing is exclusively related to memory management and value lifecycle. In David&#x2019;s words, we&#x2019;re managing &#x201C;a resource whose use is tied closely to heap use&#x201D;. A similar use of finalizers that makes sense to me is <a href="https://web.archive.org/web/20220525085959/http://www.golangdevops.com/2019/12/31/autopool/">autopool</a> which returns things to a <code>sync.Pool</code> automatically. This is the kind of thing that can happen &#x201C;whenever the GC happens to collect the value&#x201D; so is a good fit for finalizers.</p>
<p>As a nice side-effect, we also save the CPU cycles of parsing certificates that are already in use by other connections, although <a href="https://go.dev/cl/274234">Roland&#x2019;s cryptobyte rewrite of the parser</a> had made that way faster already.</p>
<p>This change has now landed in <code>master</code> and will be in Go 1.20 (unless we have to revert it) and it has zero exposed APIs: you just upgrade Go and every application that opens multiple TLS connections to the same endpoint will be automagically a little lighter and faster. &#x2728;</p>
<p>Like for most Go standard library changes, a lot of the work was actually in a less visible part: we spent quite a bit of time discussing whether this change had backwards compatibility issues, because the certificates you get from <code>PeerCertificates</code> are now shared between connections, and what happens if you modify one? We concluded this is fine because it was already the case that some certificates in the chain could be shared between connections, for example if they referred to the roots or intermediates <code>CertPool</code>. <a href="https://go.dev/cl/427155">We added an explicit note about it to the docs, too.</a></p>
<p><img src="https://words.filippo.io/content/images/2022/11/photo---1.jpeg" alt="The Central Park fountain with the sun shining behind it and lighting up the water. In the distance, trees and a couple of the tall square skyscrapers. The bottom half is filled by the reflection of the fountain in the water." loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>The root on Linux is actually a shared pointer to the Certificate value in the CertPool. There is some <a href="https://go.dev/cl/230025">cool stuff going on to keep roots compressed until they are needed</a>. Other platforms don&#x2019;t load the roots but instead use the platform API to do the verification and get back a full chain, so also the root gets duplicated. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>I run <code>make.bash</code> with <code>GOGC=off</code> because the compiler is short-lived enough and gets a little faster that way. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Why Did the OpenSSL Punycode Vulnerability Happen]]></title><description><![CDATA[We look at how fuzzing should have caught the OpenSSL Punycode vulnerability, and why that code was even necessary in the first place.]]></description><link>https://words.filippo.io/dispatches/openssl-punycode/</link><guid isPermaLink="false">6362a08102604e003daf6b24</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Wed, 02 Nov 2022 17:22:29 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>Some room-temperature takes on yesterday&apos;s not-quite-RCE vulnerabilities in OpenSSL 3.0, and on what there is to learn about safe cryptography engineering.</p>
<h2 id="a-recap">A recap</h2>
<p>Yesterday OpenSSL <a href="https://www.openssl.org/news/secadv/20221101.txt">published</a> version 3.0.7, which was pre-announced to contain a fix for a CRITICAL vulnerability, the first one since 2016 and since Heartbleed before that. The vulnerability was downgraded to HIGH. You can read why <a href="https://www.openssl.org/blog/blog/2022/11/01/email-address-overflows/">on the OpenSSL blog</a>.</p>
<p>The vulnerability is a stack write overflow in certificate verification. You can choose to overflow an unlimited number of <code>.</code> bytes, or four arbitrary bytes. The four-byte overflow is a little subtler, but the <code>.</code> is fairly straightforward.</p>
<p>There is a function, <code>ossl_punycode_decode</code> that decodes <a href="https://en.wikipedia.org/wiki/Punycode">Punycode</a>. Punycode is a way to encode Unicode as ASCII, used to represent Unicode strings in the ASCII-only world of DNS. <code>ossl_punycode_decode</code> takes an output buffer, and if the buffer runs out it keeps parsing and verifying the Punycode but discards the rest of the output.</p>
<p>I did not have the heart to figure out why it works like this. Maybe there&apos;s a good reason to do progressive parsing. Maybe it&apos;s an artifact of how C makes you do memory management or of OpenSSL&apos;s C style. Anyway.</p>
<p>You can see where this is going. Sometimes the &quot;should we discard the output or add it to the buffer&quot; check is faulty, and the function keeps appending to the buffer past its end.</p>
<p><a href="https://github.com/openssl/openssl/commit/680e65b94c916af259bfdc2e25f1ab6e0c7a97d6#diff-de2651c670dde92b08e86f386059436bee7f7271df21a18036e8b9d85b8070feL303-L307">This is the relevant snippet of code.</a> The reading key is that <code>result</code> is both the eventual return value, and the thing that controls whether output gets added to <code>outbuf</code>. Once <code>outbuf</code> runs out <code>result</code> gets set to 0, but line 303 doesn&apos;t check <code>result</code> before adding a <code>.</code>.</p>
<p>The crasher PoC is simply a domain with a lot of Punycode labels, like <code>xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a.xn--a</code>. All those <code>.</code>s end up on the stack even if the <code>outbuf</code> was smaller.</p>
<p><code>ossl_punycode_decode</code> is finally used (only) in the process of enforcing an X.509 chain feature called Name Constraints on email addresses, which is how this is reachable from certificate verification.</p>
<p><a href="https://github.com/colmmacc/CVE-2022-3602">Colm has a nice writeup and a PoC repo.</a> I live-streamed some analysis and played with Colm&apos;s PoC to confirm our understanding of the vulnerability. <a href="https://www.twitch.tv/videos/1640540734">You can watch the recording.</a></p>
<h2 id="on-severity">On severity</h2>
<p>This was initially announced as a CRITICAL, and then downgraded to HIGH. Honestly, I think might even be a MEDIUM, because of <em>where</em> you need to put these strings to reach the parser.</p>
<ol>
<li>
<p>The vulnerability is in certificate verification, so most TLS servers are not affected right off the bat. Only servers that accept client certificates do certificate verification.</p>
</li>
<li>
<p>Name Constraints are only checked after a chain has been built to a trust anchor. The code is not part of certificate parsing itself. <strong>This is very good.</strong> The malicious certificates need to be part of a chain ultimately signed by a trusted root, and most environments trust their roots.</p>
<ul>
<li>I&apos;m told Basic Constraints are checked before this, too, so you can&apos;t pull off a trick where you get a certificate from Let&apos;s Encrypt for <code>filippo.io</code> and then pretend it&apos;s an intermediate root and use it to sign a malicious certificate.</li>
</ul>
</li>
<li>
<p>IMHO most importantly, the malicious string must be in the <strong>intermediate root</strong>, not in the leaf. It&apos;s conceivable that there might be systems out there that issue untrusted parties leaf certificates for arbitrary email addresses, but I can&apos;t see an attacker getting their hands on an intermediate root with a custom Name Constraint that chains to a trusted root.</p>
</li>
</ol>
<p>So yeah, not the end of the world.</p>
<p>Lots of people criticized the OpenSSL project for causing alarm, but as someone who ran a vulnerability reporting program for a large project (Go) I think they did ok. Vulnerability triage is a high-pressure activity you do on a clock, and you have to make judgement calls. Upgrading the severity at the last moment is way worse than downgrading it, so they IMHO erred on the right side. Maybe it would have been nice to get a heads up of the downgrade, but you&apos;re sometimes doing analysis until the very last moment.</p>
<p>It&apos;s also the first CRITICAL in more than five years, so it&apos;s not like they are constantly crying wolf.</p>
<p>One thing I&apos;ll say about the process is that <a href="https://twitter.com/FiloSottile/status/1587376656594993154">it would have been nice to know the CVE number in advance</a> so we could coordinate effectively instead of using made up names, which is the point of CVEs.</p>
<h2 id="why-did-it-make-it-to-a-release">Why did it make it to a release</h2>
<p>There are process lessons to learn, though.</p>
<p>Hanno, as always bridging the gap between available tools and concrete results, <a href="https://twitter.com/hanno/status/1587775675397726209">pointed out that this vulnerability could be found in a second by LibFuzzer with the simplest possible fuzzing function</a>.</p>
<p>I&apos;m transcribing it here just to make a point about how simple it is. <code>ossl_punycode_decode</code> is not a carefully chosen internal function, it has <a href="https://github.com/openssl/openssl/blob/00e38edcfb95b556a59de96e0c18343828929c8f/doc/internal/man3/ossl_punycode_decode.pod">a man page</a>.</p>
<pre><code>#include &quot;crypto/punycode.h&quot;

int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {
    unsigned int out[32];
    unsigned int outlen = 32;
    ossl_punycode_decode((const char *)data, size, out, &amp;outlen);
    return 0;
}
</code></pre>
<p><strong>I&apos;m a big fan of asking &quot;how could we have found this bug in advance without knowing anything about it?&quot;</strong> Sometimes the answer is complicated, like &quot;we would have had to write a fuzzer for all arithmetic operations that mixes values that we know in advance are likely to hit edge cases even if we don&apos;t know which ones and then compare against a known-good implementation&quot; (which is what we did in the Go standard library anyway!).</p>
<p>This time it looks like the answer was &quot;we should have used a fuzzer at all&quot;. That&apos;s disappointing. This was <strong>newly added code</strong>. This was <strong>a parser written in C</strong>. This was a <em>perfect</em> match for fuzzing. It didn&apos;t require any novel tool or technique.</p>
<p>We could talk about expanding tooling for fuzzing coverage reports, and I think we can do a lot in general to make fuzzer behavior more understandable. However here the issue would have been prevented by just having a policy of &quot;when fuzzing makes perfect sense and is very easy, use it&quot;.</p>
<p>I&apos;m not sure what the next step is or who should take it, but there seems to be a large margin for cheap process improvements that would yield a large security benefit in critical software infrastructure.</p>
<h2 id="why-was-this-code-even-necessary">Why was this code even necessary</h2>
<p>There&apos;s an even wider scope to consider, though. Why is that code there? Could it have been even more secure by not existing?</p>
<p>As <a href="https://twitter.com/bagder/status/1587777555121246209">curl author Daniel Stenberg said</a>, &quot;I&apos;ve never even considered to decode punycode. Why does something like OpenSSL need to decode this?&quot;</p>
<p>The answer is: <strong>an explicit IETF design choice, that made punycode decoding part of X.509 verification, without even a line of acknowledgement in the Security Considerations</strong>.</p>
<p>As we said, Punycode is about encoding Unicode in domain names. You might be tempted to say &quot;ah, why would we want Unicode in delicate cryptography stuff like this&quot;. I invite you to resist that urge. <strong>Internationalization is not the issue, internationalization is the job.</strong> We make things to serve users, and users (mostly outside the US and UK) communicate using more than ASCII, and their domain names and email addresses should be written in their language and work as well as English ones. The general effort to expand i18n is good.</p>
<p>How did that lead to &quot;OpenSSL has a Punycode parser&quot; though? Well, folks (rightfully) wanted Unicode email addresses in X.509 certificates, but punycode is only defined for domain names. What if there&apos;s Unicode in the local part (the stuff before the <code>@</code>) of email addresses?</p>
<p>There were a number of ways to solve this!</p>
<p>One was to just define how to encode the local part in ASCII, staying true to the idea of punycode as the way to abstract encoding issues. <a href="https://datatracker.ietf.org/doc/html/draft-lbaudoin-iemax-02">Here&apos;s a draft</a> that does just that by prepending a <code>:</code> and then encoding with Base64. Roughly one page long. No Name Constraints interactions, barely any new code path. We could have had nice things!</p>
<p>But nope. Here&apos;s <a href="https://www.rfc-editor.org/rfc/rfc8398.html">RFC 8398</a>. It adds a new Subject Alternative Name type that&apos;s a UTF-8 email address, <code>SmtpUTF8Mailbox</code>.<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> But what if the issuer (i.e. the intermediate root) has a Name Constraint that says it can only issue for a certain domain? That Name Constraint will be encoded as Punycode... how does it apply to a <code>SmtpUTF8Mailbox</code> in a leaf? Well, <a href="https://www.rfc-editor.org/rfc/rfc8398.html#section-5">you decode the Punycode before doing the comparison</a>, of course. The sections on matching and Name Constraints are longer than the whole alternative draft, and there&apos;s <a href="https://www.rfc-editor.org/rfc/rfc8399">a whole other RFC</a> of amendments to path verification.<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p>What&apos;s really short instead is the Security Considerations section with no mention of the fact that this adds a whole new parser to the critical path of certificate verification, so I&apos;m not sure the risk and cost of software complexity was taken into account, making this as much an IETF specification failure as a C language failure.</p>
<p>In conclusion, this is why we resist adding even trivial features to crypto/x509, Go&apos;s implementation of a X.509 parser and verifier. I seem to remember a feature request for exposing <code>otherName</code> fields of certificates, which includes <code>SmtpUTF8Mailbox</code>. It felt pretty innocuous: just another field we could add to the struct, five lines of code maybe. However, the moment we expose it we need to apply Name Constraints to it! Not doing so would be a security vulnerability. Without knowing it, we could have opted into all this complexity and ended up importing a Punycode parser in crypto/x509. Still, it would not have been written in C, I guess.</p>
<h2 id="the-picture">The picture</h2>
<p>Florence is always pretty.</p>
<p><img src="https://words.filippo.io/content/images/2022/11/IMG_9255.jpeg" alt loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>It&apos;s even more complex, actually: if there&apos;s Unicode in the local part, you use <code>SmtpUTF8Mailbox</code>, if there&apos;s Unicode only in the domain you&apos;re still expected to use punycode. You could end up with most certificates in the organization using punycode and only a few using <code>SmtpUTF8Mailbox</code>, which would surely work out great. <a href="https://www.rfc-editor.org/rfc/rfc8399#section-2.5">RFC 8399, Section 2.5</a> summarizes the new logic X.509 verifiers need to apply. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>There are some good choices in there, like deprecating NCs on the local parts of email addresses that no one was using, instead of defining UTF-8 constraints. But that also opened the door to keeping encoding issues entirely out of Name Constraints while still supporting international domains through Punycode, so it really feels like a missed opportunity. Punycode was supposed to be the abstraction layer, to keep encoding out of the rest of the stack. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[The Reciprocal Value of Access to Maintainers]]></title><description><![CDATA[Having a direct line to the maintainers of Open Source project is reciprocally valuable, and made possible by high-touch contractual relationships.]]></description><link>https://words.filippo.io/dispatches/reciprocal/</link><guid isPermaLink="false">6358784fc67051004ddb9886</guid><category><![CDATA[dispatches]]></category><category><![CDATA[maintainer]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Wed, 26 Oct 2022 01:35:19 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>Last May I left Google to build a more sustainable model for Open Source maintenance. After a summer break, I resumed <a href="https://words.filippo.io/dispatches/go1-20/">my maintenance work on the Go project</a> in September, and I started offering my services to companies that rely on Go.</p>
<p>My vision is that of Open Source maintenance as a real <a href="https://words.filippo.io/professional-maintainers/">profession</a>, where maintainers offer ongoing contracts to the companies that critically rely on their projects. Maintainers get paid like the senior engineers they are, and companies get reassurances on the reliability of their dependencies, mitigating business risk.</p>
<p>When pitching my services to companies, I am selling three things: ongoing maintenance, access to the maintainer, and marketing. An easily overlooked component of the access part is <strong>the reciprocal value of companies having a direct line to the maintainers</strong> of the projects they rely on.</p>
<p>If you&apos;re a company that relies on a critical piece of Open Source software, the project&apos;s roadmap matters to you. For example:</p>
<ul>
<li>you might be interested in adopting a new package that&apos;s being added in the next release and want to make sure it fits your use case</li>
<li>you might rely on a legacy option that&apos;s being deprecated or made simpler and slower to reduce complexity and need that rescheduled</li>
<li>you might consistently find your developers make mistakes when using an API and could benefit from a safer interface</li>
<li>you might be affected by a set of bugs in a specific component that you need addressed with better testing or a refactor</li>
<li>you might use a protocol implementation that&apos;s evolving and that the project has to keep up with</li>
</ul>
<p>I&apos;m not talking about extra features or individual bugfixes. Those, you can usually contribute as a PR (although that <em>increases the maintenance burden</em><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> and still requires maintainer time for the design, decision, and code review processes). All the examples I listed above are things you primarily need the maintainer to prioritize in their own roadmap.</p>
<p>How do you encourage them to do that and support them in doing it? There is no good, reliable answer in the current models of Open Source.</p>
<p>Sure, there&apos;s many ways to reach a maintainer. The public issue tracker, their emails... even Twitter DMs (please don&apos;t). I don&apos;t always respond, but I truly read everything that comes my way. The problem is that an endless stream of unqualified requests is not very useful for decision-making.</p>
<p>Everyone wants something from your project, everyone has a feature request or an idea for how to design a thing or a theory for what&apos;s the root cause of a bug or a preference for what to prioritize next. When you&apos;re <a href="https://alexdanco.com/2020/10/08/making-is-show-business-now/">working in public</a> you need to change how you think about external inputs: they are kind offers, that you&apos;re free to take or leave.</p>
<p>Even more importantly, they are <em>unqualified</em>: as a maintainer you don&apos;t know if they reflect a real-world need that&apos;s impacting production workloads, or just someone who did not do their research properly or who would be better served by a different project with different goals. It can actually be pretty hard to get reliable, actionable information about the needs of the users of your project.</p>
<p>There are a few things that work. First, personal experience as a user of your own library, which is invaluable but also unavoidably very limited in scope. Second, personal relationships and high-bandwidth interactions. For example, if I meet an engineer at a conference who tells me they are struggling with the performance of a component I get to grill them on what workload they&apos;re running, what they tried to address it, what alternatives they considered, what tradeoffs they can make. I can&apos;t afford to do that for every open issue! Those interactions also grow into personal relationships, where I can trust that they did their research before raising something directly with me.</p>
<p>Those interactions and personal relationships can be very valuable for a company, but they are not a reliable risk mitigation if they depend on the timing of a conference or on the continued employment of a person who has the maintainer&apos;s ear.</p>
<p>That&apos;s what a contractual relationship with a maintainer does: it institutionalizes the high-trust, high-attention relationship and makes it reliable.</p>
<p>From the other side, having a direct line to the major users of my code is valuable to me as a maintainer: I get to reach out, ask questions, and learn about how they use it. Is this component as important as I think? Does anybody use this feature? Is deprecating that feasible? What are the pain points of this thing I am planning to refactor? Would this new solution address real-world use cases?</p>
<p>To be clear, what this doesn&apos;t do is provide a guarantee that a certain issue will be resolved or a change merged. It also doesn&apos;t cut out other, non-paying users. It&apos;s not pay to play. That wouldn&apos;t be in anyone&apos;s interest, because an Open Source project that prioritizes one stakeholder over the ecosystem will either bloat or become irrelevant, losing most of its value.</p>
<p>This reciprocal value is, I believe, very specific of a funding model that involves <a href="https://en.wikipedia.org/wiki/High-touch">high-touch</a> direct relationships with multiple companies. If an intermediary gets involved, the communication channel is severed. If there is only one funder, the broad surveying capability is lost.</p>
<p>This is why I am pursuing professional maintainership as a high-touch contractor. If this is interesting to you and your company relies on Go and its cryptography libraries, drop me a line.</p>
<h2 id="the-picture">The picture</h2>
<p>Pop quiz: what&apos;s this lion&apos;s name?</p>
<p><img src="https://words.filippo.io/content/images/2022/10/IMG_8969.jpeg" alt="A large stone lion, bigger than life, on a pedestal pictured from the right. In the background, a tree, a building with white columns, and a skyscraper." loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>This might be an unpopular opinion: sending PRs is not contributing back to the project. It might be contributing back to the ecosystem, but it imposes a cost on the project both immediately (for code review) and on an ongoing basis (for maintenance). <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[age and Authenticated Encryption]]></title><description><![CDATA[age currently only provides confidentiality. We look at how a couple small tweaks can introduce authentication, when you'd need it, and how it is different from signing.]]></description><link>https://words.filippo.io/dispatches/age-authentication/</link><guid isPermaLink="false">6335cea8cce5ec003d9b7b2a</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Thu, 29 Sep 2022 18:45:31 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p><a href="https://age-encryption.org">age</a> is a file encryption format, tool, and library. It was made to replace one of the last remaining GnuPG use cases, but it was not made to <em>replace GnuPG</em> because in the last 20 years we learned that cryptographic tools work best when they are specialized and opinionated instead of flexible Swiss Army knives. How it went is that you&apos;d read <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">The PGP Problem</a> on the Latacora blog, get convinced that you should use the right tool for the job, scroll to the &quot;Encrypting Files&quot; section, and it&apos;d say:</p>
<blockquote>
<p>This really is a problem. If you&#x2019;re <em>not</em> making a backup, and you&#x2019;re <em>not</em> archiving something offline for long-term storage, and you&#x2019;re <em>not</em> encrypting in order to securely send the file to someone else, and you&#x2019;re <em>not</em> encrypting virtual drives that you mount/unmount as needed to get work done, then there&#x2019;s no one good tool that does this now.</p>
</blockquote>
<p>age was made to fill that gap. It&apos;s an annoying gap to fill, because the job is much more underspecified than, say, virtual drives or even backups. People mean different things for files, and even for encryption. They want to encrypt with a passphrase, with a symmetric key, with an asymmetric key, with KMS, with a YubiKey... We had a whole session at the High-Assurance Cryptography Workshop titled something along the lines of &quot;Encrypting files: what does it mean???&quot;.</p>
<p>Eventually what we targeted with age was whatever people were using <code>gpg -c</code> (password encryption) or <code>gpg -e</code> (public key encryption) for. We assumed by the time you dropped down to age you knew what problem you were trying to solve, and wanted a tool that would spare you the pain and risk of dealing with a myriad of legacy cryptographic options you don&apos;t care about. We made it a good UNIX tool, working on pipes, and put you in charge of key management, simplified down to copy-pastable short strings. We introduced <a href="https://github.com/FiloSottile/age/releases/tag/v1.1.0-rc.1">plugins</a> to support encrypting to whatever you want (<a href="https://github.com/str4d/age-plugin-yubikey">YubiKeys</a>, KMS, ...).</p>
<p>One thing we decided is that we&apos;d not include signing support. Signing introduces a whole dimension of complexity to the UX, to key management, and to the cryptographic design of a streamable seekable format. age is in the business of integrity and confidentiality, not authentication. This was <a href="https://github.com/FiloSottile/age/issues/51">hotly debated early on</a>, and still is <a href="https://twitter.com/FiloSottile/status/1475954548556673024">periodically</a>.</p>
<p>In short, while no one can modify an encrypted age file, anyone can replace it with a completely new encrypted file. (This is not actually strictly true, as we&apos;ll see later, but it&apos;s what age says on the tin to be conservative.)</p>
<p>Still, I kept thinking about it, and I am now considering a small backwards-compatible tweak that would introduce explicit support for authentication (not signing!) in age, based on the unadvertised authentication properties that age already has. I&apos;m looking for feedback, especially on the use cases (do you need it? do you not? what for? would this work for you?) so click the reply button or <a href="https://github.com/FiloSottile/age/discussions">open a discussion on GitHub</a>.</p>
<p>First, some background about what authentication is for, and what it is.</p>
<h2 id="what-doesnt-need-authentication">What doesn&apos;t need authentication</h2>
<p>There are a number of age use cases that don&apos;t need age to take care of authentication. They mostly match what age is used for today, which I find fairly reassuring.</p>
<h3 id="storing-secrets-next-to-code">Storing secrets next to code</h3>
<p>If you use something like <a href="https://major.io/2022/04/19/encrypted-gitops-secrets-with-flux-and-age/">SOPS</a> or just check age secrets into a git repository next to source code, you need an authentication story for the whole repository. Having authentication for the secrets will do nothing if the attacker can change the source code that decrypts and uses them.</p>
<p>That story can simply be &quot;we trust GitHub&quot; like most projects. Encrypting secrets with age will keep them confidential even if the project is Open Source, and anyone wanting to replace them will have to make a PR even if they can generate a new valid age file.</p>
<h3 id="local-password-store">Local password-store</h3>
<p>I use <a href="https://github.com/FiloSottile/passage">passage</a>, a <a href="https://www.passwordstore.org/">password-store</a> fork, with <a href="https://github.com/str4d/age-plugin-yubikey">age-plugin-yubikey</a> as my password manager. I don&apos;t need it to authenticate the secrets it decrypts: again, if an attacker can tamper with the encrypted secrets they can change the code that my laptop will run, and do much worse.</p>
<p>(Actually, I also obviously have full-disk encryption enabled, so the only reason I use passage instead of a <code>passwords.txt</code> file<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> is that with age-plugin-yubikey each decryption requires a YubiKey physical touch. This way even if you compromise my laptop you can&apos;t exfiltrate all my secrets at once.)</p>
<p>I honestly didn&apos;t really get why you&apos;d use passage or password-store at all without a hardware key, which is part of why age doesn&apos;t have an agent yet, but I&apos;ve sort of come around to the &quot;secrets are synced to the cloud&quot; scenario. That use case <em>does</em> need authentication if you&apos;re worried about the attacker feeding you fake passwords.</p>
<h3 id="self-authenticating-data">Self-authenticating data</h3>
<p>If a file is self-authenticating, for example because it starts with a secret token, the attacker can&apos;t produce a new age file <em>that starts with that secret</em> without knowing it. This is because age uses AEADs and never produces unauthenticated output. &quot;Wait, did you just say age is authenticated?&quot; Yes, the term is overloaded and it&apos;s confusing. We&apos;ll talk more about the difference between authenticated-as-in-AEAD and authenticated-as-in-this-article later.</p>
<p>I know of companies in the payment processing space that use age like this. In fact, they probably got a security update by switching from unsigned PGP to age, because the mechanism that provides this kind of integrity in PGP, the &quot;Modification Detection Code&quot;, is/was optional, predates AEADs, and is sketchy at best.<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<h3 id="encrypt-to-delete">Encrypt-to-delete</h3>
<p>Deleting bits from storage media is hard, especially in the era of SSDs and wear leveling. Instead, I often encrypt something with age, and just make sure the key never hits permanent storage. Key gone, data as good as deleted.</p>
<p>Here I am only worried about passive attacks, like someone who finds the drive in a dumpster or attached to a cloud VM, not about attackers with the ability to replace the file while I&apos;m working on it.</p>
<h2 id="what-does-need-authentication">What does need authentication</h2>
<p>Does this mean that no one could benefit from authentication? Nope, that&apos;s why we&apos;re here. I can think of at least one broad use case where lack of authentication is uncomfortable.</p>
<h3 id="cloud-backups">Cloud backups</h3>
<p>If you make a backup with age, and then store it in the cloud, age will prevent the cloud provider from inspecting the backups. However, the provider <em>can</em> replace the whole backup with something else. Maybe you&apos;ll notice while recovering it because your files are not in there, maybe you&apos;ll not and run some code from it that gives the cloud provider access that shouldn&apos;t have been available. Not great.</p>
<p>This generally extends to storing anything in the cloud encrypted with age (or with GnuPG without signing it).</p>
<h3 id="borderline-misuses">Borderline misuses</h3>
<p>Aside from untrusted remote storage, I could only come up with some contrived scenarios. If you were to use age as a way to protect a public API, like &quot;POST an age-encrypted file to this endpoint with your instructions&quot;, you&apos;d probably want it to provide authentication.</p>
<p>age is for <em>file encryption</em>, one could argue that this is misuse&#x2014;there are better ways to build something like this than using age&#x2014;but we&apos;re in the business of making safe tools, not another generation of footguns.</p>
<p>(There&apos;s a good chance I&apos;m overlooking some other use cases! I&apos;d like to know about them as I try to design a solution that works broadly. Hit the reply button, you know the drill.)</p>
<h2 id="authentication-vs-aeads">Authentication vs AEADs</h2>
<p>You might have heard that a selling point of age is that it uses AEADs, which expands to Authenticated Encryption with Additional Data. Doesn&apos;t that mean age is authenticated!?</p>
<p>No, that&apos;s about symmetric encryption. I know it&apos;s confusing. We&apos;re bad at naming things.</p>
<p>What using AEADs means is that if you encrypt this file</p>
<pre><code>The Magic Words are Squeamish Ossifrage.

We attack at dawn.
</code></pre>
<p>and the attacker knows the <code>We attack at dawn</code> part but not the first part, they can&apos;t tamper with it, flipping some bits, turning <code>dawn</code> into <code>dusk</code>. AEADs have Message Authentication Codes that ensure that whoever authored the whole message knew the symmetric key that allows decrypting it.</p>
<p>This is table stakes and in 2022 you should not use anything that doesn&apos;t do authenticated symmetric encryption.</p>
<p>What&apos;s tricky about AEADs is that they authenticate the whole message at once at the end. This is fine if your message is small enough. If your message is too big, like a multi-GB file, you will want to stream it rather than hold it all in memory, and might be tempted to output (&quot;release&quot;) plaintext as you decrypt it, before you get to and verify the MAC at the end. That&apos;s how you get attacks like <a href="https://efail.de/">EFail</a>. What age does is split the file into 64KiB chunks, encrypt each of them with an AEAD, and verify each of them before releasing its plaintext. The scheme it uses is called <a href="https://eprint.iacr.org/2015/189">STREAM</a>, but intuitively it&apos;s just about putting a counter in the AEAD nonce.</p>
<p>Anyway, AEADs operate at a lower level than asymmetric encryption. What this article is about is authenticated <em>asymmetric</em> encryption, where you get guarantees about who sent the whole message, not just about the message not being partially tampered with.</p>
<h2 id="authentication-vs-signing">Authentication vs signing</h2>
<p>Wait, &quot;guarantees about who sent the whole message&quot;... isn&apos;t that just signing? Well, no. Existing tools (<em>cough</em> gpg <em>cough</em>) trained us to consider them one and the same because the only way they provide sender authentication is via signing, but authentication is a more limited and easily achieved property. Signing is publicly verifiable: the recipient can go to a third party and prove that the sender sent the message by showing the signature and the sender&apos;s public key. Sender authentication proves <em>to the recipient</em> that the message was generated by the sender. There isn&apos;t necessarily a sender public key, and the recipient might be able to forge messages looking like they are from the sender (called &quot;key compromise impersonation&quot; if you don&apos;t like it, and &quot;deniability&quot; if you do).</p>
<p>Examples of schemes with sender authentication but without signing are the <a href="https://noiseprotocol.org/noise.html#one-way-handshake-patterns">Noise patterns K and X</a>, <a href="https://signal.org/docs/specifications/x3dh/">Signal&apos;s X3DH</a>, <a href="https://words.filippo.io/dispatches/nacl-api/">NaCl&apos;s box</a>, or <a href="https://libsodium.gitbook.io/doc/key_exchange">libsodium&apos;s key exchange APIs</a>.</p>
<p>Another difference is that while authentication can happen at the key exchange level, and the derived shared symmetric key can be used with STREAM as age does, signatures need to be necessarily computed over the whole message. This sets us back on making the format seekable and streamable: either we make an expensive asymmetric signature for every chunk, or we get fancy with signed Merkle trees, which anyway get us a streamable format only either in the encryption or in the decryption direction. (Or, like discussed above, we just stick a signature at the end and release unverified plaintext at decryption time, causing countless vulnerabilities.)</p>
<h3 id="on-combining-signing-and-encryption">On combining signing and encryption</h3>
<p>The common advice for people who need encryption and authentication is to combine age with a signing tool like signify or OpenSSH (which can sign files now!). Part of why I&apos;m thinking about age and authentication is that I am not very satisfied with that. Combining encryption and signing is actually kinda tricky and can&apos;t be done perfectly. This is also why we did not document recommended ways to do this.</p>
<p>If you <em>encrypt and then sign</em>, an attacker can strip your signature, replace it with their own, and make it look like they encrypted the file even if they don&apos;t actually know the contents.</p>
<p>If you <em>sign and then encrypt</em>, the recipient can decrypt the file, keep your signature, and encrypt it to a different recipient, making it look like you intended to send the file to them.</p>
<p>What you need to avoid both issues at the same time is a different cryptographic primitive called <em>signcryption</em>. The good (???) news is that no popular tool does signcryption, so you&apos;re probably not worse off by using signify and age.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<h2 id="age-is-already-authenticated">age is already authenticated!</h2>
<p>Here&apos;s the big reveal: age is already authenticated, sort of. <strong>You can&apos;t produce an age file that will decrypt with a given identity if you don&apos;t know its recipient.</strong><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> (Read on for an important gotcha though, which is why this is not yet advertised.)</p>
<p>This means that if you need to make sure an attacker can&apos;t forge age encrypted files for you, you just need to keep the recipient string (<code>age1...</code>) secret from the attacker. For example, if you upload backups to cloud storage, simply make sure you don&apos;t upload the recipient string along with them.</p>
<p>It will be cryptographically impossible for the attacker to generate a file that age will successfully decrypt with the corresponding identity. This is easily shown with an information-theoretical argument: the age file key is encrypted with an AEAD; the key for that is derived with HKDF from the shared secret, the ephemeral key, <em>and the recipient</em>.<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> Without knowledge of the recipient, the attacker can&apos;t produce a key that will cause the AEAD decryption to succeed. age is very simple, so it&apos;s also easy to show we don&apos;t have baked-in default private keys or NULL cipher modes, so the only identities that are accepted are the ones you specify on the command line.</p>
<p>It&apos;s not as straightforward to show that the recipient can&apos;t be extracted from an encrypted file or from an online decryption oracle, but there&apos;s literature about this that approaches it from the angle of anonymity: if it were possible to extract the recipient, it would be possible to deanonymize it, and they show that&apos;s not possible.</p>
<p>Whether this all holds depends on the recipient type. I am confident the property holds for the X25519 recipients, and that it would hold for a hypothetical <a href="https://words.filippo.io/dispatches/post-quantum-age/">Kyber768+X25519</a> one, but it&apos;s important not to advertise it as an age-wide property.</p>
<p>Note that unlike Noise/X3DH/NaCl<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup> this doesn&apos;t provide for multiple sender identities: the only authentication performed here is &quot;the sender knew the recipient for this identity&quot;. If you need to tell apart files encrypted by Server A and by Server B, you&apos;ll need to generate two separate keypairs, and give each of them a different one. Thankfully, age keypairs are cheap! This lets us avoid adding an extra knob in the UI for the sender&apos;s public/private key: when you use <code>-r</code> you&apos;re proving you know the recipient, and when you use <code>-i</code> you&apos;re saying you want the file to come from someone who knows the corresponding recipient. This might not be enough to, say, encrypt emails, but it&apos;s enough for all the use cases we discussed above.</p>
<h2 id="the-ux-issue">The UX issue</h2>
<p>The main issue with making this guarantee usable is that the recipient is supposed to be public, and now we&apos;re telling people to keep it secret.</p>
<p>I actually had a very hard time getting a cryptographer<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup> to confirm my understanding of the authentication properties, because they kept saying &quot;but the public key is public&quot; and I kept saying &quot;ok but imagine we didn&apos;t give it to the attacker&quot; and we kept going in a loop like that until I said &quot;alright there is no public key anywhere and let&apos;s call this curve point the super-secret sender key&quot;. It went ok from there.</p>
<p>The best idea I have so far is making a plugin called <code>authkey</code> for this, and then the recipients will look like <code>age1authkey1...</code> which might be enough? The alternative, which I am not a fan of, is introducing a new recipient format like <code>AGE-AUTH-KEY1...</code>. I&apos;m looking for feedback on this!</p>
<h2 id="the-multiple-recipients-issue">The multiple recipients issue</h2>
<p>It&apos;s not this simple though. There is also a gotcha that we need to fix with a technical tweak.</p>
<p>If you encrypt a file to Alice&apos;s recipient and to Bob&apos;s recipient (age supports <a href="https://github.com/FiloSottile/age/blob/main/README.md#multiple-recipients">multiple recipients</a>), and send it to both, you just gave a blank check to Alice and Bob to encrypt files to each other even if they don&apos;t know each other&apos;s recipients.</p>
<p>How that works is that Alice can take the file, derive the file key using her identity, and then use the file key to change the contents of the file, keeping the same header. That new file will still decrypt successfully with Bob&apos;s identity, but it was produced by Alice, who doesn&apos;t know Bob&apos;s recipient. Alice can even drop her stanza from the header and recompute the HMAC, and Bob wouldn&apos;t even know this happened.</p>
<p>This is too sharp an edge to leave it laying around, and it&apos;s why age doesn&apos;t say &quot;it&apos;s authenticated, just keep the recipient secret&quot; on the tin.</p>
<p>We encountered this before while designing age: the symmetric passphrase-encryption <em>scrypt</em> recipient type can&apos;t be used with multiple recipients, precisely for this reason. We figured that if you decrypt a file with a passphrase you have an expectation that whoever produced it knew the passphrase. That is, there is a sender authentication expectation embedded in the passphrase encryption UX. To stop an attack like the one above, we <a href="https://github.com/FiloSottile/age/blob/000e9311011084a3e80e5baddc62e44cf2f3d337/age.go#L114-L122">special-cased it</a>.</p>
<p>We can do the same thing with our special authenticated recipient type: enforce<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup> that when it&apos;s used, it&apos;s the only recipient of the file. Rather than adding a special case, I am thinking of extending the <a href="https://github.com/C2SP/C2SP/pull/5">plugin protocol</a> and <a href="https://pkg.go.dev/filippo.io/age#Recipient"><code>Recipient</code> interface</a> to let a recipient specify that it wants to provide authentication. This will also let us remove the scrypt special case and enable symmetric encryption plugins that are as good as the built-in scrypt recipient type &#x1F64C;</p>
<h2 id="age-authkey-plugin">age-authkey-plugin</h2>
<p>Summing up, bringing authentication to age should be as simple as</p>
<ol>
<li>adding a way for recipient implementations and plugins to signal they should only ever be used as the only recipient for any given file</li>
<li>making a plugin/built-in recipient type that flips that flag and has a clear name but otherwise looks exactly like the X25519 recipient type</li>
</ol>
<p>The plugin might not even need to implement the identity/decryption side:<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup> it can just produce files that decrypt with regular native age identities, as those already provide authentication as designed. This prevents the receiving side from checking for misuse, but as we said an attacker can just strip the other recipients from the file, and once a file is encrypted to multiple recipients the damage is done.</p>
<p>None of this is implemented yet, so please reach out with feedback on use-cases, UX, and cryptography design, whether positive or negative!</p>
<h2 id="the-picture">The picture</h2>
<p>Took this at 100ft with no filter, no flash, no custom white balancing, and no post-production. It was this eerie spot of bright red at a depth where only blue light can get. Apparently it&apos;s symbiotic bioluminescent bacteria. Anyway, it had <em>no right</em> to be that red that deep under the sea.</p>
<p><img src="https://words.filippo.io/content/images/2022/09/Newsletter---1.jpeg" alt="A red anemone with two clownfish, surrounded by deep blue reef." loading="lazy"></p>
<p>If you want to stay up to date with my work on age, consider <a href="https://twitter.com/FiloSottile">following me on Twitter</a> or <a href="https://filippo.io/newsletter">subscribing to this newsletter</a> if you haven&apos;t already!</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Unpopular opinion: <code>passwords.txt</code> is <em>fine</em>. If you can extract files from my laptop you can probably get my cookies (depending on how the OS keychain is used), and certainly a number of authentication tokens, as well as pictures and private documents. <a href="https://xkcd.com/1200/">Relevant XKCD.</a> <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>As far as I can tell, MDCs are mandatory now, but <a href="https://crypto.stackexchange.com/questions/80098/what-does-modification-detection-code-mdc-in-openpgp-do">were optional for a long time</a>, meaning attackers could just strip them, generating only a warning that every user and application ignored. This is how <a href="https://efail.de/">EFail</a> happened. GnuPG also supports AEADs now, but again when dealing with a fragmented ecosystem full of weaker protocol options, who knows if the other side updated or not, and whether it&apos;s configured correctly or not. See the Authentication vs AEADs section for some more background about why all this matters. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn3" class="footnote-item"><p>It&apos;s especially vexing that GnuPG doesn&apos;t do signcryption because it totally could! Its UX already involves dealing with a sender key pair and a recipient key pair for each encrypt+sign operation, and its signatures span the whole message so safe streaming is already out the window. However, alas. <a href="#fnref3" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn4" class="footnote-item"><p>In age, an identity is a string commonly containing a private key like <code>AGE-SECRET-KEY-16DDVPME9RAUQYXULTUXG0L0L87W52H2C0M7PTEXSS9JKHSTR525QP7Z3SM</code> and a recipient is a string commonly containing a public key like <code>age1k5flf920mg7lderduqclc74m5aevha47rzk6x4xww48m9xzy93gs37q7c6</code>. <a href="#fnref4" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn5" class="footnote-item"><p>This doesn&apos;t even rely on X25519 itself having contributory behavior, which requires rejecting the all-zeroes output. The age spec and implementation still do that, but even if an implementation missed that check the HKDF derivation would still provide authentication. <a href="https://eprint.iacr.org/2019/526.pdf">Other protocols were not as lucky.</a> <a href="#fnref5" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn6" class="footnote-item"><p>X3DH does three DH exchanges, while here we do only the one. The second introduces sender identities, which we intentionally reject for UX/UI reasons. The third is about forward secrecy and it involves rotating pre-keys. It would be interesting to make a forward-secrecy plugin for age that uses some support server to store the pre-keys. We discussed this briefly at HACS and it might be worth writing up, but it&apos;s going to be another issue :) <a href="#fnref6" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn7" class="footnote-item"><p>&quot;Filippo, I thought you were a cryptographer?&quot; When talking with people who care about the difference, I&apos;m more properly a cryptography engineer, and I still occasionally get actual cryptographers to review my stuff if I&apos;m doing something weird. <a href="#fnref7" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn8" class="footnote-item"><p>This doesn&apos;t stop a malicious sender from bypassing the check and encrypting a file to multiple recipients anyway, but a malicious sender can just share the secret recipient string, so we&apos;re not defending against that, just against accidental &quot;misuse&quot;. (Or, more properly, unexpected behavior.) <a href="#fnref8" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn9" class="footnote-item"><p>This is something I&apos;m pretty happy about the <a href="https://github.com/C2SP/C2SP/pull/5">plugin protocol</a>: a plugin can implement only the recipient side and produce files that decrypt without the plugin, or just the identity side and decrypt files that were encrypted without the plugin. It enables things like agent forwarding to happen entirely behind a plugin. Or, if you have a hardware token or an API that supports X25519, you can make a plugin for it that doesn&apos;t require any special software on the encryption side. <a href="#fnref9" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Planning Go 1.20 Cryptography Work]]></title><description><![CDATA[My plans for Go 1.20 include landing the crypto/ecdh package, making progress on moving math/big out of the security perimeter, and a batch of crypto/tls work.]]></description><link>https://words.filippo.io/dispatches/go1-20/</link><guid isPermaLink="false">631f6ade632962003db5de01</guid><category><![CDATA[dispatches]]></category><category><![CDATA[maintainer]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Mon, 12 Sep 2022 21:37:12 GMT</pubDate><content:encoded><![CDATA[<p>As you might know, <a href="https://twitter.com/FiloSottile/status/1522671407636877315">I left Google in spring</a> to try and make the concept of a <a href="https://words.filippo.io/professional-maintainers/">professional Open Source maintainer</a> a thing. I&apos;m staying on as a maintainer of the Go cryptography standard library, and I am going to seek funding from companies that rely on it, want to ensure its security and reliability, and would like to get a direct line to the maintainers of their critical business infrastructure. (If this sounds like you, reply to this email!)</p><p>In the meantime, though, the <a href="https://github.com/golang/go/wiki/Go-Release-Cycle">Go development cycle</a> progresses inexorably, with the Go 1.20 feature freeze coming at the beginning of November. Once the main Go tree freezes, I plan to work on <code>x/crypto/ssh</code> and <code>age</code>, but in the meantime I have a few things I am excited about for Go 1.20.</p><!--kg-card-begin: markdown--><h2 id="cryptoecdh">crypto/ecdh</h2>
<p>The most visible change will be the landing the new <a href="https://pkg.go.dev/crypto/ecdh@master"><code>crypto/ecdh</code> package</a> I <a href="https://github.com/golang/go/issues/52221">proposed</a> and <a href="https://go.dev/cl/398914">implemented</a> earlier this year. The package provides a safe, <code>[]byte</code>-based, easy to use API for Elliptic Curve Diffie-Hellman over Curve25519 and NIST curves (P-256 and company, but no P-224 if we can get away with it).</p>
<p><code>crypto/ecdh</code> was made possible by a long-running refactor of the elliptic curve implementations in the standard library. Between Go 1.17 and Go 1.19, most critical code was moved to safer low-level APIs under <code>crypto/internal/nistec</code> and <code>crypto/internal/edwards25519</code>, large pieces were replaced with code generated from <a href="https://github.com/mit-plv/fiat-crypto">fiat-crypto</a>&apos;s formally verified models, making every curve constant time, most group logic was replaced with modern complete formulas, and even <a href="https://go-review.googlesource.com/c/go/+/396255">the assembly was massaged to implement the same functions on all architectures</a> and fit the nistec API. <a href="https://go-review.googlesource.com/c/crypto/+/315269">Some assembly is gone</a>, actually!</p>
<p>(<a href="https://go-review.googlesource.com/q/hashtag:crypto-elliptic-refactor">Here are all the changes.</a> <a href="https://cs.opensource.google/go/go/+/master:src/crypto/ecdh/nist.go;l=16-29;drc=d88d91e32e1440307369d50ba17ce622399a8bc1">A couple nifty uses of generics in there if you&apos;re curious.</a>)</p>
<p>The goal of the package is to replace the major use case for the <strong>now-deprecated</strong> <code>crypto/elliptic</code> API, which has a hardcoded dependency on the variable-time, large, and complex <code>math/big</code> package. <code>crypto/elliptic</code> is now no more than a compatibility wrapper. Any more advanced uses of <code>crypto/elliptic</code> can switch to <a href="https://filippo.io/nistec">filippo.io/nistec</a> which is an exported version of <code>crypto/internal/nistec</code>, or <a href="https://filippo.io/edwards25519">filippo.io/edwards25519</a> which is an exported version of <code>crypto/internal/edwards25519</code>.</p>
<p>What&apos;s left to do in Go 1.20 then?</p>
<p>First, actually landing the new package, <a href="https://go.dev/cl/398914">which is already submitted</a>! Then, adding and reviewing new tests (including <a href="https://go-review.googlesource.com/c/crypto/+/424274">Wycheproof integration</a> by Roland), which actually revealed there are <a href="https://go-review.googlesource.com/c/go/+/425463">fewer (!!) edge cases than I had originally documented</a>. Finally, reviewing <a href="https://go-review.googlesource.com/c/go/+/423363">the BoringCrypto integration by Russ</a>.</p>
<h2 id="mathbig-out-of-the-security-perimeter">math/big out of the security perimeter</h2>
<p>There is an even broader goal behind this work: moving <code>math/big</code> out of the security perimeter entirely, meaning making it unreachable from attacker-exposed cryptographic APIs and protocols.</p>
<p><code>math/big</code> is a general-purpose big integer library, it&apos;s not constant time, and it&apos;s full of complex code that while unnecessary for cryptography has <strong>repeatedly led to security vulnerabilities in crypto packages</strong>. While it was a convenient way to bootstrap the Go crypto standard library, <code>math/big</code> does not belong in crypto code in 2022.</p>
<p><code>crypto/ecdh</code> lets us deprecate <code>crypto/elliptic</code>, and lets us bypass <code>math/big</code> in <code>crypto/tls</code>&apos;s ECDHE implementation.</p>
<p>The next step is modifying <code>crypto/ecdsa</code> to use <code>crypto/internal/nistec</code> for the group operations on known curves, deprecate the use of custom curves, and replace the scalar field operations with... something. That something might be fiat-crypto field implementations for each scalar field (P-256&apos;s, P-384&apos;s, and P-521&apos;s) with the <a href="https://words.filippo.io/dispatches/wide-reduction/">wide reduction trick we talked about in Cryptography Dispatches</a>, or using a minimal bigint implementation shared with <code>crypto/rsa</code>.</p>
<p>Speaking of, <code>crypto/rsa</code> unavoidably needs a lightweight bigint implementation to replace its dependency on <code>math/big</code>. The good news is that we can make that one constant-time, simple, and tightly scoped for its purposes, which should make it much easier to maintain and keep secure. <a href="https://go-review.googlesource.com/c/go/+/326012">Lucas contributed one</a> that needs review, and Thomas Pornin offered a Go port of <a href="https://www.bearssl.org/bigint.html">BearSSL&apos;s one</a>. This will be a significant amount of assessment, review, and testing work, but it&apos;s the last real hurdle.</p>
<p>Finally, we need to worry about the places where <code>big.Int</code> is exposed in public APIs, mainly <code>crypto/rsa</code> and <code>crypto/ecdsa</code> key types. An idea is making the <code>(*Int).SetBytes</code>/<code>(*Int).FillBytes</code> round-trip constant-time so it can be used as just an annoying way to carry around the <code>[]byte</code> encoding of the key values. The problems with that are how to handle (or check in constant time) any manual modification to the <code>big.Int</code>, and how to store zero-padded values (which we can&apos;t unpad in constant time) without breaking the normalization invariant of <code>big.nat</code>. I welcome suggestions!</p>
<p>If we do go the route of keeping a select subset of <code>math/big</code> exposed, we&apos;ll want to lock it in to ensure we can keep it constant time and well reviewed. For that I have a <a href="https://go-review.googlesource.com/c/go/+/402554">WIP test that does static analysis to ensure only expected functions are reachable from crypto packages</a>.</p>
<h2 id="more-elliptic-curves">More elliptic curves</h2>
<p>Aside from the <code>math/big</code>-related efforts, there are a couple other Go 1.20 tasks that have to do with elliptic curves.</p>
<p>First, <a href="https://go-review.googlesource.com/c/go/+/420454">landing a rewrite of the edwards25519 scalar field</a> that replaces the last bits of unreadable ref10 code with fiat-crypto generated code. You can read more on <a href="https://words.filippo.io/dispatches/wide-reduction/">a previous Cryptography Dispatches issue</a>, and there&apos;s an overview of the overall edwards25519 rewrite in <a href="https://go-review.googlesource.com/c/go/+/276272">the CL that landed it after years out-of-tree</a>.</p>
<p>Second, finally <a href="https://go-review.googlesource.com/c/go/+/373076">landing support for Ed25519ph (the pre-hashed variant of Ed25519)</a> in <code>crypto/ed25519</code>.</p>
<h2 id="cryptotls">crypto/tls</h2>
<p>Finally, as a stretch goal in case elliptic curve work leaves some space for other things, I collected a couple batches of <code>crypto/tls</code> work. (I find it more efficient to work in topic-scoped batches, so I can load context on a protocol and codebase once and use it to land multiple changes.)</p>
<p>One batch revolves around session resumption: exposing a way to provide external PSKs in TLS 1.3 (which are the underlying mechanism of session tickets in TLS 1.3), maybe implementing PSK modes, implementing Session IDs, making sessions serializable/exportable.</p>
<p>Here&apos;s a list of related issues. (The one about forward secrecy by default was already mostly addressed by <a href="https://go-review.googlesource.com/q/%252325256">work we landed somewhat quietly with Katie in Go 1.15</a>, which I&apos;m hoping to write about for the Go blog, as it sets Go significantly apart from any other TLS stack I know about.)</p>
<ul>
<li><a href="https://github.com/golang/go/issues/31641">crypto/tls: TLS session resumption re-verifies the client&apos;s certificate chain</a></li>
<li><a href="https://github.com/golang/go/issues/25351">crypto/tls: make ClientSessionState serializable</a></li>
<li><a href="https://github.com/golang/go/issues/25228">proposal: crypto/tls: implement Session IDs resumption</a></li>
<li><a href="https://github.com/golang/go/issues/19199">proposal: crypto/tls: SessionTicketWrapper and Forward Secrecy by default</a></li>
<li><a href="https://github.com/golang/go/issues/6379">crypto/tls: add PSK support</a></li>
<li><a href="https://github.com/golang/go/issues/46718">proposal: crypto/tls: expose a session identifier</a></li>
</ul>
<p>The second batch is a miscellaneous list of crypto/tls work. If you have anything else TLS-related you care about, now is a good time to ping me on it.</p>
<ul>
<li><a href="https://github.com/golang/go/issues/20420">crypto/tls: customisable max TLS record size</a></li>
<li><a href="https://github.com/golang/go/issues/35504">crypto/tls: improve default performance of SupportsCertificate</a></li>
<li><a href="https://github.com/golang/go/issues/46308">crypto/tls: add VersionName function to return a string version of the TLS Version</a></li>
<li><a href="https://github.com/golang/go/issues/48152">crypto/tls: expose all presented certs in error type on handshake failure</a></li>
<li><a href="https://github.com/golang/go/issues/49126">crypto/tls: support ECDHE key exchanges when ec_point_formats is missing in ClientHello extension</a></li>
<li><a href="https://github.com/golang/go/issues/50773">crypto/tls: make maxHandshake larger or configurable</a></li>
<li><a href="https://github.com/golang/go/issues/51434">crypto/tls: run BoringSSL test suite (BoGo)</a></li>
<li><a href="https://github.com/golang/go/issues/43922">proposal: crypto/tls: implement RFC7627</a></li>
</ul>
<!--kg-card-end: markdown--><h2 id="the-picture">The picture</h2><p>DEF CON was a blast (we won a Black Badge with the Scavenger Hunt!) and systematically eating outdoors and wearing a P100 respirator spared me from COVID. Las Vegas is hell but pretty.</p><figure class="kg-card kg-image-card"><img src="https://words.filippo.io/content/images/2022/09/Newsletter---1--1--1.jpeg" class="kg-image" alt="A night-time picture of the Las Vegas skyline taken from a high floor. In the foreground a large road, mostly empty, and two blocks of low buildings and empty space with a couple billboards with bright lights. Mid-frame, a string of high-rise casinos covered in sparkly lights. In the background, pitch black sky." loading="lazy" width="2000" height="1096" srcset="https://words.filippo.io/content/images/size/w600/2022/09/Newsletter---1--1--1.jpeg 600w, https://words.filippo.io/content/images/size/w1000/2022/09/Newsletter---1--1--1.jpeg 1000w, https://words.filippo.io/content/images/size/w1600/2022/09/Newsletter---1--1--1.jpeg 1600w, https://words.filippo.io/content/images/size/w2400/2022/09/Newsletter---1--1--1.jpeg 2400w" sizes="(min-width: 720px) 720px"></figure><p>If you want to stay up to date with my Open Source work, consider <a href="https://twitter.com/FiloSottile">following me on Twitter</a> or <a href="https://filippo.io/newsletter">subscribing to this newsletter</a> if you haven&apos;t already! <strong>If your company depends on Go and its cryptography libraries</strong>, or any other of my Open Source projects, consider sponsoring my maintenance work. Reply to this email, introduce me to the right people, and I&apos;ll work with your accounting department to make it happen!</p>]]></content:encoded></item><item><title><![CDATA[A Wide Reduction Trick]]></title><description><![CDATA[We look into a neat trick that allowed replacing the last bit of unreadable edwards25519 code, and learn about the structure and lineage of ECC implementations.]]></description><link>https://words.filippo.io/dispatches/wide-reduction/</link><guid isPermaLink="false">62ebd9588e3610003db6533b</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Thu, 04 Aug 2022 14:52:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>In line with the original spirit of Cryptography Dispatches, this is a quick<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> issue to talk about a neat bit of cryptography engineering I encountered.</p>
<h2 id="the-structure-of-an-ecc-implementation">The structure of an ECC implementation</h2>
<p>Elliptic curve cryptography implementations all roughly share the following structure: there&apos;s a base field implementation, the group logic, a scalar field implementation, and a higher level protocol (key exchange, signatures, ...) over the group.</p>
<p>The base field is the set of numbers modulo a large prime number (such as 2^255-19, from which Curve25519 takes its name). The implementation provides arithmetic operations in the field, such as modular addition, subtraction, multiplication, and inversion, as well as encoding and decoding of field elements to/from bytes.</p>
<p>The group is the set of points on the elliptic curve. The implementation represents a point in some coordinate system where each coordinate is a base field element, and then applies a point addition formula which is defined in terms of base field operations.</p>
<p>The scalar field is, like the base field, the set of numbers modulo a large prime. However, this large prime is not selected by the designers, but is instead the <em>order of the group</em>. That is, the number of times you need to add a point to itself before you get back to that point.<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> In practice, the scalar field implementation is often very different from the base field implementation, for a few reasons:</p>
<ol>
<li>the performance of scalar field operations is less important to the high-level protocol performance than that of base field operations;</li>
<li>the prime modulus can&apos;t be selected to have a nice optimization-friendly shape, with cute reduction identities and such;</li>
<li>some high-level protocols only need a very restricted set of scalar field operations, or none at all (such as ECDH);</li>
<li>some other high-level protocols need scalar field operations that aren&apos;t relevant to the base field, such as a &quot;wide&quot; modular reduction from a value numerically much higher than the field order to a field element.</li>
</ol>
<p>In this issue we&apos;re going to talk about those wide modular reductions.</p>
<h2 id="fiat-crypto">fiat-crypto</h2>
<p>Field implementations are where some of the most subtle and terrifying bugs hide. Most bugs in group logic, protocol implementations, and the way these all interact can be reached with careful, extensive testing.</p>
<p>Carry bugs in field implementations can easily occur randomly for one in 2^64 inputs, only on some specific architecture, with no way to share test cases between implementations.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> Mentally reviewing the logic is <a href="https://go.googlesource.com/go/+/d95ca9138026cbe40e0857d76a81a16d03230871%5E%21/">awful</a>, and a tiny mistake is enough to <a href="https://i.blackhat.com/us-18/Wed-August-8/us-18-Valsorda-Squeezing-A-Key-Through-A-Carry-Bit-wp.pdf">exfiltrate keys</a>.</p>
<p>Enter <a href="https://github.com/mit-plv/fiat-crypto">fiat-crypto</a>. This un-Googleable project uses formal methods to prove the logic of field arithmetic operations correct, and generates code in a variety of languages to implement those operations. <a href="https://github.com/FiloSottile/edwards25519/blob/8c58ed0e35502a485538e4c5ec086070840f3410/scalar_fiat.go">The code is not the most readable</a> but the API is usable and the most common bugs are ruled out by the formal proof.</p>
<p>Between Go 1.17 and Go 1.19 I progressively replaced with it all NIST curves base field implementations in the Go standard library (except the most aggressively optimized assembly ones).</p>
<p>What about the scalar fields though?</p>
<h2 id="aside-the-christmas-tree">Aside: the Christmas tree</h2>
<p>Let&apos;s take a detour in cryptography engineering history.</p>
<p>Most cryptography implementations aren&apos;t written from scratch, and instead have somewhat of a lineage. The current Go edwards25519 implementation traces back to a port from C to Go by Adam Langley of the &quot;ref10&quot; public domain implementation by Daniel Bernstein, so called because it was distributed as the <code>crypto_sign/ed25519/ref10</code> subfolder of a benchmarking tarball called SUPERCOP.<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> It was then extracted for use in github.com/gtank/ristretto255 by George Tankersley, Henry de Valence, and me, merged with an old 2017 assembly optimization by George Tankersley, and finally exposed as filippo.io/edwards25519. One year ago, <a href="https://go-review.googlesource.com/c/go/+/276272">I re-upstreamed it, replacing the code in the standard library it started from</a>.</p>
<p>Over the years, all the base field and group logic from ref10 was replaced, but the scalar field implementation was still the same. In fact, most of the edwards25519 implementations I am aware of use that scalar implementation, consisting of two large functions: <code>sc_muladd</code> which computes <code>a * b + c</code> and <code>sc_reduce</code> which reduces a 512-bit value. This <a href="https://github.com/jedisct1/supercop/blob/fe36cc1446cb8b1d5c82881e9d03fce82bbde370/crypto_sign/ed25519/ref10/sc_muladd.c">giant uncommented blob of hardcoded integer constants</a> is so infamous that it&apos;s affectionately referred to as &quot;the Christmas tree&quot; amongst practitioners, due to the <a href="https://github.com/FiloSottile/edwards25519/blob/37b8fb5359e55196500b70f5148bd97fb03e5ecd/scalar.go#L234-L256">shape of the large addition round of multiplication terms</a>.</p>
<p>(Imagine a pen-and-paper columnar multiplication between two large numbers with the same digit count. The rightmost digit of the result is the sum of one product, the second rightmost of two, and so on until the middle one, and then back down until the leftmost is the sum of one product again, ignoring carries. That&apos;s what gives the Christmas tree its shape. There is also an explanation <a href="https://github.com/FiloSottile/edwards25519/blob/37b8fb5359e55196500b70f5148bd97fb03e5ecd/field/fe_generic.go#L47-L77">in our edwards25519 base field implementation</a>.)</p>
<p>Anyway, George Tankersley&apos;s branch for the PR that replaced <code>scMulAdd</code> with fiat-crypto was called <code>gtank/war-on-christmas</code>. That is all.</p>
<h2 id="wide-reduction">Wide reduction</h2>
<p>fiat-crypto provides only one decoding function, which requires the input to already be lower than the field order. This is mostly not a problem with base fields, where non-canonical &quot;overflowing&quot; values are rejected.<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> However, we often need to operate on and reduce scalar values higher than the scalar field order:</p>
<ul>
<li>the simplest constant-time way to select a random scalar, e.g. for EdDSA or hashing to the curve, is to take a random 512-bit value and reduce it modulo the scalar field order, making the bias negligibly small;</li>
<li>Ed25519 &quot;clamping&quot;&#x2014;which is actually useless in a signature scheme but for some reason got copied from RFC 7748 to RFC 8032&#x2014;sets the second most significant bit in a 32-byte string representing the scalar, making it by definition at least 2^254, while the scalar field order is a little over 2^252;</li>
<li>ECDSA takes a base field element and interprets it as a scalar field element because it&apos;s a horrible, <em>horrible</em> protocol, and the base field is a little larger than the scalar field.</li>
</ul>
<p>What do we do then if we have a value that might be as high as 2^512-1 and a field implementation that can only take inputs lower than the order (2^252 and change)?</p>
<p><em>My</em> answer was &quot;we find the lovely, helpful fiat-crypto authors at a cryptography workshop in Amsterdam and ask them to add a wide reduction function to fiat-crypto&quot; but it turns out that implementing that in the Montgomery backend (what you need for weirdly shaped primes like this) is not easy, especially if you need to reduce from above the square of the order, which we do.</p>
<p>Thankfully Frank Denis had a much, much better answer. The kind so simple (for a person who spends most of their time working on this stuff) that it clicks immediately and then you want to write a newsletter issue about.</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I represent the  value as a+b*2^192+c*2^384 <a href="https://t.co/O0dwPKbzAL">https://t.co/O0dwPKbzAL</a></p>&#x2014; Frank &#x26A1; (@jedisct1) <a href="https://twitter.com/jedisct1/status/1525228662492119040?ref_src=twsrc%5Etfw">May 13, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
<h2 id="the-trick">The trick</h2>
<p>Here&apos;s the idea: take a large number, such as 712376532, and imagine we need to operate over it with a calculator that can only count up to 1041, and then wraps around to 0. The good news is that we want all our results modulo 1042.</p>
<p>First, we notice we can write <code>712376532 mod 1042</code> as</p>
<pre><code>712376532 = 712 * 1000000 + 376 * 1000 + 532 mod 1042
</code></pre>
<p>&quot;But wait&quot;, you&apos;ll say, &quot;1000000 is more than 1042!&quot; Yes, but since we are operating modulo 1042 we can precompute its reduction, like this</p>
<pre><code>712376532 = 712 * 722 + 376 * 1000 + 532 mod 1042
</code></pre>
<p>These are now all numbers that we can put into our calculator!</p>
<p><a href="https://github.com/FiloSottile/edwards25519/commit/63e0935134d650f03ae6ff8e0da6760f18e5f5f8">We do the same thing to use fiat-crypto for the edwards25519 scalar field.</a> We cut the 64 bytes wide value up into three pieces, two of 21 bytes and one of 22 bytes; we decode each of them with fiat-crypto, since they are all guaranteed to be less than 2^176; we multiply the two most significant ones by 2^336 (for which we precomputed the reduction) and 2^168; and finally we add it all together.</p>
<pre><code>x = c * 2^336 + b * 2^168 + a  mod l
</code></pre>
<p>The result is the correct value of the 512-bit wide input modulo the field order, but we got there through two additions and two multiplications of values below the field order, which is what fiat-crypto provides us.</p>
<p>With this, the last piece of the ref10 scalar implementation is gone, resulting in an <a href="https://go-review.googlesource.com/c/go/+/420454">overall change</a>, ignoring autogenerated code, of 268 insertions(+), 893 deletions(-).</p>
<p>Any day we get to delete 900 lines of unreadable crypto code is a good day.</p>
<h2 id="the-picture">The picture</h2>
<p>An especially good day if you get to do it on the side of a beautiful lake.</p>
<p><img src="https://words.filippo.io/content/images/2022/08/IMG_7123-Large.jpeg" alt="A picture of the side of a lake at night. In the foreground, a cement bench seen from behind with a yellow backpack on it, next to a tree that frames the picture at the top. Beyond it, a small pier with wooden poles stretches into the pitch balck water. In the distance the lights of a town on the other side of the lake." loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Look, I swear it started quick. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>I&apos;m ignoring cofactors in this explanation. You don&apos;t need them today. The technically correct definition of the order of the scalar field is the order of the prime-order subgroup of the elliptic curve, so the number of times you need to add a point on the prime-order subgroup like the canonical generator to itself before you get back to the point. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn3" class="footnote-item"><p>However, you can make fuzzer mutators that leverage knowledge about the internals of the field implementation to much more efficiently generate inputs that are likely to tickle edge cases without knowing in advance what bugs you&apos;re looking for. There is such a fuzzer in filippo.io/edwards25519 and <a href="https://go.googlesource.com/go/+/d95ca9138026cbe40e0857d76a81a16d03230871%5E%21/">there was one in the stdlib P224</a> before I torched that whole implementation. I plan to write a retrospective analysis some day showing how many bugs it could have found in various implementations. <a href="#fnref3" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn4" class="footnote-item"><p>SUPERCOP implementations are distributed without READMEs or version control. We all use <a href="https://github.com/jedisct1/supercop">Frank Denis&apos;s unofficial repository</a> to track them and <a href="https://lobste.rs/s/ercmor/remote_code_execution_qmail_cve_2005_1513#c_3x7s7l">this whole arrangement has been problematic in the past</a>. Let&apos;s just say there are many reasons I am happy to replace the last vestiges of SUPERCOP code in crypto/ed25519. <a href="#fnref4" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn5" class="footnote-item"><p>This is actually also a problem for the Curve25519 base field, since RFC 7748 in its effort to make every 32-byte string a valid public key accepts the non-canonical values 2^255-19 through 2^255-1 as valid representations of 0 to 18. RFC 8032 rejects them, but in practice <a href="https://hdevalence.ca/blog/2020-10-04-its-25519am">Ed25519 implementations allow them</a>. A future Dispatches issue will talk about how we&apos;re testing these edge cases in Go, and how perfect backwards compatibility is critical to avoid forks in consensus applications. Such a small range can be handled with a conditional subtraction, which however needs to be implemented manually: subtract 2^255-19 and choose whether to keep the result or the input based on the final borrow value. This is not a problem in Go because we have a modern, well-tested, custom implementation of the Curve25519 base field. <a href="#fnref5" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[KEMs and Post-Quantum age]]></title><description><![CDATA[NIST selected a post-quantum cryptographic KEM. We look at how it works and how we can use it for file encryption with age.]]></description><link>https://words.filippo.io/dispatches/post-quantum-age/</link><guid isPermaLink="false">62c96956e7963a004da54b0b</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Fri, 29 Jul 2022 01:38:30 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>They&apos;re here! <a href="https://csrc.nist.gov/projects/post-quantum-cryptography/selected-algorithms-2022">NIST selected a first batch</a> of post-quantum cryptographic key exchange and signature algorithms. <a href="https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8413.pdf">The report</a> is a nice read that explains a lot of the goals, candidates, selections, and rationales. I recommend Sections 2, 3.3, and 4.1.</p>
<p>For key exchange, NIST selected only CRYSTALS-Kyber, a KEM with IND-CCA2 security based on structured lattices, <a href="https://cryptojedi.org/peter/data/inria-20170411.pdf">a successor of NewHope</a>, with 800 bytes keys and ciphertexts (although the authors <a href="https://pq-crystals.org/kyber/">recommend</a> using the category 3 parameters, with 1184 bytes public keys and 1088 bytes ciphertexts). Four other KEMs based on codes and isogenies are continuing to a fourth round that will select a key exchange fallback in case lattices turn out to be a bad idea.<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
<h2 id="kems">KEMs</h2>
<p>What&apos;s a KEM and what does it mean for it to have IND-CCA2 security? A Key Encapsulation Method is an implementation of the following API.</p>
<pre><code>KeyGen() -&gt; public key, secret key
Encapsulate(public key) -&gt; ciphertext, shared key
Decapsulate(secret key, ciphertext) -&gt; shared key
</code></pre>
<p>One way to implement a KEM that you might already be familiar with is with Elliptic Curve Diffie-Hellman. In ECDH, the ciphertext is more commonly called the peer or ephemeral share.</p>
<pre><code>KeyGen():
    secret key = random_scalar()
    public key = scalar_mult(secret key, generator)

Encapsulate(public key):
    ephemeral = random_scalar()
    ciphertext = scalar_mult(ephemeral, generator)
    s = scalar_mult(ephemeral, public key)
    shared key = KDF(s || public key || ciphertext)

Decapsulate(secret key, ciphertext):
    s = scalar_mult(secret key, ciphertext)
    shared key = KDF(s || public key || ciphertext)
</code></pre>
<p>One can also make a KEM from RSA. It&apos;s actually a much simpler, safer, and easier-to-prove way to do RSA encryption, compared with RSA-OAEP and especially with with RSA PKCS #1 v1.5 encryption. I regret using RSA-OAEP instead of RSA-KEM for <code>ssh-rsa</code> support in age.</p>
<pre><code>KeyGen():
    p, q = random_prime(), random_prime()
    public key = n = p * q
    e = 65537
    secret key = d = e&#x207B;&#xB9; mod &#x3BB;(n)

Encapsulate(n):
    m = random(2, n)
    ciphertext = m ^ e mod n
    shared key = KDF(m || n || ciphertext)

Decapsulate(d, ciphertext):
    m = ciphertext ^ d mod n
    shared key = KDF(m || n || ciphertext)
</code></pre>
<p>(In the wild, you&apos;ll find RSA-KEM with configurable public exponent <code>e</code> and without <code>n</code> and <code>c</code> hashed into the shared key. Good cryptographic engineering hygiene requires <a href="https://www.imperialviolet.org/2022/03/15/pickingparameters.html">fixing parameters</a>, and hashing transcripts. The former <a href="https://github.com/ytdl-org/youtube-dl/pull/8142">saved my homebrew youtube-dl update verification function</a>, and the latter makes the KEM <a href="https://eprint.iacr.org/2019/526">contributory</a>.)</p>
<p>So that&apos;s what a KEM is.<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> What about IND-CCA2 security? It means that it provides &quot;ciphertext indistinguishability against adaptive chosen ciphertext attacks&quot;. More concretely, it means you can reuse a public key instead of having to generate a new one for every decapsulation. The alternative is for it to be secure only against chosen plaintext attacks (CPA), where the attacker doesn&apos;t have access to a decryption oracle. In practice, that would require using each public key only once, restricting its use mostly to interactive protocols.</p>
<p>A CCA-secure KEM is a very versatile tool, that lets us do many (although not all) things we&apos;re used to doing in the pre-quantum world. The main difference from (EC)DH is that KEMs are asymmetric: you can&apos;t use the public key as a ciphertext and vice-versa.</p>
<p>Here&apos;s what can be done with a CCA-secure KEM:</p>
<ul>
<li>
<p>It can be combined with symmetric encryption in an offline KEM-DEM public key encryption scheme, like ECDHE turns into ECIES (which is what age&apos;s X25519 recipients implement): the sender does an encapsulation to the recipient&apos;s public key, uses the shared key to encrypt a message with a symmetric AEAD, and sends the KEM ciphertext and the encrypted message.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
</li>
<li>
<p>It can be used to build authenticated key exchanges by running the KEM three times (or two, to authenticate only one side) in parallel: once with an ephemeral  public key for forward secrecy, once with one peer&apos;s long term public key, and once with the other peer&apos;s long term public key. The three shared keys are hashed together, and using the resulting key authenticates the two peers.<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></p>
</li>
<li>
<p>It allows caching and reusing public keys in ephemeral key exchanges like ECDHE in TLS (which you might or might not want to do&#x2014;with ECDH we pretty much collectively gave up on it, because many many many implementation errors become unexploitable if the &quot;public key&quot; is used only once<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>).</p>
</li>
</ul>
<h2 id="kyber">Kyber</h2>
<p>Kyber is designed as a CPA-secure PKE core, turned into a CCA-secure KEM with a standard construction, but only the CCA-secure KEM is specified as an exposed primitive. This is cheap&#x2014;it just adds a handful of hash invocations<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup> and a PKE encapsulation to the KEM decapsulation step&#x2014;and a very good idea: we don&apos;t need two very similarly named primitives with very different security properties floating around, when we could just have the safer one everywhere. I hope implementations respect the spirit of the design and don&apos;t expose the CPA-secure PKE.</p>
<p>Another robustness detail I appreciate of Kyber is that it hashes the transcript (ciphertext and public key) into the key by design.<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup> When making a KEM out of ECDH, you need to feed shared secret, public key, and peer share/ciphertext into the KDF to get a contributory KEM. Kyber does that for you. While not required for CCA-security, contributory behavior <a href="https://eprint.iacr.org/2019/526">can prevent some neat real-world attacks</a> and should even allow using the public key as an authentication key.<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup> Enshrining this property into the design and test vectors is the right way to ensure implementations don&apos;t forget it when they need it.</p>
<h2 id="post-quantum-age">Post-quantum age</h2>
<p><a href="https://age-encryption.org">age</a> is a simple, modern, and secure file encryption format, tool, and library. Its native recipient type is based on X25519, but it supports custom recipient types through Go interfaces or an stdin/stdout plugin system. All a recipient needs to do is wrap and unwrap a file key given a recipient and identity string, respectively. Can we make a post-quantum age recipient based on Kyber?</p>
<h3 id="128-bits-are-enough">128 bits are enough</h3>
<p>The main concern is the size of the file key: 128 bits.<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup> My previous rough understanding of <a href="https://en.wikipedia.org/wiki/Grover%27s_algorithm">Grover&apos;s attack</a> was that it allowed searching an n-bit key space for a black box function in n/2 &quot;time&quot; on a quantum computer. This understanding is fairly popular: it&apos;s sort of a meme that you need to support AES-256 for &quot;post-quantum reasons&quot;. If that&apos;s right, then no matter what we use for the recipient implementation, age v1 can be attacked with a quantum computer by bruteforcing the file key (and checking it correctness against the header HMAC) in 2&#x2076;&#x2074; time, which sounds unacceptable.</p>
<p>That understanding is practically wrong.</p>
<p>The <a href="https://csrc.nist.gov/projects/post-quantum-cryptography/post-quantum-cryptography-standardization/evaluation-criteria/security-(evaluation-criteria)">NIST security evaluation criteria</a> for post-quantum cryptography define five security categories of increasing strength. Each proposed post-quantum scheme provides a set of parameters to match these categories, which you can think about like key sizes in classical cryptography. To meet category 1 requirements, attacking a set of parameters &quot;must require computational resources comparable to or greater than those required for key search on a block cipher with a 128-bit key (e.g. AES128)&quot;.</p>
<p>Not only is a 128-bit key not a deal-breaker, then, but it&apos;s the benchmark against which category 1 post-quantum parameters are measured against. How to reconcile this with our understanding of Grover? NIST explains:</p>
<blockquote>
<p>[...] NIST suggests an approach where quantum attacks are restricted to a fixed running time, or circuit depth. Call this parameter MAXDEPTH. This restriction is motivated by the difficulty of running extremely long serial computations. Plausible values for MAXDEPTH range from 2&#x2074;&#x2070; logical gates (the approximate number of gates that presently envisioned quantum computing architectures are expected to serially perform in a year) through 2&#x2076;&#x2074; logical gates (the approximate number of gates that current classical computing architectures can perform serially in a decade), to no more than 2&#x2079;&#x2076; logical gates (the approximate number of gates that atomic scale qubits with speed of light propagation times could perform in a millennium).</p>
<p>The complexity of quantum attacks can then be measured in terms of circuit size. These numbers can be compared to the resources required to break AES and SHA3. At the present time, NIST would give the following estimates for the classical and quantum gate counts for the optimal key recovery and collision attacks on AES and SHA3, respectively, where circuit depth is limited to MAXDEPTH:</p>
<p>AES-128: 2&#xB9;&#x2077;&#x2070; / MAXDEPTH quantum gates<br>
[...]</p>
<p>It is worth noting that the security categories based on these reference primitives provide substantially more quantum security than a na&#xEF;ve analysis might suggest. For example, categories 1, 3 and 5 are defined in terms of block ciphers, which can be broken using Grover&#x2019;s algorithm, with a quadratic quantum speedup. But Grover&#x2019;s algorithm requires a long-running serial computation, which is difficult to implement in practice. In a realistic attack, one has to run many smaller instances of the algorithm in parallel, which makes the quantum speedup less dramatic.</p>
</blockquote>
<p>The summary is that Grover requires an unrealistically long-running serial computation<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>, and <a href="https://arxiv.org/abs/quant-ph/9711070">can&apos;t be parallelized better than naively running multiple instances</a>. When taking into account a conservative maximum running time, such as 2&#x2076;&#x2074; gates, running Grover on a 128-bit key space would require a circuit size of 2&#xB9;&#x2070;&#x2076;.</p>
<p>Assuming that there aren&apos;t any better-than-Grover attacks against the age primitives&#x2014;HKDF-SHA-256 followed by HMAC-SHA-256 or ChaCha20Poly1305&#x2014;it&apos;s fully appropriate to match category 1 post-quantum KEMs with 128-bit symmetric keys, like in age.</p>
<blockquote class="twitter-tweet" data-dnt="true"><p lang="en" dir="ltr">Yes, it&apos;s fine to use Kyber512 like this. But I recommend defaulting to Kyber768 unless you have a hard performance constraint that forces you to use 512.</p>&#x2014; John Schanck (@susurrusus) <a href="https://twitter.com/susurrusus/status/1544698275718053890?ref_src=twsrc%5Etfw">July 6, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
<blockquote class="twitter-tweet" data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">Indeed If 128-bit brute force is the best way of attacking the protocol, then it meets Level 1 requirements; being equivalent to AES-128.<br>( Most L5 PQC constructions actually have exactly 256-bit secrets inside them -- for XOF seed expanders, KDFs etc. There&apos;s no margin. )</p>&#x2014; mjos\dwez (@mjos_crypto) <a href="https://twitter.com/mjos_crypto/status/1544699876545634307?ref_src=twsrc%5Etfw">July 6, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
<h3 id="the-age-kyber768x25519-plugin">The age Kyber768+X25519 plugin</h3>
<p>Having established that the overall age protocol can by definition meet NIST&apos;s category 1 post-quantum security requirements, we can start thinking about how a post-quantum age plugin would look like.</p>
<p>Kyber&apos;s category 1 parameters are Kyber512, but <a href="https://pq-crystals.org/kyber/index.shtml">the authors recommend using Kyber768</a> unless prohibitive due to performance reasons. Both are plenty fast, and both have large public keys (800 vs 1184 bytes), so let&apos;s pick the conservative option. As str4d&#x2014;<a href="https://github.com/str4d/rage">rage</a>&apos;s author&#x2014;points out, this would also let us decide later that we do instead want to increase the file key size, while letting users keep their keys with a matching comfortable margin.</p>
<p>Any deployment of experimental post-quantum cryptography should be hybrid: paired with classical cryptography such that even if lattice cryptography turns out to be a bad idea, the combined system will be at least as secure as the classical algorithm. For our plugin, we&apos;ll just combine the Kyber768 KEM with X25519.</p>
<p>Native X25519 recipients wrap the file key using ChaCha20Poly1305 with a key derived as <code>HKDF-SHA-256(ikm = shared secret, salt = ephemeral share || recipient, info = &quot;age-encryption.org/v1/X25519&quot;)</code>. We could just add the Kyber key to the input key material, but we can take the occasion to fix a small regret in the age design: the salt is supposed to be random or fixed for domain separation, while ephemeral share and recipient should have been part of the input key material. This is not a security issue, but it makes applying some proofs more convoluted.</p>
<p>The wrapping key for the Kyber768+X25519 plugin can then be <code>HKDF-SHA-256(ikm = shared secret || ephemeral share || recipient || kyber key, salt = &quot;age-encryption.org/Kyber768+X25519&quot;, info = nil)</code>.</p>
<p>There are a few open questions that relate to optional properties that are not part of the core age guarantees but some recipients provide:</p>
<ul>
<li>Do a decryption or encryption oracle leak information about the public key? As we talked about above,<sup class="footnote-ref"><a href="#fn8" id="fnref8:1">[8:1]</a></sup> the public key is hashed into the key (the KEM is contributory), so an attacker can&apos;t generate a valid ciphertext for an unknown public key. If the attacker also can&apos;t learn the public key from an oracle, it might be possible to build authentication semantics around this.</li>
<li>Are ciphertexts for the same public key efficiently linkable? X25519 and Scrypt ciphertexts are unlikable, so given two age files you can&apos;t tell if they are encrypted to the same recipient. Does the same hold for Kyber768+X25519? (This does not hold for the SSH recipients, which intentionally include a public key hash, so we don&apos;t ask for the passphrase for keys that wouldn&apos;t work.)</li>
<li>Is it possible to craft ciphertexts that are valid (and lead to known keys) under multiple public keys, enabling multi-key attacks <a href="https://github.com/FiloSottile/age/commit/2194f6962c8bb3bca8a55f313d5b9302596b593b">like against X25519 and ChaCha20Poly1305</a>? Although the impact of this is limited&#x2014;allows efficient searches of the accepted public keys of a decryption oracle&#x2014;it might be a good reason to use a robust AEAD instead of ChaCha20Poly1305.</li>
</ul>
<p>Finally, there&apos;s the elephant in the room: the UX issue of the large public keys.</p>
<p>One of the key strengths (pun not intended) of age is that it has small, copy-pastable recipients like age1ydzqkt4vfuumwgk5hxus22gakwpqk9knua62qnzcqw5nzta30d9q3va9x0. A Kyber768+X25519 recipient would be... quite a bit longer. I am not going to paste one here because I care about the delivery rate of this email, but it&apos;d be 1960 characters, more than 30 times longer than the X25519 one.</p>
<p>A suggestion I like was to have the plugin store keys with a <code>-learn</code> flag, and then allow using them with a short identifier, like a hash. Or, maybe we bring back the aliases file that was in the original <a href="https://age-encryption.org/design">age design document</a> but never made it to v1.0.0. Or, we just accept that Kyber768+X25519 recipients will be mostly used with <code>--recipients-file</code>. It is still shorter than an armored OpenPGP public key. I welcome opinions and ideas.</p>
<blockquote class="twitter-tweet" data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">Does age currently use any local state? You could do like a mapping from H(public key) -&gt; public key locally, then just require registering a public key once.<br><br>But maybe you have a better idea.</p>&#x2014; L&#xFA;c&#xE1;s Meier (@cronokirby) <a href="https://twitter.com/cronokirby/status/1544716869671784450?ref_src=twsrc%5Etfw">July 6, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
<p>One more bonus UX issue: how do we stop people from mixing Kyber768+X25519 and plain X25519 recipients, defeating the post-quantum security of the file? Ideally without a special case.</p>
<p>If you&apos;ve made it this far, you might enjoy <a href="#/portal/signup">subscribing to Cryptography Dispatches</a> or <a href="https://twitter.com/FiloSottile">following me on Twitter</a>.</p>
<h2 id="bonus-picture">Bonus picture</h2>
<p>I&apos;m <a href="https://words.filippo.io/dispatches/dsa/">back</a> on the lake for the Italian math team training (where the promising kids train and I mostly play board games)!</p>
<p><img src="https://words.filippo.io/content/images/2022/07/IMG_6905.jpg" alt="A picture of a lake taken from the shore. The sky is full of clouds colored orange from a recent storm. They reflect on the water, where a few boats sit anchored. Two wooden piers extend from the shore from right to left. In the distance mountains on the other side of the lake, and a small sliver of blue sky." loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>For signatures, NIST selected CRYSTALS-Dilithium, FALCON, and SPHINCS+. CRYSTALS-Dilithium is based on structured lattices and has 1312 bytes keys and 2420 bytes signatures (at category 2, see below). FALCON is also based on structured lattices, has significantly more complex implementation (requiring constant time floating point operations, which we collectively don&apos;t have experience with), but provides 897 bytes public keys and 666 bytes signatures (at category 1). SPHINCS+ is a stateless hash-based signature scheme, with compact 32 bytes public keys but very large signatures starting at 7856 bytes. CRYSTALS-Dilithium is the main recommendation, FALCON is there for when you don&apos;t have 2KiB for a signature (which, regrettably, probably means we&apos;ll have to use the complex option in X.509), and SPHINCS+ is the fallback in case lattices turn out to be a bad idea (or you don&apos;t care at all about signature size, like apparently firmware updates don&apos;t, since the signature is discarded after verifying it and it&apos;s only the public key taking up precious flash memory). This leaves a gap for non-lattice small signatures, for which NIST is planning to run a new Call for Proposal over the coming years. No other current candidates are being considered anymore. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>If this explanation of what a KEM is didn&apos;t work for you, I liked <a href="https://crypto.stackexchange.com/a/52395">this Stack Exchange answer</a> which maps out the relationship between KEMs, public key encryption, and key exchanges. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn3" class="footnote-item"><p>See Appendix A of <a href="https://eprint.iacr.org/2017/634.pdf">the Kyber paper</a> for a sketch of a KEM-DEM public key encryption scheme. <a href="#fnref3" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn4" class="footnote-item"><p>See Section 5 of <a href="https://eprint.iacr.org/2017/634.pdf">the original Kyber paper</a> for a fully worked out sketch of this key exchange protocol. <a href="#fnref4" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn5" class="footnote-item"><p>It&apos;s interesting to think about ECDH implementation vulnerabilities, such as <a href="https://i.blackhat.com/us-18/Wed-August-8/us-18-Valsorda-Squeezing-A-Key-Through-A-Carry-Bit-wp.pdf">our old attack against a carry bug in Go</a> and many others, as degrading security of the scheme from CCA to CPA. In that sense, making a CPA-secure ECDH implementing is actually not that hard. I can&apos;t think of any implementation vulnerabilities, including side channel attacks, that violated CPA security. This makes intuitive sense, since in a CPA/ephemeral scenario the attacker only gets one shot at extracting information about the key, which usually comes a few bits at a time. I wonder if this will be true of post-quantum KEMs, too. Maybe we should generally try to design protocols that only require CPA security even when a CCA-secure tool is available, as a mitigation for implementation issues. <a href="#fnref5" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn6" class="footnote-item"><p>Kyber is so fast that the hashes take almost &#xBE; of the Encaps and Decaps CPU cycles. Kyber also made some <a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/h4Is0_xuDaM">slightly bizarre hash choices</a>, using different SHA-3 variants for domain separation. This is a small thing that I hope will change in the final standard, as I&apos;m not a fan of using four different hash variants in one scheme, I&apos;d rather see SHAKE used everywhere and the fixed size SHA-3 variants forgotten, and domain separation is best understood in the context of a whole protocol, where prefixes (or HMAC keys, or context-aware hashes) are the standard. You run out even of SHA-3 variants, eventually. <a href="#fnref6" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn7" class="footnote-item"><p>See Section 4 of <a href="https://eprint.iacr.org/2017/634.pdf">the Kyber paper</a>, subheading &quot;Hashing pk into &#x2C6;K&quot;. <a href="#fnref7" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn8" class="footnote-item"><p>The idea being that without the public key it might be impossible for the attacker to forge a ciphertext for that public key that will decrypt to a known key, making the public key a valid authentication capability key. It&apos;s easy to show that knowledge of the public key is necessary to produce a ciphertext that decrypts to a known key, since the public key is hashed into the key; what&apos;s harder is showing that a CCA decryption oracle doesn&apos;t leak information about the public key. We&apos;ll return to this in the context of adding authentication to age. <a href="#fnref8" class="footnote-backref">&#x21A9;&#xFE0E;</a> <a href="#fnref8:1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn9" class="footnote-item"><p>Why 128 bits? Because the file key is wrapped in each recipient stanza, so adding 16 more bytes to the file key would add 16 bytes to the file size <em>per recipient</em>. Instead, we have a 128-bit per-file nonce to provide a comfortable margin against multi-user attacks, where a shared search space of only 128 bits would be too tight. <a href="#fnref9" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn10" class="footnote-item"><p>This nuance comes up in evaluating classical attacks, too, by the way. There was some commotion about attacks against static Diffie-Hellman oracles a few years ago, claiming it reduced the security of Privacy Pass over Curve25519 or ristretto255, but a <a href="https://mailarchive.ietf.org/arch/msg/cfrg/YDVS5Trpr6suig_VCFEOH6SOn8Q/">careful analysis</a> showed that to get a worrying improvement it required almost 2&#x2076;&#x2074; <em>sequential</em> oracle queries, which even at one query per nanosecond would take 400 years. For a parallelizable attack, 2&#x2076;&#x2074; is almost trivial, but as sequential operations where the input of the next requires the previous one, it&apos;s a prohibitive scale. <a href="#fnref10" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[How to pay professional maintainers]]></title><description><![CDATA[To successfully fund Open Source projects, companies should: pay the maintainers; pay them real money; pay for maintenance; and keep paying them.]]></description><link>https://words.filippo.io/pay-maintainers/</link><guid isPermaLink="false">6232079078cffd003d3fa629</guid><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Thu, 17 Mar 2022 11:07:51 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: html--><p style="font-style: italic; text-align:right;">I work on the Go team at Google, but this is my personal opinion as someone who built a career on Open Source <a href="https://github.com/FiloSottile/">both at and outside big companies</a>.</p><!--kg-card-end: html--><figure class="kg-card kg-image-card"><img src="https://words.filippo.io/content/images/2022/03/Untitled_Artwork.png" class="kg-image" alt="A sketch of an invoice from &quot;Maintainer LLC&quot; to &quot;Acme Co&quot;. Only line item is &quot;Keep doing what you&apos;re doing&quot; and the total is $75,000." loading="lazy" width="1542" height="875" srcset="https://words.filippo.io/content/images/size/w600/2022/03/Untitled_Artwork.png 600w, https://words.filippo.io/content/images/size/w1000/2022/03/Untitled_Artwork.png 1000w, https://words.filippo.io/content/images/2022/03/Untitled_Artwork.png 1542w" sizes="(min-width: 720px) 720px"></figure><p>In a previous essay, <a href="https://words.filippo.io/professional-maintainers/"><em>Professional maintainers: a wake-up call</em></a>, I argued that we need Open Source maintainers to professionalize into a role that&apos;s legible to the companies that are invested in their projects. For that to work, we also need companies to understand and pay professional maintainers.</p><p>While the previous piece addressed maintainers, this one is aimed at the companies that depend on Open Source projects and wish to get a solid contractual relationship with this critical part of their supply chain, improving its sustainability.</p><p>I believe that to successfully fund an Open Source project, a company needs to:</p><ul><li><strong>Pay the maintainers.</strong> Not people external to the project.</li><li><strong>Pay them real money.</strong> In the order of what they could make as senior engineers.</li><li><strong>Pay for maintenance.</strong> Not features, grants, governance, or support.</li><li><strong>Keep paying them.</strong> Assess performance at contract renewal time.</li></ul><h2 id="pay-the-maintainers">Pay the maintainers</h2><p>This might seem obvious, but if you already have employees and contractors you trust, the temptation to pay them to work on the project might be strong.</p><p>However, new contributors <em>increase the maintainer&apos;s workload</em> without improving their motivation or sustainability. I often read advice along the lines of &quot;if you want to help a project send PRs&quot; and I never understood it. Reviewing and iterating or pushing back on PRs is work! Often more than writing the code itself.</p><p>I know that some companies have policies against paying contractors to do what employees could do, but what you&apos;re paying the maintainer for is <em>being the maintainer of that specific project</em>. That&apos;s not something you can pay anyone else to be.</p><p>This also helps with not being perceived as taking over the project, which Open Source communities are quick to reject.</p><!--kg-card-begin: markdown--><h2 id="pay-them-real-money">Pay them real money</h2>
<p>Designing, building, managing, and growing an Open Source project demostrates all the skills required of a Senior Software Engineer. That means maintainers can access $150k&#x2013;300k++/year compensation packages.<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
<p>Many maintainers are not in Open Source for the money, and that&apos;s fine, but often life happens and as circumstances change they might not be able to afford to turn down a proper salary anymore.</p>
<p>If your goal is ensuring the ongoing maintenance of the project, you should target figures between 25% and 100% of a SWE compensation package, depending on how likely the project is to get multiple sources of funding. $1,000/month without benefits is a nice way to show appreciation, but won&apos;t achieve any other goals.</p>
<h2 id="pay-for-maintenance">Pay for maintenance</h2>
<p>This is the most important part, and getting this wrong sunk more than one attempt at funding the Open Source ecosystem.</p>
<p>Maintainers are worried that taking your money will take control away from them. They, and their communities, don&apos;t want you to impose control over technical decisions. You don&apos;t want that either! You want to pay them to keep doing what they are doing, or to dedicate more resources to it. After all, you&apos;re already using their project because they did a good job so far prioritizing and executing. Governance is a delicate and complex topic, and you want to leave it as orthogonal as possible to funding.</p>
<p>Maintainers are already busy people, so you also don&apos;t want them to spend half their time writing grant proposals detailing what they plan to do so you will fund them. Instead, <strong>fund them so that they can dedicate resources to the project, and trust them to direct those resources like you&apos;d trust a senior engineer to execute on a broadly scoped project</strong>.</p>
<p>Finally, the health of the project depends on issue triage, bug fixes, refactors, and design work more than on new features. In fact, new features increase the maintenance burden. Paying for new features makes for easy to define deliverables, but sets up the wrong long-term incentives.</p>
<h3 id="other-things-you-should-pay-for">Other things you should pay for</h3>
<p>That doesn&apos;t mean the contract should come with no strings attached. Half the point of paying maintainers is getting solid guarantees back. (The other half is making the ecosystem sustainable.)</p>
<p>Over time, you can require a set of processes and practices that bring the development of the projects you depend on up to the standard of the software you develop in house:</p>
<ul>
<li>security practices, like two-factor authentication and mandatory code review;</li>
<li>reliable timelines for reviewing and merging or rejecting contributions;</li>
<li>quality standards, including vetted and minimized dependency trees;</li>
<li>careful handling of security reports and actionable vulnerability metadata;</li>
<li>processes useful to downstream users, such as SLSA or release signing.</li>
</ul>
<p>Moreover, you can ask for recognition in the project&apos;s documentation or as part of the project&apos;s updates. A &quot;What&apos;s new in Foo 3.0&quot; post that makes it to the Hacker News front page with the text &quot;This work was funded by Acme Co.&quot; is an excellent recruiting lead generator.</p>
<p>Finally, once you have the contractual relationship, it&apos;s easy to extend it to add scoped work like specific extensions, support, or training. If you&apos;re suddenly faced with an emergency, having the contract and payment rails ready will make it easy to engage the maintainer for some extra help.</p>
<h2 id="keep-paying-them">Keep paying them</h2>
<p>For Open Source maintenance to be a sustainable profession, it needs to be a reliable source of income. You&apos;re not expected to provide the same long term commitment of a full-time employer, but structuring the payment as a one-off bonus is not going to be as effective as a renewable contract.</p>
<p>A way to get both marketing exposure and the information to decide on contract renewal is to request an end-of-year article detailing the work that was performed thanks to the funding.</p>
<p>This might feel uncomfortable if you&apos;re used to contracts with precise deliverables defined in advance, but it is similar to how performance is evaluated for senior full-time employees: after the fact, as a way to decide whether to continue the engagement.</p>
<p>It&apos;s time to make Open Source maintainer a sustainable profession at the foundation of the software supply chain.</p>
<p>If you&apos;re a company that tried or wants to try to fund Open Source projects, reach out at <code>hi</code> at <code>filippo.io</code>. I&apos;m interested in hearing your experience, and maybe in helping make this kind of transactions an everyday reality.</p>
<p>If you want to follow along, you might want to <a href="https://twitter.com/FiloSottile">follow me on Twitter</a>.</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>I used the 90th percentile of all SWE salaries in Berlin, London, and New York from levels.fyi to back up this number, but really what I&apos;m seeing from large companies as well as startups is north of $500k/year in the US market, and more and more companies offer remote positions with uniform compensation. Surprisingly, I always get pushback from upset engineers when I mention this. Anyway, this post is for companies, and companies know how much they pay engineers, hopefully. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><blockquote class="twitter-tweet" data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">To successfully fund Open Source projects, companies should: pay the maintainers; pay them real money; pay for maintenance; and keep paying them.<br><br>A follow-up to my piece last year about how maintainers should make themselves legible to companies.<a href="https://t.co/nsVOGFU3C5">https://t.co/nsVOGFU3C5</a></p>&#x2014; Filippo ${jndi:ldap://filippo.io/t} Valsorda (@FiloSottile) <a href="https://twitter.com/FiloSottile/status/1504415979778019331?ref_src=twsrc%5Etfw">March 17, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> <!--kg-card-end: html-->]]></content:encoded></item><item><title><![CDATA[Professional maintainers: a wake-up call]]></title><description><![CDATA[Open Source software runs the Internet, and by extension the economy. This is an undisputed fact about reality in 2021. And yet, the role of Open Source maintainer has failed to mature from a hobby into a proper profession.]]></description><link>https://words.filippo.io/professional-maintainers/</link><guid isPermaLink="false">61b4b86d236f3a003b4e0ede</guid><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Sat, 11 Dec 2021 18:58:03 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: html--><p style="font-style: italic; text-align:right;">I work on the Go team at Google, but this is my personal opinion as someone who built a career on Open Source <a href="https://github.com/FiloSottile/">both at and outside big companies</a>.</p><!--kg-card-end: html--><figure class="kg-card kg-image-card"><img src="https://words.filippo.io/content/images/2021/12/sponsors.png" class="kg-image" alt="The popular xkcd 2347: Dependency, with a screenshot saying &quot;3 sponsors are funding rgoers&apos;s work&quot; at the top of the arrow pointing to the little piece holding the whole stack in place." loading="lazy" width="770" height="978" srcset="https://words.filippo.io/content/images/size/w600/2021/12/sponsors.png 600w, https://words.filippo.io/content/images/2021/12/sponsors.png 770w" sizes="(min-width: 720px) 720px"></figure><p>Open Source software runs the Internet, and by extension the economy. This is an undisputed fact about reality in 2021. And yet, the role of Open Source maintainer has failed to mature from a hobby into a proper profession.</p><p>The catastrophic consequences are almost a daily occurrence. Less than a couple months ago, the United States Cybersecurity &amp; Infrastructure Security Agency <a href="https://www.cisa.gov/uscert/ncas/current-activity/2021/10/22/malware-discovered-popular-npm-package-ua-parser-js">issued an alert</a> about the hijacking of a popular NPM package named <code>ua-parser-js</code>. That project has 6.5k stars on GitHub and has <a href="https://opencollective.com/ua-parser-js">raised a total of $41.61 on OpenCollective</a>. Earlier this week, <a href="https://www.wired.com/story/log4j-flaw-hacking-internet/">a severe RCE in a logging library called Log4j2</a> got everyone, from Apple to Minecraft. As of yesterday, the maintainer who patched the vulnerability <a href="https://twitter.com/FiloSottile/status/1469441487175880711">had three sponsors on GitHub</a>: Michael, Glenn, and Matt. I could go on and on and on. We&apos;ve all seen <a href="https://xkcd.com/2347/">the xkcd</a>.</p><h2 id="the-status-quo-is-unsustainable">The status quo is unsustainable</h2><p>Most maintainers fall in one of two categories: volunteers or big company employees. Sometimes both. Neither model is healthy.</p><p>Volunteers are doing their best in their spare time out of passion, or because they are (or were) having fun. They feel tremendous responsibility, but ultimately can&apos;t be expected to persevere in the face of burnout, a change in life circumstances (like, having a kid or changing jobs), or even shifting priorities. They also can&apos;t be expected to provide professional levels of performance because, again, <em>no one is paying them</em> and they are well within their rights to do only the fun parts of the &quot;job&quot;.<em> </em>Professionals are expensive for a reason.</p><p>GitHub Sponsors and Patreon are a nice way to show gratitude, but they are an extremely unserious compensation structure. The average maintainer of a successful project would qualify as a Senior Software Engineer, and those can easily make $150k&#x2013;300k+/year. (90th percentile of SWE salaries, all levels: <a href="https://www.levels.fyi/Salaries/Software-Engineer/New-York-City/">$355k in NYC</a>, <a href="https://www.levels.fyi/Salaries/Software-Engineer/London/">$232k in London</a>, <a href="https://www.levels.fyi/Salaries/Software-Engineer/Berlin-Germany/">$163k in Berlin</a>. Note that these are low-balls if you negotiate, especially in 2021/2022, and remote positions exist. <a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/">Read some Patrick McKenzie.</a>) When is the last time you&apos;ve seen a GitHub Sponsors recipient making more than $1,000/month? That&apos;s <em>at least</em> 12 times less than the alternative.</p><p>Even more importantly, there isn&apos;t a career path. You can&apos;t start as a junior maintainer, get training and experience, and expect to eventually grow into a better paid senior maintainer. That&apos;s not how any of it works today.</p><p>Being employed as a full-time maintainer by a big company pays better but is not much healthier, both organizationally and individually. Executives and promotion committees start asking &quot;what is it that we pay you for exactly?&quot;, and suddenly you&apos;re spending more and more time proving your work is important, and less and less time doing it. The workload increases as the project grows, but the team struggles to get more resources, no one gets promoted, and people burn out and leave or change roles. I&apos;ve seen this play out across multiple companies and ecosystems, over and over.</p><h2 id="professionalizing-the-role-of-maintainer">Professionalizing the role of maintainer</h2><p>&quot;Alright, Filippo,&quot; you&apos;ll say, &quot;we know everything&apos;s broken. Isn&apos;t it just an unavoidable tragedy of the commons? Is this just a long rant?&quot; It doesn&apos;t have to be. I have hope change is possible because <strong>companies are not getting what they want, and they are starting to notice</strong>.</p><p>Open Source sustainability and &#x2728; supply chain security &#x2728; are on everyone&apos;s slide decks, blogs, and press releases. Big companies <em>desperately need</em> the Open Source ecosystem to professionalize.</p><p>Here are a few examples of what they might want out of Open Source projects:</p><ul><li>security practices, like two-factor authentication and mandatory code review;</li><li>updates to keep up with the evolution of the ecosystem (adopting new versions of dependencies, porting to Python 3...);</li><li>reliable timelines for reviewing and merging <em>or rejecting</em> contributions;</li><li>support and troubleshooting for filed issues and bug reports;</li><li>quality standards, including vetted and minimized dependency trees;</li><li>careful handling of security reports and actionable vulnerability metadata;</li><li>adoption of standards useful to downstream users, such as SLSA;</li><li>even a succession plan to ensure the project won&apos;t go unmaintained if a key developer steps down.</li></ul><p>Can they demand any of it without paying the maintainers? Definitely not. </p><p>However, <strong>companies are in the business of getting what they need&#x2014;by paying invoices</strong>. The moment a company has a contractual relationship with a maintainer <em>for a significant sum of money</em> (1x to 0.3x of a market salary, depending on how likely the maintainer is to invoice other companies, too) it can request what it needs as a contractual condition. In turn, maintainers will be free to sustainably focus on the project like professionals, and prioritize the long-term health of the project, as well as deliver on the company requirements. (Or not, if they turn down the contract! I&apos;m very specifically not talking about transferring governance.)</p><p>But! Maintainers need to be <em>legible</em> to the big company department that approves and processes those invoices. Think about it: no company pays their law firm on Patreon. You&apos;d be amazed how much harder it is to explain &quot;what the fuck is an open collective?&quot; for a $10k donation, compared to paying a $100k invoice to an LLC that filed a W-9 or W-8BEN and takes payment through ACH. The trick is that you can easily incorporate a pass-through US LLC and open a business account for it even if you&apos;re not a US citizen, it&apos;s not rocket science. I am not an accountant (and oh god I am not <em>your</em> accountant) but I did it in an afternoon.</p><p>This is what I hope to see happen more and more: Open Source maintainers graduating to sophisticated counterparties who send invoices for &quot;support and sponsorship&quot; on letterhead, and big companies developing procedures to assess, approve, and pay them as a matter of routine so that they can get what they need from the ecosystem. Eventually, a whole career path with an onramp for junior maintainers, including training, like a real profession.</p><p>Now is the perfect time for Open Source maintainers to become legible to the big companies that depend on them&#x2014;and that want to get more out of them&#x2014;<em>and send them five-to-six figure invoices</em>. Big companies can either lead, or play catch up.</p><p>Personally, I find this idea more and more exciting and inevitable, and I am planning my future career directions around it. If you want to follow along, you can <a href="https://twitter.com/FiloSottile">follow me on Twitter</a>. If you&apos;re interested in being part of it, email me at hi@ this domain, and let&apos;s talk.</p><p><em>P.S. For the other side of the transaction, read the March 2022 follow-up &quot;<a href="https://words.filippo.io/pay-maintainers">How to pay professional maintainers</a>&quot; addressing companies.</em></p><figure class="kg-card kg-embed-card"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">We all agree the status quo is unsustainable.<br><br>Here are 1,000 words on how we could get the role of Open Source maintainer to graduate to a real, properly paid profession.<br><br>The thing is, companies need it as much as maintainers do.<a href="https://t.co/RK26lKGg3h">https://t.co/RK26lKGg3h</a></p>&#x2014; Filippo ${jndi:ldap://filippo.io/t} Valsorda (@FiloSottile) <a href="https://twitter.com/FiloSottile/status/1469749412998041610?ref_src=twsrc%5Etfw">December 11, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure>]]></content:encoded></item><item><title><![CDATA[Automatic Cipher Suite Ordering in crypto/tls]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p><em>This is the first article I wrote <a href="https://go.dev/blog/tls-cipher-suites">for the Go blog</a> (!!) about how TLS cipher suites configuration got so complicated, and how we&apos;ve made it way easier in Go 1.17.</em></p>
<p>The Go standard library provides <code>crypto/tls</code>,
a robust implementation of Transport Layer Security (TLS),
the most</p>]]></description><link>https://words.filippo.io/dispatches/cipher-suite-ordering/</link><guid isPermaLink="false">61e9aafa35f8a7003b975b7a</guid><category><![CDATA[dispatches]]></category><category><![CDATA[Elsewhere]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Wed, 15 Sep 2021 22:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p><em>This is the first article I wrote <a href="https://go.dev/blog/tls-cipher-suites">for the Go blog</a> (!!) about how TLS cipher suites configuration got so complicated, and how we&apos;ve made it way easier in Go 1.17.</em></p>
<p>The Go standard library provides <code>crypto/tls</code>,
a robust implementation of Transport Layer Security (TLS),
the most important security protocol on the Internet,
and the fundamental component of HTTPS.
In Go 1.17 we made its configuration easier, more secure,
and more efficient by automating the priority order of cipher suites.</p>
<h2 id="how-cipher-suites-work">How cipher suites work</h2>
<p>Cipher suites date back to TLS&#x2019;s predecessor Secure Socket Layer (SSL),
which <a href="https://datatracker.ietf.org/doc/html/draft-hickman-netscape-ssl-00#appendix-C.4" rel="noreferrer" target="_blank">called them &#x201C;cipher kinds&#x201D;</a>.
They are the intimidating-looking identifiers like
<code>TLS_RSA_WITH_AES_256_CBC_SHA</code> and
<code>TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256</code>
that spell out the algorithms used to exchange keys,
authenticate certificates, and encrypt records in a TLS connection.</p>
<p>Cipher suites are <em>negotiated</em> during the TLS handshake:
the client sends the list of cipher suites it supports in its first message,
the Client Hello, and the server picks one from that list,
communicating its choice to the client.
The client sends the list of supported cipher suites in its own preference order,
and the server is free to pick from it however it wants.
Most commonly, the server will pick the first mutually supported cipher
suite either in client preference order or in server preference order,
based on its configuration.</p>
<p>Cipher suites are really only one of many negotiated parameters&#x2014;supported
curves/groups and signature algorithms are additionally negotiated through
their own extensions&#x2014;but are the most complex and famous ones,
and the only ones that developers and administrators were trained over the
years to have opinions on.</p>
<p>In TLS 1.0&#x2013;1.2, all these parameters interact in a complex web of inter-dependencies:
for example supported certificates depend on supported signature algorithms,
supported curves, and supported cipher suites.
In TLS 1.3 this was all drastically simplified:
cipher suites only specify symmetric encryption algorithms,
while supported curves/groups govern the key exchange and supported signature
algorithms apply to the certificate.</p>
<h2 id="a-complex-choice-abdicated-to-developers">A complex choice abdicated to developers</h2>
<p>Most HTTPS and TLS servers delegate the choice of cipher suites and preference
order to the server operator or the applications developer.
This is a complex choice that requires up-to-date and specialized knowledge for many reasons.</p>
<p>Some older cipher suites have insecure components,
some require extremely careful and complex implementations to be secure,
and some are only secure if the client applies certain mitigations or even
has certain hardware.
Beyond the security of the individual components,
different ciphersuites can provide drastically different security properties
for the whole connection,
as cipher suites without ECDHE or DHE don&#x2019;t provide forward secrecy&#x2014;the
property that connections can&#x2019;t be retroactively or passively decrypted
with the certificate&#x2019;s key.
Finally, the choice of supported cipher suites impacts compatibility and performance,
and making changes without an up-to-date understanding of the ecosystem
can lead to breaking connections from legacy clients,
increasing the resources consumed by the server,
or draining the batteries of mobile clients.</p>
<p>This choice is so arcane and delicate that there are dedicated tools to guide operators,
such as the excellent <a href="https://ssl-config.mozilla.org/" rel="noreferrer" target="_blank">Mozilla SSL Configuration Generator</a>.</p>
<p>How did we get here and why is it like this?</p>
<p>To start, individual cryptographic components used to break much more often.
In 2011, when the BEAST attack broke CBC cipher suites in such a way that
only clients could mitigate the attack,
servers moved to preferring RC4, which was unaffected.
In 2013, when it became clear that RC4 was broken,
servers went back to CBC.
When Lucky Thirteen made it clear it was extremely hard to implement CBC
cipher suites due to their backwards MAC-then-encrypt design&#x2026;
Well, there wasn&#x2019;t anything else on the table so implementations had to
<a href="https://www.imperialviolet.org/2013/02/04/luckythirteen.html" rel="noreferrer" target="_blank">carefully jump through hoops</a>
to implement CBC and kept <a href="https://blog.cloudflare.com/yet-another-padding-oracle-in-openssl-cbc-ciphersuites/" rel="noreferrer" target="_blank">failing at that daunting task for years</a>.
Configurable cipher suites and <a href="https://www.imperialviolet.org/2016/05/16/agility.html" rel="noreferrer" target="_blank">cryptographic agility</a>
used to provide some reassurance that when a component broke it could be
replaced on the fly.</p>
<p>Modern cryptography is significantly different.
Protocols can still break from time to time,
but it&#x2019;s rarely an individual abstracted component that fails.
<em>None of the AEAD-based ciphersuites introduced starting with TLS 1.2 in
2008 have been broken.</em> These days cryptographic agility is a liability:
it introduces complexity that can lead to weaknesses or downgrades,
and it is only necessary for performance and compliance reasons.</p>
<p>Patching used to be different, too. Today we acknowledge that promptly applying
software patches for disclosed vulnerabilities is the cornerstone of secure
software deployments,
but ten years ago it was not standard practice.
Changing configuration was seen as a much more rapid option to respond to
vulnerable cipher suites,
so the operator, through configuration, was put fully in charge of them.
We now have the opposite problem: there are fully patched and updated servers
that still behave weirdly,
suboptimally, or insecurely, because their configurations haven&#x2019;t been touched in years.</p>
<p>Finally, it was understood that servers tended to update more slowly than clients,
and therefore were less reliable judges of the best choice of cipher suite.
However, it&#x2019;s servers who have the last word on cipher suite selection,
so the default became to make servers defer to the client preference order,
instead of having strong opinions.
This is still partially true: browsers managed to make automatic updates
happen and are much more up-to-date than the average server.
On the other hand, a number of legacy devices are now out of support and
are stuck on old TLS client configurations,
which often makes an up-to-date server better equipped to choose than some of its clients.</p>
<p>Regardless of how we got here, it&#x2019;s a failure of cryptography engineering
to require application developers and server operators to become experts
in the nuances of cipher suite selection,
and to stay up-to-date on the latest developments to keep their configs up-to-date.
If they are deploying our security patches,
that should be enough.</p>
<p>The Mozilla SSL Configuration Generator is great, and it should not exist.</p>
<p>Is this getting any better?</p>
<p>There is good news and bad news for how things are trending in the past few years.
The bad news is that ordering is getting even more nuanced,
because there are sets of cipher suites that have equivalent security properties.
The best choice within such a set depends on the available hardware and
is hard to express in a config file.
In other systems, what started as a simple list of cipher suites now depends
on <a href="https://boringssl.googlesource.com/boringssl/+/c3b373bf4f4b2e2fba2578d1d5b5fe04e410f7cb/include/openssl/ssl.h#1457" rel="noreferrer" target="_blank">more complex syntax</a>
or additional flags like <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_CTX_clear_options.html#:~:text=session-,ssl_op_prioritize_chacha,-When" rel="noreferrer" target="_blank">SSL_OP_PRIORITIZE_CHACHA</a>.</p>
<p>The good news is that TLS 1.3 drastically simplified cipher suites,
and it uses a disjoint set from TLS 1.0&#x2013;1.2.
All TLS 1.3 cipher suites are secure, so application developers and server
operators shouldn&#x2019;t have to worry about them at all.
Indeed, some TLS libraries like BoringSSL and Go&#x2019;s <code>crypto/tls</code> don&#x2019;t
allow configuring them at all.</p>
<h2 id="gos-cryptotls-and-cipher-suites">Go&#x2019;s crypto/tls and cipher suites</h2>
<p>Go does allow configuring cipher suites in TLS 1.0&#x2013;1.2.
Applications have always been able to set the enabled cipher suites and
preference order with <a href="https://pkg.go.dev/crypto/tls#Config.CipherSuites" rel="noreferrer" target="_blank"><code>Config.CipherSuites</code></a>.
Servers prioritize the client&#x2019;s preference order by default,
unless <a href="https://pkg.go.dev/crypto/tls#Config.PreferServerCipherSuites" rel="noreferrer" target="_blank"><code>Config.PreferServerCipherSuites</code></a> is set.</p>
<p>When we implemented TLS 1.3 in Go 1.12, <a href="https://go.dev/issue/29349">we didn&#x2019;t make TLS 1.3 cipher suites configurable</a>,
because they are a disjoint set from the TLS 1.0&#x2013;1.2 ones and most importantly
they are all secure,
so there is no need to delegate a choice to the application.
<code>Config.PreferServerCipherSuites</code> still controls which side&#x2019;s preference order is used,
and the local side&#x2019;s preferences depend on the available hardware.</p>
<p>In Go 1.14 we <a href="https://pkg.go.dev/crypto/tls#CipherSuites" rel="noreferrer" target="_blank">exposed supported cipher suites</a>,
but explicitly chose to return them in a neutral order (sorted by their ID),
so that we wouldn&#x2019;t end up tied to representing our priority logic in
terms of a static sort order.</p>
<p>In Go 1.16, we started actively <a href="https://go.dev/cl/262857">preferring ChaCha20Poly1305 cipher suites over AES-GCM on the server</a>
when we detect that either the client or the server lacks hardware support for AES-GCM.
This is because AES-GCM is hard to implement efficiently and securely without
dedicated hardware support (such as the AES-NI and CLMUL instruction sets).</p>
<p><strong>Go 1.17, recently released, takes over cipher suite preference ordering for all Go users.</strong>
While <code>Config.CipherSuites</code> still controls which TLS 1.0&#x2013;1.2 cipher suites are enabled,
it is not used for ordering, and <code>Config.PreferServerCipherSuites</code> is now ignored.
Instead, <code>crypto/tls</code> <a href="https://go.dev/cl/314609">makes all ordering decisions</a>,
based on the available cipher suites, the local hardware,
and the inferred remote hardware capabilities.</p>
<p>The <a href="https://cs.opensource.google/go/go/+/9d0819b27ca248f9949e7cf6bf7cb9fe7cf574e8:src/crypto/tls/cipher_suites.go;l=206-270" rel="noreferrer" target="_blank">current TLS 1.0&#x2013;1.2 ordering logic</a>
follows the following rules:</p>
<ol>
<li>
<p>ECDHE is preferred over the static RSA key exchange.</p>
<p>The most important property of a cipher suite is enabling forward secrecy.
We don&#x2019;t implement &#x201C;classic&#x201D; finite-field Diffie-Hellman,
because it&#x2019;s complex, slower, weaker, and <a href="https://datatracker.ietf.org/doc/draft-bartle-tls-deprecate-ffdh/" rel="noreferrer" target="_blank">subtly broken</a> in TLS 1.0&#x2013;1.2,
so that means prioritizing the Elliptic Curve Diffie-Hellman key exchange
over the legacy static RSA key exchange.
(The latter simply encrypts the connection&#x2019;s secret using the certificate&#x2019;s
public key, making it possible to decrypt if the certificate is compromised
in the future.)</p>
</li>
<li>
<p>AEAD modes are preferred over CBC for encryption.</p>
<p>Even if we do implement partial countermeasures for Lucky13
(<a href="https://go.dev/cl/18130">my first contribution to the Go standard library, back in 2015!</a>),
the CBC suites are <a href="https://blog.cloudflare.com/yet-another-padding-oracle-in-openssl-cbc-ciphersuites/" rel="noreferrer" target="_blank">a nightmare to get right</a>,
so all other more important things being equal,
we pick AES-GCM and ChaCha20Poly1305 instead.</p>
</li>
<li>
<p>3DES, CBC-SHA256, and RC4 are only used if nothing else is available, in that preference order.</p>
<p>3DES has 64-bit blocks, which makes it fundamentally vulnerable to
<a href="https://sweet32.info" rel="noreferrer" target="_blank">birthday attacks</a> given enough traffic.
3DES is listed under <a href="https://pkg.go.dev/crypto/tls#InsecureCipherSuites" rel="noreferrer" target="_blank"><code>InsecureCipherSuites</code></a>,
but it&#x2019;s enabled by default for compatibility.
(An additional benefit of controlling preference orders is that
we can afford to keep less secure cipher suites enabled by default
without worrying about applications or clients selecting them
except as a last resort.
This is safe because there are no downgrade attacks that rely on
the availability of a weaker cipher suite to attack peers
that support better alternatives.)</p>
<p>The CBC cipher suites are vulnerable to Lucky13-style side channel attacks
and we only partially implement the <a href="https://www.imperialviolet.org/2013/02/04/luckythirteen.html" rel="noreferrer" target="_blank">complex</a>
countermeasures discussed above for the SHA-1 hash, not for SHA-256.
CBC-SHA1 suites have compatibility value, justifying the extra complexity,
while the CBC-SHA256 ones don&#x2019;t, so they are disabled by default.</p>
<p>RC4 has <a href="https://www.rc4nomore.com" rel="noreferrer" target="_blank">practically exploitable biases</a>
that can lead to plaintext recovery without side channels.
It doesn&#x2019;t get any worse than this, so RC4 is disabled by default.</p>
</li>
<li>
<p>ChaCha20Poly1305 is preferred over AES-GCM for encryption,
unless both sides have hardware support for the latter.</p>
<p>As we discussed above, AES-GCM is hard to implement efficiently and
securely without hardware support.
If we detect that there isn&#x2019;t local hardware support or (on the server)
that the client has not prioritized AES-GCM,
we pick ChaCha20Poly1305 instead.</p>
</li>
<li>
<p>AES-128 is preferred over AES-256 for encryption.</p>
<p>AES-256 has a larger key than AES-128, which is usually good,
but it also performs more rounds of the core encryption function,
making it slower.
(The extra rounds in AES-256 are independent of the key size change;
they are an attempt to provide a wider margin against cryptanalysis.)
The larger key is only useful in multi-user and post-quantum settings,
which are not relevant to TLS, which generates sufficiently random IVs
and has no post-quantum key exchange support.
Since the larger key doesn&#x2019;t have any benefit,
we prefer AES-128 for its speed.</p>
</li>
</ol>
<p><a href="https://cs.opensource.google/go/go/+/9d0819b27ca248f9949e7cf6bf7cb9fe7cf574e8:src/crypto/tls/cipher_suites.go;l=342-355" rel="noreferrer" target="_blank">TLS 1.3&#x2019;s ordering logic</a>
needs only the last two rules,
because TLS 1.3 eliminated the problematic algorithms the first three rules
are guarding against.</p>
<h2 id="faqs">FAQs</h2>
<p><em>What if a cipher suite turns out to be broken?</em> Just like any other vulnerability,
it will be fixed in a security release for all supported Go versions.
All applications need to be prepared to apply security fixes to operate securely.
Historically, broken cipher suites are increasingly rare.</p>
<p><em>Why leave enabled TLS 1.0&#x2013;1.2 cipher suites configurable?</em> There is a
meaningful tradeoff between <em>baseline</em> security and legacy compatibility
to make in choosing which cipher suites to enable,
and that&#x2019;s a choice we can&#x2019;t make ourselves without either cutting out
an unacceptable slice of the ecosystem,
or reducing the security guarantees of modern users.</p>
<p><em>Why not make TLS 1.3 cipher suites configurable?</em> Conversely,
there is no tradeoff to make with TLS 1.3,
as all its cipher suites provide strong security.
This lets us leave them all enabled and pick the fastest based on the specifics
of the connection without requiring the developer&#x2019;s involvement.</p>
<h2 id="key-takeaways">Key takeaways</h2>
<p>Starting in Go 1.17, <code>crypto/tls</code> is taking over the order in which available
cipher suites are selected.
With a regularly updated Go version, this is safer than letting potentially
outdated clients pick the order,
lets us optimize performance, and it lifts significant complexity from Go developers.</p>
<p>This is consistent with our general philosophy of making cryptographic decisions whenever we can,
instead of delegating them to developers,
and with our <a href="https://go.dev/design/cryptography-principles">cryptography principles</a>.
Hopefully other TLS libraries will adopt similar changes,
making delicate cipher suite configuration a thing of the past.</p>
<h2 id="the-picture">The picture</h2>
<p>Just for the Cryptography Dispatches edition, here&apos;s a picture of a bit of the New York skyline from my old apartment.</p>
<p><img src="https://words.filippo.io/content/images/2022/01/caa0a645-f719-462f-8f01-d2f6aed834d0.jpeg" alt="In the background, a skyline with six skyscrapers against a blue sky with a few bright clouds. In the foreground, a terrace with outdoor chairs and an Italian flag hung on the railing." loading="lazy"></p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[The Most Backdoor-Looking Bug Ive Ever Seen]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>This is the story of a bug that was discovered and fixed in Telegram&apos;s self-rolled cryptographic protocol about seven years ago. The bug didn&apos;t get any press, and no one seems to know about it, probably because it was only published in Russian.</p>
<p>To this day,</p>]]></description><link>https://words.filippo.io/dispatches/telegram-ecdh/</link><guid isPermaLink="false">61e9993635f8a7003b975a6d</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Sat, 09 Jan 2021 23:00:00 GMT</pubDate><media:content url="https://words.filippo.io/content/images/2022/01/ee618b89-a8fa-45a2-af01-6f9955d2c99a-1.jpeg" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://words.filippo.io/content/images/2022/01/ee618b89-a8fa-45a2-af01-6f9955d2c99a-1.jpeg" alt="The Most Backdoor-Looking Bug I&#x2019;ve Ever Seen"><p>This is the story of a bug that was discovered and fixed in Telegram&apos;s self-rolled cryptographic protocol about seven years ago. The bug didn&apos;t get any press, and no one seems to know about it, probably because it was only published in Russian.</p>
<p>To this day, it&apos;s the most backdoor-looking bug I&apos;ve ever seen.</p>
<p>Google Translate does a good enough job on the <a href="https://habrahabr.ru/post/206900/">original article</a>, which is still available on Habr, but I&apos;m going to walk you through it along with some context.</p>
<p>Telegram is a popular chat app that uses its own... bizarre protocol to encrypt chats, called MTProto. The protocol is used both to encrypt all messages to the Telegram server, and to encrypt opt-in 1:1 end-to-end &quot;Secret Chats&quot;.<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> In text I can&apos;t do justice to the facial expressions of cryptographers when you mention Telegram&apos;s protocol, so just believe me that it&apos;s <em>weird</em>.</p>
<p>The current consensus seems to be that the latest version is not broken in known ways that are severe or relevant enough to affect end users, assuming the implementation is correct. That is about as safe as leaving exposed wires around your house because they are either not live or placed high enough that no one should touch them.</p>
<p>The original version was, however, completely broken, in the most puzzling of ways.</p>
<p>End-to-end Telegram chat sessions use <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">finite-field Diffie-Hellman</a><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> to establish a shared key between the two participants. The negotiation happens through messages relayed by the Telegram server. Diffie-Hellman is a fundamental building block of many cryptosystems, and it allows two parties to establish a shared secret that any eavesdroppers can&apos;t derive. It is however only one part of a secure key exchange, because an attacker capable of intercepting the messages could simply establish two separate sessions with the two parties, carrying out a <a href="https://en.wikipedia.org/wiki/Person-in-the-middle_attack">Person-in-the-Middle</a> attack. The parties need some way to verify they derived the same secret. In TLS, they use a signature from a certificate. In most secure chat apps, there is a fingerprint (&quot;Safety Numbers&quot; in Signal) that the two parties can compare out-of-band.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> What&apos;s important is that if the two sides derived the same secret, they can be sure no one else has access to it.</p>
<p>The Telegram key exchange is described in <a href="https://web.archive.org/web/20131220000537/https://core.telegram.org/api/end-to-end#key-generation">the &quot;Key Generation&quot; section of Telegram&apos;s end-to-end API docs</a>. Concretely, Alice requests the DH parameters <code>(p, g)</code> from Telegram, painstakingly verifies them, computes a random <code>a</code> value, and sends <code>g^a mod p</code> to Telegram. Bob receives <code>(p, g, g^a mod p)</code>, similarly computes <code>b</code> and <code>g^b mod p</code>, and sends the latter back (along with a truncated hash of the derived key, for some reason).</p>
<p>Now, normally the two sides would compute the shared key as <code>(g^a)^b mod p</code> and <code>(g^b)^a mod p</code>. Instead, the original version of MTProto computed it as</p>
<pre><code>(g^a)^b mod p XOR nonce
</code></pre>
<p>where <code>nonce</code> was an arbitrary, supposedly random value sent by the server along with the peer&apos;s public contribution.</p>
<p>This was a completely non-standard and useless addition, and all it did was let the server perform an undetected Person-in-the-Middle attack. Let&apos;s see how.</p>
<p>In a normal PitM, the server negotiates two separate Diffie-Hellman sessions with Alice and Bob, who end up with different shared keys, which they could detect by comparing fingerprints.</p>
<pre><code>Alice                     Telegram              Bob

a = random()       
A = g^a mod p       -&gt;
                        t = random()
                        T = g^t mod p -&gt;
                                          b = random()
                                      &lt;-  B = g^b mod p
                                          key = T^b mod p
                    &lt;-  T
key = T^a mod p

                    T^a mod p != T^b mod p
</code></pre>
<p>With the nonce addition, however, the server could &quot;fix&quot; Alice&apos;s key to match Bob&apos;s by manipulating Alice&apos;s nonce. The two parties would end up with the same fingerprint, and couldn&apos;t tell that an attack happened, but the server (and no one else) would know the shared key, allowing it to decrypt all messages.</p>
<pre><code>nonce_bob = random()
key_bob = T^b mod p  XOR  nonce_bob

nonce_alice = A^t mod p  XOR  B^t mod p  XOR  nonce_bob
key_alice = T^a mod p  XOR  nonce_alice =
  T^a mod p  XOR  (A^t mod p  XOR  B^t mod p  XOR  nonce_bob) =
  B^t mod p  XOR  nonce_bob = key_bob
</code></pre>
<p>Why do I say this addition was useless? Because it literally had no purpose! Indeed, the vulnerability was <a href="https://web.archive.org/web/diff/20131220000537/20131225140924/http://core.telegram.org/api/end-to-end">fixed by silently removing the nonce step from the docs</a>.<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> <a href="https://core.telegram.org/constructor/encryptedChatRequested?layer=11">A later API revision</a> removed the nonce parameter with the caption &quot;Improve secret chats&quot;. All <a href="https://web.archive.org/web/20131028041748/http://core.telegram.org/constructor/encryptedChatRequested">the original API reference</a> said about the nonce is &quot;Random server sequence for calculation of key&quot;.</p>
<p>I never heard a plausible explanation for why the designers of MTProto went out of their way to add useless complexity to their protocol, with the only outcome of making undetectable interception possible.</p>
<p><strong>Edit (2021-01-11)</strong>: <a href="https://twitter.com/asdofindia/status/1348491279798128641">@asdofindia linked me on Twitter</a> to <a href="https://telegram.org/blog/crowdsourcing-a-more-secure-future">an official statement by Telegram about this</a> that I couldn&apos;t find anymore. It claims the nonce was there to protect clients with weak random number generators. Here&apos;s what I had buried into a footnote when I couldn&apos;t find a citation to attribute that explanation to Telegram:</p>
<blockquote>
<p>This doesn&apos;t make sense for a number of reasons: 1) clients with weak randomness are likely to be toast anyway, because Telegram&apos;s bizarro not-a-MAC relies on randomness in the payload to avoid an offline decryption oracle (there is a plaintext hash of the payload on the wire, I told you this was weird!); 2) the API also allows clients to request random bytes from the server to XOR with their secret share; and 3) defending against weak randomness by relying on a server contribution defends against everything but the server, which is the relevant attacker in the end-to-end setting. (Said another way, anyone that can intercept client-server messages can see the extra randomness, making it moot.) Non-practitioners might think this is a reasonable defense in depth, belts and suspenders kind of thing, but in cryptography engineering adding complexity to defend against scenarios that lead to compromise anyway is simply pointless.</p>
</blockquote>
<p>Anyway, it&apos;s been a while, the world is a different place now, and maybe <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor">Hanlon&apos;s razor</a> cuts deeper than I thought. I think there are better reasons not to use Telegram today than this old bug<sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup>, but it&apos;s still what I think about every time people talk about far-fetched &quot;bugdoors&quot;. The bar is high!</p>
<h2 id="the-picture">The picture</h2>
<p>In other news, this newsletter is going to pivot into Rome photoblogging. (Not really, if you made it this far and like cryptography engineering, you should <a href="https://buttondown.email/cryptography-dispatches?tag=header">subscribe</a> or <a href="https://twitter.com/FiloSottile">follow me on Twitter</a>.)</p>
<p><img src="https://words.filippo.io/content/images/2022/01/ee618b89-a8fa-45a2-af01-6f9955d2c99a.jpeg" alt="The Most Backdoor-Looking Bug I&#x2019;ve Ever Seen" loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>By the way, aside from all the cryptographic weirdness and the unexplained backdoor-looking bug, the real reason you should not trust Telegram&apos;s encryption is that it&apos;s off by default, inconvenient to use, and simply unavailable in groups, meaning most messages flow unencrypted on Telegram&apos;s servers. Nonetheless, Telegram markets itself as a secure chat app, with misleading copy along the lines of &quot;everything is encrypted, Secret Chats are just <em>more</em> encrypted!&quot; They explain in their FAQ that it&apos;s all about backups, and that other more secure apps &quot;<a href="https://telegram.org/faq#dev_page_content:~:text=Other%20apps%20ignore%20the%20need%20for,before%20ever%20reaching%20a%20million%20users.">never reach a million users</a>&quot;. <a href="https://twitter.com/signalapp/status/1347240006444675072">In other news</a>. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a> <a href="#fnref1:1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Diffie-Hellman over finite fields is how it was originally designed, but today we&apos;d use Elliptic-Curve Diffie-Hellman, which is faster, has smaller outputs, and is safer. FFDH has many of <a href="https://buttondown.email/cryptography-dispatches/archive/557475c5-9781-47e0-a640-5734bc849bc7">the same issues as DSA</a> (FFDH is to DSA like ECDH is to ECDSA and EdDSA.) Current-day MTProto 2.0 still uses FFDH, but that&apos;s far from the most anachronistic choice in it. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn3" class="footnote-item"><p>This is admittedly not a particularly strong authentication strategy, but it relies on the assumption that even if 1% of users check their fingerprints, systematic PitM is likely to be detected, and high-risk users can be extra careful and consistently check fingerprints. I hope solutions like key transparency can improve this picture in the coming years without changing the default UX. <a href="#fnref3" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Can we talk about how cool the Wayback Machine Compare feature is? Now is a good time to <a href="https://archive.org/donate/">donate to the Internet Archive</a>, by the way. <a href="#fnref4" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Re-Deriving the edwards25519 Decoding Formulas]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>A lot of my job is implementing specifications, and sometimes in a crypto spec you&apos;ll encounter something like this</p>
<pre><code>         (p+3)/8      3        (p-5)/8
x = (u/v)        = u v  (u v^7)         (mod p)
</code></pre>
<p>and what you do is nod, copy it into a comment, break it</p>]]></description><link>https://words.filippo.io/dispatches/edwards25519-formulas/</link><guid isPermaLink="false">61e99e5335f8a7003b975a97</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Thu, 17 Dec 2020 23:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>A lot of my job is implementing specifications, and sometimes in a crypto spec you&apos;ll encounter something like this</p>
<pre><code>         (p+3)/8      3        (p-5)/8
x = (u/v)        = u v  (u v^7)         (mod p)
</code></pre>
<p>and what you do is nod, copy it into a comment, break it down into a sequence of operations, and check that the result matches a test case.<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
<p>However, the other day I was having a bit of an identity crisis because I could not remember basic algebra, so I went and re-derived the edwards25519 point decoding formulas as a sort of homework. It turned out to be pretty useful for understanding pieces of the implementation I had been just treating as black boxes.</p>
<p>I&apos;m going to try to take you along for the ride, to show that there is no dark magic involved, and that we can all get to the same result as the specification with step-by-step high-school algebra.</p>
<p>Warning: math. (You&apos;ve got this!)</p>
<p><img src="https://words.filippo.io/content/images/2022/01/0965325d-1db4-4c98-95de-9b3f8c3d12f2.jpg" alt="My whiteboard where I worked out the formulas in this issue" loading="lazy"></p>
<h2 id="your-mission-should-you-choose-to-accept-it">Your mission, should you choose to accept it...</h2>
<p>What we are trying to do is derive the concrete formulas to decode a point on the edwards25519 elliptic curve, the one used for the Ed25519 signature algorithm.</p>
<p>Points are described by two integer coordinates, <code>x</code> and <code>y</code>, that satisfy the curve equation below, our starting point. Points are encoded by serializing the <code>y</code> coordinate and a single bit to distinguish between the two possible <code>x</code> values that can correspond to it.</p>
<p>The curve equation is</p>
<pre><code>-x&#xB2; + y&#xB2; = 1 + dx&#xB2;y&#xB2;   mod p
</code></pre>
<p>where <code>d</code> is <code>-121665/121666</code> and <code>p</code> is <code>2&#xB2;&#x2075;&#x2075;-19</code>.</p>
<p>This is also called point decompression and is not only more efficient on the wire but also safer than serializing both coordinates, as the latter encourages skipping point validation, which can lead to a fun array of vulnerabilities.</p>
<p>The algorithm is described by <a href="https://tools.ietf.org/html/rfc8032#section-5.1.3">Section 5.1.3 of RFC 8032</a>.<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<pre><code>2.  To recover the x-coordinate, the curve equation implies
    x^2 = (y^2 - 1) / (d y^2 + 1) (mod p).  The denominator is always
    non-zero mod p.  Let u = y^2 - 1 and v = d y^2 + 1.  To compute
    the square root of (u/v), the first step is to compute the
    candidate root x = (u/v)^((p+3)/8).  This can be done with the
    following trick, using a single modular powering for both the
    inversion of v and the square root:

                         (p+3)/8      3        (p-5)/8
                x = (u/v)        = u v  (u v^7)         (mod p)

3.  Again, there are three cases:

    1.  If v x^2 = u (mod p), x is a square root.

    2.  If v x^2 = -u (mod p), set x &lt;-- x * 2^((p-1)/4), which is a
        square root.

    3.  Otherwise, no square root exists for modulo p, and decoding
        fails.

4.  Finally, use the x_0 bit to select the right square root. [...]
</code></pre>
<p>We&apos;ll break down each of those steps.</p>
<h2 id="stand-back-im-going-to-try-algebra">Stand back, I&apos;m going to try algebra</h2>
<p>First, we can do regular algebra to isolate the <code>x</code> on one side of the equation. Remember that we have everything in the equation except the <code>x</code>, and keep in mind that every formula is over the base field: that is, values are integers modulo <code>p</code>.</p>
<pre><code>-x&#xB2; + y&#xB2; = 1 + dx&#xB2;y&#xB2;
x&#xB2; + dx&#xB2;y&#xB2; = y&#xB2; - 1
x&#xB2;(dy&#xB2; + 1) = y&#xB2; - 1
x&#xB2; = (y&#xB2; - 1)/(dy&#xB2; + 1)
</code></pre>
<p>This matches the spec&apos;s <code>x^2 = (y^2 - 1) / (d y^2 + 1)</code>, yay!</p>
<h2 id="division-and-inverses">Division and inverses</h2>
<p>In a finite field (the integers modulo a prime), division by <code>n</code> is performed by finding the inverse <code>n&#x207B;&#xB9;</code> and multiplying by that. The inverse is an integer, and behaves like <code>1/n</code>: <code>n * n&#x207B;&#xB9; = 1</code>.</p>
<p>We can use <a href="https://en.wikipedia.org/wiki/Modular_multiplicative_inverse#Using_Euler&apos;s_theorem">Euler&apos;s theorem to compute the inverse</a>, the same theorem that makes RSA work. <code>&#x3D5;(p)</code> is <code>p - 1</code> for all primes.</p>
<pre><code>a ^ &#x3D5;(p) = a ^ (p - 1) = 1 = a&#x2070;
a ^ (p - 2) = a&#x207B;&#xB9;
</code></pre>
<p>Full size exponentiation, even by a pretty number like <code>2&#xB2;&#x2075;&#x2075; - 21</code>, is <a href="https://github.com/FiloSottile/edwards25519/blob/700f4f4a6763998ec122f464b61562904af731e6/fe.go#L117-L182">a pretty expensive operation (255 squarings and 11 multiplications) but it can be done in constant time</a>, so that&apos;s nice.</p>
<h2 id="the-denominator-is-always-non-zero">The denominator is always non-zero</h2>
<p>Just like you can&apos;t divide by zero, there is no modular inverse for zero, so that formula only works if <code>dy&#xB2; + 1</code> is not zero. The spec confidently proclaims: &quot;The denominator is always non-zero mod p&quot;. Let&apos;s check that.</p>
<pre><code>dy&#xB2; + 1 &#x2260; 0
dy&#xB2; &#x2260; -1
y&#xB2; &#x2260; -1/d = 121666/121665
</code></pre>
<p>One way to check that inequality, is to check that <code>121666/121665</code> is not square in the field. We can use <a href="https://en.wikipedia.org/wiki/Euler%27s_criterion">Euler&apos;s criterion</a> and some Python for that. If the Euler&apos;s criterion formula works out to <code>-1</code>, <code>121666/121665</code> is not square and can&apos;t be equal to <code>y&#xB2;</code>, so we are good.</p>
<pre><code>(121666/121665) ^ ((p - 1) / 2) = -1
(121666 * 121665&#x207B;&#xB9;) ^ ((p - 1) / 2) = -1
(121666 * 121665 ^ (p - 2)) ^ ((p - 1) / 2) = p - 1
</code></pre>
<pre><code>&gt;&gt;&gt; p = 2**255 - 19
&gt;&gt;&gt; a = 121666 * pow(121665, p - 2, p)
&gt;&gt;&gt; pow(a, (p-1)//2, p) == p - 1
True
</code></pre>
<p>Yay.</p>
<h2 id="candidate-for-square-root-office">Candidate for square root office</h2>
<p>Back to our formula. The spec tells us to call numerator <code>u</code> and denominator <code>v</code> for convenience, and then to look for the square root of that ratio.</p>
<pre><code>x&#xB2; = (y&#xB2; - 1)/(dy&#xB2; + 1)
x&#xB2; = u/v = uv&#x207B;&#xB9;
x = &#x221A;(uv&#x207B;&#xB9;)
</code></pre>
<p>How do you find a square root in a field? Since <code>p = 5 mod 8</code> (because number theory <em>is</em> magic and formulas work or break based on the shape the numbers have) we can use <a href="https://en.wikipedia.org/wiki/Quadratic_residue#Prime_or_prime_power_modulus">Legendre&apos;s solution</a>.</p>
<p>It starts by trying what the spec calls the <code>candidate root x = (u/v)^((p+3)/8)</code> and we&apos;ll call <code>x&#x2081;</code>.</p>
<p>The spec says it uses &quot;a trick&quot; to combine the inversion and the square root. Why? Remember that exponentiation by a large number takes a lot of operations, and both the inversion and the square root require an exponentiation. The trick coalesces the two exponents into a single value. Let&apos;s break it down.</p>
<!-- ```
          (p+3)/8    (p+3)/8  -(p+3)/8
x = (u/v)        = u        v        
``` -->
<p>Recall that per Euler&apos;s theorem, <code>a ^ (p - 1) = a&#x2070; = 1</code>...</p>
<p><img src="https://words.filippo.io/content/images/2022/01/6ecbb2b2-dc0e-49cb-b4bd-afac8914d880.png" alt="x_1 = (u/v)^((p+3)/8) = u^((p+3)/8) v ^ (-(p+3)/8) = u^((p+3)/8) v^(p-1) v^(-(p+3)/8) = u^(1+(p-5)/8) v^(p-1-(1+(p-5)/8)) = u^(1+(p-5)/8) v^(3+p-5-(p-5)/8) = u^(1+(p-5)/8) v^(3+7(p-5)/8) = u v^3 (u v^7 )^((p-5)/8)" loading="lazy"></p>
<!-- ```
      (p+3)/8  p-1  -(p+3)/8       1+(p-5)/8  p-1-(1+(p-5)/8)
x = u        v    v            = u          v                =

      1+(p-5)/8  3+p-5-(p-5)/8     1+(p-5)/8  3+7(p-5)/8
x = u          v               = u          v                =

        3     7  (p-5)/8
x = u v  (u v )
``` -->
<p>Indeed, we get the same result as the spec says, and we now understand the formula at the top of this issue.</p>
<pre><code>          (p+3)/8      3        (p-5)/8
x&#x2081; = (u/v)        = u v  (u v^7)
</code></pre>
<p>This is a rare &quot;good clever&quot;: the numbers are the same as when we started, but arranged like this the result is much faster to compute for two reasons.</p>
<p>First, <code>uv&#x2077;</code> is easy to compute after computing <code>uv&#xB3;</code>. How we do this kind of math on computers is through a sequence of additions, multiplications, and squarings, and we get to hold on to any intermediate values that we might use later for free. <code>uv&#xB3;(uv&#x2077;)</code> is <a href="https://github.com/FiloSottile/edwards25519/blob/700f4f4a6763998ec122f464b61562904af731e6/fe.go#L396-L402">just five multiplications and a squaring</a> how I ended up doing it.</p>
<pre><code>uv&#xB3; = u * v&#xB2; * v
uv&#x2077; = [uv&#xB3;] * [v&#xB2;] * [v&#xB2;]
uv&#xB3;(uv&#x2077;) = [uv&#xB3;] * [uv&#x2077;]
</code></pre>
<p>Second, like we hardcoded an exponentiation by <code>p - 2 = 2&#xB2;&#x2075;&#x2075; - 21</code> to implement inversion, here we can hardcode <a href="https://github.com/FiloSottile/edwards25519/blob/700f4f4a6763998ec122f464b61562904af731e6/fe.go#L333-L382">a similar exponentiation chain</a> for <code>(p - 5) / 8 = 2&#xB2;&#x2075;&#xB2; - 3</code>.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> This explains the function called <code>fePow22523</code> in the library I was looking at!</p>
<h2 id="if-not-this-one-the-other-one">If not this one, the other one</h2>
<p>Ok, but <code>x = x&#x2081;</code> is only one of the two possible Legendre&apos;s solutions. It can also be <code>x = x&#x2081; * 2^(p-1)/4</code>, based on some obscure property of <code>x&#xB2;</code> that we don&apos;t want to figure out directly.</p>
<p>It&apos;s easy to check if <code>x = x&#x2081;</code> is the right one.</p>
<pre><code>x&#x2081; = x = &#x221A;(uv&#x207B;&#xB9;)
x&#x2081;&#xB2; = uv&#x207B;&#xB9;
vx&#x2081;&#xB2; = u
</code></pre>
<p>What if it&apos;s <code>x = x&#x2081; * 2^(p-1)/4</code> though? How would we know?</p>
<p>Well, there&apos;s something special about <code>2^(p-1)/4</code>: per <a href="https://en.wikipedia.org/wiki/Euler%27s_criterion">Euler&apos;s criterion</a> (the same one we used to check if the denominator was square earlier), that value is <code>&#x221A;-1</code>, the square root of minus one.<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> (In complex numbers we would call that <em>i</em>, the imaginary constant, but on a finite field there is acutally such an integer.) This also explains why that constant is called <code>SQRT_M1</code> in the code I was looking at!</p>
<pre><code>2^(p-1)/4 = &#x221A;-1
(2^(p-1)/4)^2 = 2^(p-1)/2 = -1
</code></pre>
<pre><code>&gt;&gt;&gt; SQRT_M1 = pow(2, (p-1)/4, p)
&gt;&gt;&gt; pow(SQRT_M1, 2, p) == p - 1
True
</code></pre>
<p>So if <code>x = x&#x2081;</code> is not it, we need to check if <code>x = x&#x2081; * &#x221A;-1</code> is the correct solution.</p>
<pre><code>x&#x2081; * &#x221A;-1 = x = &#x221A;(uv&#x207B;&#xB9;)
(x&#x2081; * &#x221A;-1)&#xB2; = uv&#x207B;&#xB9;
-x&#x2081;&#xB2; = uv&#x207B;&#xB9;
vx&#x2081;&#xB2; = -u
</code></pre>
<p>Note how similar to the <code>x = x&#x2081;</code> check that is. This means we can compute <code>vx&#x2081;&#xB2;</code>, and pick <code>x = x&#x2081;</code> if it works out to <code>u</code>, or <code>x = x&#x2081; * 2^(p-1)/4</code> if it works out to <code>-u</code>, which is a very cheap comparison. If it&apos;s neither, there is no square root and we exit.<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></p>
<p>Indeed, this matches the algorithm of the spec!</p>
<h2 id="wrapping-up">Wrapping up</h2>
<p>Cool, we have <code>x</code> and everything matches the spec, but most importantly we understand how we got there. The final step is choosing between <code>x</code> and <code>-x</code>, since just like with regular algebra, they are both square roots of <code>x&#xB2;</code>. They both correspond to valid points, one the negative of the other. We use the <code>x_0</code> bit (aka the sign bit) that was stored in the unused top bit of <code>y</code> to choose between them.</p>
<p>All this is <a href="https://github.com/FiloSottile/edwards25519/blob/700f4f4a6763998ec122f464b61562904af731e6/edwards25519.go#L143-L192">implemented</a> in <a href="https://filippo.io/edwards25519">filippo.io/edwards25519</a> my new Go library based on work by Adam Langley, George Tankersley, and Henry de Valence. This library is <a href="https://go-review.googlesource.com/c/go/+/276272">faster</a>, safer, and easier to use than <code>crypto/ed25519/internal/edwards25519</code>, which a lot of projects forked over the years. It also supports multi-scalar multiplication for <a href="https://github.com/hdevalence/ed25519consensus/issues/5">batch signature verification</a>. Try it out!</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>By the way, high quality specs should have intermediate test cases, not just test cases for the whole algorithm. There are two reasons: first, in cryptography when you get something wrong it can be extremely hard to narrow down where the mistake is, all you know is that you wrote 300 lines and the result is wrong, great; second, you get to more easily write test cases for edge cases that are hard to hit from the high-level API. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Sort of. Almost no one actually implements Section 5.1.3, because it retconned a few strictness checks that were not in the original Ed25519. After reading this issue you&apos;ll be in a better position to understand that mess <a href="https://hdevalence.ca/blog/2020-10-04-its-25519am">as explained by Henry de Valence</a> but you don&apos;t need to understand that first to read on. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn3" class="footnote-item"><p>If you squint here, you can see why that formula we used requires <code>p = 5 mod 8</code>: it means <code>(p+3)/8</code> and <code>(p-5)/8</code> are integers. <a href="#fnref3" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn4" class="footnote-item"><p>A bit of cheating here: I did not recognize that value as <code>&#x221A;-1</code>. Instead, I looked at the <code>x = x&#x2081; * 2^(p-1)/4</code> condition, and tried to work my way back to how that was possible, which required <code>&#x221A;-1</code> to exist. <a href="#fnref4" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn5" class="footnote-item"><p>If we want to do this without leaking information about the point through a side-channel, we&apos;ll have to <a href="https://github.com/FiloSottile/edwards25519/blob/700f4f4a6763998ec122f464b61562904af731e6/fe.go#L413">compute both and do a select in constant time</a>, but again this is cheap. The <a href="https://tools.ietf.org/id/draft-irtf-cfrg-ristretto255-decaf448-00.html#section-4.2">ristretto255 spec</a> has this whole &quot;constant time square root of a ratio&quot; operation defined, including what it returns when the ratio is not a square. <a href="#fnref5" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Reconstruct Instead of Validating]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>Project Zero <a href="https://googleprojectzero.blogspot.com/2020/10/enter-the-vault-auth-issues-hashicorp-vault.html">dropped a great bug in Vault</a> which I think would have been prevented by one of the lessons learned of cryptography engineering: when you can, always prefer reconstructing a value rather than parsing and validating it.</p>
<p>You should read the blog post to understand the attack first, because</p>]]></description><link>https://words.filippo.io/dispatches/reconstruct-vs-validate/</link><guid isPermaLink="false">61e9a10235f8a7003b975ab3</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Wed, 07 Oct 2020 22:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>Project Zero <a href="https://googleprojectzero.blogspot.com/2020/10/enter-the-vault-auth-issues-hashicorp-vault.html">dropped a great bug in Vault</a> which I think would have been prevented by one of the lessons learned of cryptography engineering: when you can, always prefer reconstructing a value rather than parsing and validating it.</p>
<p>You should read the blog post to understand the attack first, because my tl;dr will not do it justice, but here&apos;s an overview.</p>
<p><a href="https://www.vaultproject.io">Vault</a> is a thing that manages your secrets, like database credentials, and makes them accessible to the applications that need them through its various APIs. Of course, these APIs need some sort of authentication, which can be a bit of a chicken-and-egg situation. If you run on a cloud platform like AWS, the natural way to identify an application is through the IAM role it runs as, and Vault has a way to authenticate API calls through IAM roles.</p>
<p>How does Vault do that? Is there an AWS API for that? Nope!</p>
<p>How you <a href="https://docs.aws.amazon.com/general/latest/gr/sigv4_signing.html">authenticate AWS API calls</a> is by making an HMAC signature on a canonicalized<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> version of the HTTP request. This means you can hand a signed request to someone else and they can run it for you. (This is used for example to let clients download specific objects from S3 without sharing credentials.)</p>
<p>Moreover, AWS has <a href="https://docs.aws.amazon.com/STS/latest/APIReference/API_GetCallerIdentity.html">an innocuous API called <code>sts:GetCallerIdentity</code></a> which just returns the IAM role of the caller. You might see where this is going.</p>
<p>How <a href="https://www.vaultproject.io/docs/auth/aws">Vault IAM authentication</a> works is that you prepare a signed <code>sts:GetCallerIdentity</code> API request and give it to Vault, which sends it to AWS and gets the IAM role name from the response.</p>
<p>Felix Wilhelm from Project Zero found that an attacker can change the API request to hit a different AWS API which will reflect back attacker controlled data (wrapped in JSON) without needing proper authentication, and put a <code>sts:GetCallerIdentity</code> response in the attacker controlled data.</p>
<p>Again, if this doesn&apos;t make sense, <a href="https://googleprojectzero.blogspot.com/2020/10/enter-the-vault-auth-issues-hashicorp-vault.html">read the blog post</a>.</p>
<p>Multiple things went wrong here:</p>
<ol>
<li>The scheme is too clever by three quarters, using an AWS API which is not meant for authentication, and is actually considered so innocuous it can&apos;t be blocked.</li>
</ol>
<blockquote>
<p>No permissions are required to perform this operation. If an administrator adds a policy to your IAM user or role that explicitly denies access to the <code>sts:GetCallerIdentity</code> action, you can still perform this operation. Permissions are not required because the same information is returned when an IAM user or role is denied access.</p>
</blockquote>
<ol start="2">
<li>
<p>The request that Vault forwards to AWS is malleable and Vault failed to validate it sufficiently, allowing the attacker to redirect it to a different endpoint.</p>
</li>
<li>
<p>The XML parser is too lenient in allowing text before and after the element it&apos;s unmarshaling, letting the attacker embed a fake <code>GetCallerIdentityResponse</code> in a JSON blob.</p>
</li>
</ol>
<p>(1) is where things actually started taking a turn for the worse, but it&apos;s arguably AWS&apos;s fault for not providing a proper delegated auth scheme. It&apos;s also unexpected that delegating a <code>sts:GetCallerIdentity</code> request would result in delegating Vault access, but Vault apparently has a mitigation for that: you can <a href="https://www.vaultproject.io/docs/auth/aws#iam-auth-method">require a custom <code>X-Vault-AWS-IAM-Server-ID</code> header</a> in the request, which will be verified by AWS with the rest of the request. This is also clever<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>, but for some reason optional.</p>
<p>(3) is a little too much about my day job to be fun to discuss here, since the XML parser in question is Go&apos;s <code>encoding/xml</code>.<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<p>What I want to focus on is (2), because it&apos;s a lesson we learned the hard way in cryptography and didn&apos;t transfer effectively to the rest of security engineering.</p>
<p>One of my favorite cryptographic attacks is the Bleichenbacher&apos;06 signature forgery. I <a href="https://blog.filippo.io/bleichenbacher-06-signature-forgery-in-python-rsa/">wrote up how it works</a> when I found it in <code>python-rsa</code>, so again go read that, but here&apos;s a tl;dr. When you verify an RSA PKCS#1 v1.5 signature, you get a ASN.1 DER structure wrapping the message hash that you need to check. If you don&apos;t parse it strictly, for example by allowing extra fields or trailing bytes, an attacker can fake the signature. This was exploited countless times.</p>
<p>The lesson we learned was that instead of parsing the ASN.1 DER to extract the message hash, we should reconstruct the ASN.1 DER we&apos;d expect to see, and then simply compare it byte-by-byte.</p>
<p>The same technique would have saved Vault.</p>
<p>This is what a <code>sts:GetCallerIdentity</code> request looks like:</p>
<pre><code>POST / HTTP/1.1
Host: sts.amazonaws.com
Accept-Encoding: identity
Content-Length: 32
Content-Type: application/x-www-form-urlencoded
Authorization: AWS4-HMAC-SHA256 Credential=AKIAI44QH8DHBEXAMPLE/20160126/us-east-1/sts/aws4_request,SignedHeaders=host;user-agent;x-amz-date,Signature=1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef
X-Amz-Date: 20160126T215751Z
User-Agent: aws-cli/1.10.0 Python/2.7.3 Linux/3.13.0-76-generic botocore/1.3.22

Action=GetCallerIdentity&amp;Version=2011-06-15
</code></pre>
<p>The Vault API takes basically the entire thing split over four base64-encoded parameters: <code>iam_http_request_method</code>, <code>iam_request_url</code>, <code>iam_request_headers</code>, and <code>iam_request_body</code>. The attackers modified the body and headers to redirect the request and get a spoofed response. There is no reason to give an attacker all this flexibility!</p>
<p>If you look at the <code>sts:GetCallerIdentity</code> request above there are really only two fields that should ever change: <code>X-Amz-Date</code> and <code>Authorization</code>. A much better API for Vault would only take two parameters: <code>iam_request_date</code> and <code>iam_request_authorization</code>. Everything else (including the clever <code>X-Vault-AWS-IAM-Server-ID</code> header) would be hardcoded both on the Vault client and on the server.</p>
<pre><code>POST / HTTP/1.1
Host: sts.amazonaws.com
Accept-Encoding: identity
Content-Length: 32
Content-Type: application/x-www-form-urlencoded
Authorization: $iam_request_authorization
X-Amz-Date: $iam_request_date
X-Vault-AWS-IAM-Server-ID: vault.example.com
User-Agent: Vault-IAM-Authentication/1.0.0

Action=GetCallerIdentity&amp;Version=2011-06-15
</code></pre>
<p>The client would reconstruct the request to generate the <code>Authorization</code> signature, and the server would reconstruct it to send it on to AWS. The server would still have to validate or at least escape the two <code>X-Amz-Date</code> and <code>Authorization</code> header values, but that&apos;s way easier than validating a whole request. If an attacker changed anything else in the request, the <code>Authorization</code> signature would simply fail to verify. Since the attackers would not have had control over the body or the headers, the attack would have never worked. I bet it would have even been less code!</p>
<p><strong>The best way to validate something that&apos;s not supposed to change is to not accept it from the attacker at all, and reconstruct it from hardcoded values.</strong> The parameters that you do accept should be as tightly scoped as possible, to make them easier to validate without risky parsing.</p>
<p>One might ask what happens when the AWS API changes or grows a parameter, but that&apos;s an argument for this technique, not against. Any changes might invalidate the security of this scheme, especially since it&apos;s not what the <code>sts:GetCallerIdentity</code> API is for, and you don&apos;t want the client to be able to opt-in unilaterally. Indeed, <a href="https://github.com/hashicorp/vault/commit/ade448cd47b151832114bb15d03dd185a917b626">the patch</a> adds a header allowlist, which neuters the flexibility of taking the whole request from the client anyway, leaving behind just the complexity of doing unnecessary and dangerous parsing and validation.</p>
<h2 id="a-picture">A picture</h2>
<p>This newsletter is brought to you by Rome being pretty as hell. Bonus points to anyone who can recognize the garden. (I stripped EXIF metadata, sorry. &#x1F609;)</p>
<p><img src="https://words.filippo.io/content/images/2022/01/70e5316c-4c15-4a31-a158-a9d622291ee8.jpg" alt="The sun shining through the trees in a garden." loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Relatedly but orthogonally, canonicalization is just a way to introduce a dangerous parse and serialize cycle in the danger path, and as much as possible signatures should be over what&apos;s on the wire. But that&apos;s an opinion for another day. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>As my team can tell you, I don&apos;t consider &quot;clever&quot; a compliment in my line of work. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Look, I&apos;m not paid to write these. (I am paid to learn XML and despair about the backwards compatibility promise, though, so I assure you I am doing that.) <a href="#fnref3" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[NaCl Is Not a High-Level API]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>When talking about high-level application cryptography APIs I usually hear mentioned <a href="https://github.com/jedisct1/libsodium">libsodium</a>, <a href="https://opensource.google/projects/tink">Tink</a>, <a href="https://cryptography.io">pyca/cryptography</a>, and NaCl.</p>
<p>One of these things is not like the others! The value NaCl had 10 years ago was that it was an opinionated library at a time when all cryptography libraries were choose-your-own-adventure toolkits,</p>]]></description><link>https://words.filippo.io/dispatches/nacl-api/</link><guid isPermaLink="false">61e9a1a735f8a7003b975ac5</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Mon, 07 Sep 2020 22:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>When talking about high-level application cryptography APIs I usually hear mentioned <a href="https://github.com/jedisct1/libsodium">libsodium</a>, <a href="https://opensource.google/projects/tink">Tink</a>, <a href="https://cryptography.io">pyca/cryptography</a>, and NaCl.</p>
<p>One of these things is not like the others! The value NaCl had 10 years ago was that it was an opinionated library at a time when all cryptography libraries were choose-your-own-adventure toolkits, but its APIs are not high-level, and even its constructions are unsafe by today&apos;s standards.</p>
<p>NaCl refers to a set of APIs implemented in C by an old library published at <a href="https://nacl.cr.yp.to/">nacl.cr.yp.to</a>. No one really uses the original library<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>, partially because it was a pain to build and package, but two of its constructions got ported to a number of languages, including Go: box and secretbox.<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p><a href="https://godoc.org/golang.org/x/crypto/nacl/secretbox">secretbox</a> is for encrypting a message with a symmetric key, and it looks like this in Go.</p>
<pre><code>func Seal(out, message []byte, nonce *[24]byte, key *[32]byte) []byte
func Open(out, box []byte, nonce *[24]byte, key *[32]byte) ([]byte, bool)
</code></pre>
<p>It&apos;s nothing else than XSalsa20Poly1305, and you could use any other AEAD with large nonces like <a href="https://pkg.go.dev/golang.org/x/crypto/chacha20poly1305?tab=doc#NewX">straight XChaCha20Poly1305</a> in the exact same way. (It also lacks the convenient ChaCha20Poly1305 twist of skipping the leftovers of the first ChaCha20 block after generating the Poly1305 key, so the ciphertext starts on a block boundary.)</p>
<p>It&apos;s not even a good high-level AEAD API, because it leaves nonce management to the application, when it should just generate it randomly (192 bits is enough to do so safely) and prepend it to the ciphertext. The <a href="https://golang.org/pkg/crypto/cipher/#AEAD">Go AEAD interface</a> does this wrong, too, and I have seen so many developers struggling with where to store the nonce. (The answer is to prepend it to the ciphertext.) Some protocols do require controlling nonces (the TLS record layer, for example), for good reason, but they should be served by a lower-level API than what is provided to applications. secretbox was a missing opportunity here.</p>
<p><a href="https://godoc.org/golang.org/x/crypto/nacl/box">box</a> is for encrypting a message with asymmetric keys, and it looks like this in Go.</p>
<pre><code>func Seal(out, message []byte, nonce *[24]byte, peersPublicKey, privateKey *[32]byte) []byte
func Open(out, box []byte, nonce *[24]byte, peersPublicKey, privateKey *[32]byte) ([]byte, bool)
</code></pre>
<p>The first thing you might notice, after the fact that again we&apos;re asking the application for a nonce we could have randomized for them, is that sealing a message also requires a private key and opening one also requires a public key. That&apos;s because box is static Diffie-Hellman between two long-term key pairs: the sender and the receiver. Having a stable sending key is uncommon enough that libsodium introduced <a href="https://libsodium.gitbook.io/doc/public-key_cryptography/sealed_boxes">an anonymous variant</a> which generates an ephemeral sending key pair for each message, and <a href="https://blog.filippo.io/giving-up-on-long-term-pgp/">long-term secrets should be avoided</a> rather than encouraged.</p>
<p>The presence of a sending key might make you think the message is signed by it<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>, but it&apos;s not. box provides only authentication<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>, meaning that the recipient can change the message, too, and it will look the same as if the sender sent it. This is supposed to provide repudiability, a property I never really saw the value of.</p>
<p>Worse, there is actually nothing to distinguish a sender&#x2192;recipient box from a recipient&#x2192;sender one. Any third-party can take a box you sent and reflect it back to you, and it will look like it came from the recipient.</p>
<p>For example, if you have a protocol where two parties exchange boxes every hour to confirm everything is fine, like this...</p>
<p>A &#x2192; B: <code>box(pubB, privA, &quot;One o&apos;clock and all is well&quot;)</code><br>
B &#x2192; A: <code>box(pubA, privB, &quot;One o&apos;clock and all is well&quot;)</code></p>
<p>... then a MitM can just take the &quot;A &#x2192; B&quot; message and send it back to A, even if B <a href="https://www.youtube.com/watch?v=v3d3upKtbJA">was captured by a bear and a fox</a>, and it will look fine to A.</p>
<p>The <a href="https://nacl.cr.yp.to/box.html#:~:text=For%20example%2C%20the%20lexicographically%20smaller%20public,for%20its%20third%20message%2C%20etc.%20Nonces">original NaCl docs</a> suggest a scheme to protect against this, even if they don&apos;t mention the attack and focus more on avoiding nonce reuse, which again would not be a problem if they were randomized.<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></p>
<blockquote>
<p>the lexicographically smaller public key can use nonce 1 for its first message to the other key, nonce 3 for its second message, nonce 5 for its third message, etc., while the lexicographically larger public key uses nonce 2 for its first message to the other key, nonce 4 for its second message, nonce 6 for its third message, etc</p>
</blockquote>
<p>Note that for this trick to protect you against reflection attacks, you have to not only use it as your nonce generation scheme, but also to verify all the incoming nonces.</p>
<p>Now, I don&apos;t know about you, but I wouldn&apos;t call this a high-level API.</p>
<p>I mostly focused on the construction here because again no one uses the library itself from 2008&#x2013;2011, but I feel like the C API still deserves a honorable mention, because... excuse me, what!?</p>
<blockquote>
<p><code>crypto_box()</code> takes a pointer to 32 bytes before the message, and stores the ciphertext 16 bytes after the destination pointer, the first 16 bytes being overwritten with zeros. <code>crypto_box_open()</code> takes a pointer to 16 bytes before the ciphertext and stores the message 32 bytes after the destination pointer, overwriting the first 32 bytes with zeros.</p>
</blockquote>
<p>(The quote above is from <a href="https://libsodium.gitbook.io/doc/public-key_cryptography/authenticated_encryption#notes">the libsodium docs</a> because the <a href="https://nacl.cr.yp.to/box.html#:~:text=WARNING%3A%20Messages%20in%20the%20C%20NaCl,the%20ciphertext%20c%20are%20all%200.">NaCl ones were even too hard to quote</a>.)</p>
<p>Those prefix bytes apparently must be zeroes or the behavior is undefined, they must be counted in the length parameters, and the two different constants are conveniently named <code>crypto_box_BOXZEROBYTES</code> and <code>crypto_box_ZEROBYTES</code>.</p>
<p>libsodium added replacement <code>_easy</code> APIs, and mentions in its docs that &quot;the original NaCl crypto_box API is also supported, albeit not recommended&quot;. Well, yeah.</p>
<h2 id="follow-ups">Follow-ups</h2>
<p>In Dispatch #4, I mention that OpenSSH encrypts the FIDO2 key handle when you encrypt a security key-backed SSH key, and I was not sure if you could actually rely on it being necessary to use the key. <a href="https://news.ycombinator.com/item?id=24263426">tialaramex on HN pointed out</a> that WebAuthN does guarantee that: the key handle has to either include at least 100 bits of entropy, or be the encrypted key material.</p>
<p>There&apos;s a wrinkle in that OpenSSH implements FIDO2, not WebAuthN, but most hardware tokens implement both. I appreciated this line, which means my shtick is getting across.</p>
<blockquote>
<p>You&apos;d presumably hate both specifications, because they drag in (and rely upon) registries for a bunch of technically unnecessary stuff and not even for the practical engineering reason I&apos;ve excused in my sister posts to this thread.</p>
</blockquote>
<h2 id="links">Links</h2>
<ul>
<li>The Web of Trust is totally fine, except <a href="https://lists.fosdem.org/pipermail/fosdem/2016-February/002445.html">the entire system falls down if someone uses a fake passport</a>. Better blame the person who pointed this out. <a href="https://lists.debconf.org//lurker/message/20060525.133944.cf558067.en.html">Previously</a>.</li>
<li>The US Government <a href="https://github.com/18F/vulnerability-disclosure-policy/blob/master/vulnerability-disclosure-policy.md#reporting-a-vulnerability">vulnerability disclosure policy</a> was already rejecting PGP and directing reporters to a TLS form. Neat!</li>
<li><a href="https://golang.org/issues/40337">My DSA deprecation proposal</a> was accepted!</li>
<li><a href="https://twitter.com/XMPPwocky/status/1291144278953955328">Critical PGP bug just disclosed</a>.</li>
<li><a href="https://www.jcraige.com/an-explainer-on-ed25519-clamping">A nice explainer of 25519 clamping</a>. Note how clamping is actually pointless for signatures, and Ed25519 could have skipped it and there would have been no need for non-standard solutions for hierarchical keys. (But fear not, there&apos;s an IETF WG that&apos;s <a href="https://twitter.com/FiloSottile/status/1300576817053663232">standardizing ECDSA-Curve25519</a>, because sure, it&apos;s 2020.)</li>
<li>The <a href="https://cabforum.org/2020/07/16/ballot-sc31-browser-alignment/">CA/Browsers Forum ballot</a> that aligns the requirements of the various root programs with the Baseline Requirements (which exist to make a common target for audits that works for all browsers&apos; root programs) has finally passed. <a href="https://twitter.com/Scott_Helme/status/1302253356270968833">GoDaddy violated it immediately</a>.</li>
<li>Katie&apos;s <a href="https://golang.org/s/draft-fuzzing-design">fuzzing design draft</a> for Go is out. You can <a href="https://lwn.net/Articles/829242/">read about it on LWN</a> or listen to <a href="https://changelog.com/gotime/145">the Go Time episode</a>.</li>
<li>Speaking of the Go Security team, <a href="https://twitter.com/rolandshoemaker/status/1300849333969907712">Roland is joining</a> me and Katie, and <a href="https://twitter.com/empijei/status/1300855698503405568">Roberto has been helping out</a>. Very excited by what&apos;s to come.</li>
<li>I am <a href="https://twitter.com/FiloSottile/status/1300946068411121665">again sad about JWTs</a> and I&apos;m considering giving in to harm reduction and making <a href="https://twitter.com/FiloSottile/status/1300963876167712768">a safe API for verification</a>. There is still time to stop me.</li>
</ul>
<p>Finally, I really need you all to <a href="https://twitter.com/pwnallthethings/status/1301277002763251712">read this thread</a> about the festering misogyny in InfoSec, and reflect on how we all enable it by maintaining professional relationships with the people who harass our colleagues and drive them out of the industry.</p>
<h2 id="a-picture">A picture</h2>
<p>Harriman State Park is pretty great.</p>
<p><img src="https://words.filippo.io/content/images/2022/01/bc65c346-7be5-472a-adcc-c7329c84af2c.jpg" alt="My Duke 390 sitting on the side of the road with a background of a pond and some woods reflecting on it." loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>A lot of people rightfully use <a href="https://github.com/jedisct1/libsodium">libsodium</a> by Frank Denis, which started as a portable NaCl fork, but added a number of APIs, replaced some of the egregiously bad ones, and most importantly provides <a href="https://libsodium.gitbook.io/doc/">the most impressive set of cryptography library docs</a>. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p>golang.org/x/crypto/nacl also implements the auth and sign APIs, but hardly anyone uses them. <a href="https://godoc.org/golang.org/x/crypto/nacl/auth">auth</a> is just HMAC, and is imported by 10 packages. <a href="https://godoc.org/golang.org/x/crypto/nacl/sign">sign</a> is just Ed25519, is imported by 20 packages, and was not even implemented by the original library. For comparison, box and secretbox are imported by 500-700 packages. <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn3" class="footnote-item"><p>You&apos;ll see the operation of signing and asymmetrically encrypting a message called &quot;signcryption&quot;. It has its own name because it&apos;s hard to construct: you can&apos;t just compose signing and encryption. If you encrypt a message and then sign it, anyone can strip the signature, sign it themselves, and pretend it&apos;s from them even if they can&apos;t decrypt it; if you sign first and then encrypt, the recipient can decrypt it, keep the signature, and re-encrypt it to a new recipient the sender didn&apos;t mean to reach. <a href="#fnref3" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn4" class="footnote-item"><p>&quot;Authentication&quot; is an unfortunately overloaded term: in a symmetric context it means the ciphertext is not malleable (like, an AEAD instead of AES-CTR) and it&apos;s absolutely table stakes; in an asymmetric context it means this sort of &quot;only people with a certain key can send you a message&quot;. As if the authenticated vs. signed distinction wasn&apos;t confusing enough. <a href="#fnref4" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a href="https://twitter.com/SoatokDhole/status/1303205980059074562">Soatok pointed out on Twitter</a> that libsodium solved all this much more elegantly in their <a href="https://libsodium.gitbook.io/doc/key_exchange">key exchange API</a>, where they ask peers to identify as server and client, and then generate separate s&#x2192;c and c&#x2192;s keys on both sides. <a href="#fnref5" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Registries Considered Harmful]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>Cryptographic protocols and specifications often come with registries that map numeric or string identifiers to algorithms or suites.</p>
<p>Something like this.</p>
<pre><code>1    RSA-PSS-SHA256
2    RSA-PSS-SHA512
3    ECDSA-P256-SHA256
4    ECDSA-P521-SHA512
5    Ed25519
...
</code></pre>
<p>You&apos;ll find them everywhere. TLS, X.509, SSH, PGP, you name it. They enumerate signature algorithms, hash</p>]]></description><link>https://words.filippo.io/dispatches/registries-considered-harmful/</link><guid isPermaLink="false">61e9a24d35f8a7003b975adb</guid><category><![CDATA[dispatches]]></category><dc:creator><![CDATA[Filippo Valsorda]]></dc:creator><pubDate>Fri, 21 Aug 2020 22:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>Cryptographic protocols and specifications often come with registries that map numeric or string identifiers to algorithms or suites.</p>
<p>Something like this.</p>
<pre><code>1    RSA-PSS-SHA256
2    RSA-PSS-SHA512
3    ECDSA-P256-SHA256
4    ECDSA-P521-SHA512
5    Ed25519
...
</code></pre>
<p>You&apos;ll find them everywhere. TLS, X.509, SSH, PGP, you name it. They enumerate signature algorithms, hash functions, ciphers, key exchanges, encodings... all sorts of primitives and parameters. There is even a whole bureaucracy set up to handle the IETF/IANA ones. People have opinions on its bylaws.</p>
<p>I think these registries are a design smell at best, and outright harmful in most designs. What they encourage is designing for <a href="https://www.imperialviolet.org/2016/05/16/agility.html">cryptographic agility</a>: a &quot;gotta catch &apos;em all&quot; approach to cryptographic primitive choices which we now know is a very common source of protocol vulnerabilities. If you need to enumerate the options you support, it means that not only you support multiple ones, which is already bad, but you need to communicate the choices in the protocol itself, meaning you do runtime negotiation. Do you want bugs? Because that&apos;s how you get bugs.</p>
<p>Even worse than protocol registries are abstract registries, like <a href="https://www.iana.org/assignments/aead-parameters/aead-parameters.xhtml">the IANA registry of AEADs</a>. They imply that if you are going to use an AEAD in your protocol you should make it parametrizable, and they conveniently already enumerated all the options for you, in case you wanted to defer the choice between <code>AEAD_AES_256_GCM_SIV</code>, <code>AEAD_CHACHA20_POLY1305</code>, and <code>AEAD_AES_128_CCM_SHORT</code>.</p>
<p>What&apos;s the alternative? The alternative is to <em>have one joint, and keep it well-oiled</em> (to quote Adam Langley from the cryptographic agility essay linked above). Instead of parametrizing every choice, each version of a protocol or a format should pick one specific primitive, and if anything needs to change the protocol or format version can be bumped.</p>
<p>For example, <a href="https://age-encryption.org/v1">age</a> v1 uses ChaCha20-Poly1305, HKDF-SHA256, and HMAC-SHA256. There is no identifier next to the ciphertexts or MACs, there is just a format version number in the header. If we ever need to change one of the primitives, we&apos;ll make age v2. Old tools would not have supported the new primitives anyway, and new tools can still support both versions if it&apos;s safe to do so. The industry now understands updating and patching software quickly is critical, so the case for runtime configuration-based mitigations is weaker than ever.</p>
<p>If you do need to support multiple options in a format (which I mostly find objectionable but hey, not a perfect world, I get it), for example to support different key types, you should still not need registries: the type of a signature for example should be a property of the key being used to verify it. (This mantra I got from <a href="https://twitter.com/SchmiegSophie">Sophie Schmieg</a>.) You might need a name for the key type if you load it from disk, but not for the signature. Otherwise, you end up with JWT, where <a href="https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/">the signature gets to tell the verifier to use an RSA public key as an HMAC secret key</a>.</p>
<p>This is not to say that interchangeable primitives that implement a well-defined API, like AEADs or <em>cough</em> <a href="https://ietf.org/id/draft-irtf-cfrg-ristretto255-00.html#name-the-group-abstraction">prime-order groups</a>, are bad! Quite the contrary, we do need to have a variety of interchangeable well-studied primitives available off-the-shelf, so that protocols can compose them easily and safely, and even quickly replace a broken one (in a new version) if something were to happen. However, a certain protocol version should be instantiated with a specific set of concrete primitives, which make the registry unnecessary.</p>
<p>For example, a file exchange protocol version could instantiate a specific PAKE with a specific prime-order group, and pick CPace-ristretto255 for password authentication.</p>
<p>Whether libraries should implement instantiations (like CPace-ristretto255) or take an interface (like CPace over any prime order group) is a more nuanced issue, but by the time the bytes hit the wire, there must be no choice left to communicate, so there is no need for registries.</p>
<p>Admittedly, age does have something resembling a registry: the recipient types, like <code>X25519</code> and <code>scrypt</code>. Recipient types however have different user-visible behaviors, they aren&apos;t just internal cryptographic choices. Maybe better names for them would have been <code>publickey</code> and <code>passphrase</code>, respectively.<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> (They are also the main and only extensibility joint in the format: anyone can implement a custom recipient type to support hardware tokens, or KMS, or their key distribution system. Extension registries are not what I&apos;m writing about.)</p>
<p>In general, that&apos;s how I feel about options in cryptographic tools and formats: if the choice leads to different semantics, like passphrase vs. public key encryption, it might be legitimate to let the user choose; if the choice has no semantic implications, like between hash functions or between ciphers, it&apos;s our job as cryptography engineers to make it, even if it&apos;s not always an obvious one. The user&#x2014;or the developer&#x2014;would be in a worse, not better, position to make it.</p>
<h2 id="a-picture">A picture</h2>
<p>Since this round I&apos;m going to get roasted for my opinions, might as well throw my movie tastes in there as well. Here&apos;s the wall in front of my TV that I recently decorated with my favorite movies&apos; posters. (Note the server now <a href="https://filippo.io/behindthesofa/">besides the sofa</a>, and the cute zebra shark.)</p>
<p><img src="https://words.filippo.io/content/images/2022/01/a897f133-f5b8-41eb-8cce-1dee00ba219a.jpg" alt="The wall behind my couch with 9 movie posters: Good Will Hunting, Before Sunrise, Up in the Air, Lost in Translation, Apocalypse Now, The Blues Brothers, Grand Budapest Hotel, La La Land, and Men in Black." loading="lazy"></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>It&apos;s interesting to think how &quot;make it a property of the key&quot; would work here. Maybe each recipient stanza would be an opaque block and it would be passed to all the configured identities (private keys)? Type confusion is less worrying in age than JWT because the wrong identity will just not produce the right file key, but there might be a <a href="https://en.wikipedia.org/wiki/Chosen-ciphertext_attack">CCA</a> angle to it. Maybe v2 should do away with recipient type names. <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->]]></content:encoded></item></channel></rss>