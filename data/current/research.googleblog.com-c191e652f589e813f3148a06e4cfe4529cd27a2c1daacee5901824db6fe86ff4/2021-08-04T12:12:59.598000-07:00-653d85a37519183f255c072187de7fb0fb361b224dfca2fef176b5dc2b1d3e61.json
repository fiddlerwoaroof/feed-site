{
  "title":"Two New Datasets for Conversational NLP: TimeDial and Disfl-QA",
  "date":"2021-08-04T12:12:59.598000-07:00",
  "author":"Google AI",
  "id":"tag:blogger.com,1999:blog-8474926331452026626.post-2018640131411247692",
  "link":"http://feedproxy.google.com/~r/blogspot/gJZg/~3/QizNs26Pduw/two-new-datasets-for-conversational-nlp.html",
  "content":"<span class=\"byline-author\">Posted by Aditya Gupta, Software Engineer and Shyam Upadhyay, Research Scientist, Google Assistant</span> <p>A key challenge in <a href=\"https://en.wikipedia.org/wiki/Natural_language_processing\">natural language processing</a> (NLP) is building <a href=\"https://en.wikipedia.org/wiki/Dialogue_system\">conversational agents</a> that can understand and reason about different language phenomena that are unique to realistic speech. For example, because people do not always premeditate exactly what they are going to say, a natural conversation often includes interruptions to speech, called <a href=\"https://www.semanticscholar.org/paper/Preliminaries-to-a-Theory-of-Speech-Disfluencies-Schriberg/c0ca94051f549f08e0bb4be7694540460fd47f1b\">disfluencies</a>. Such disfluencies can be simple (like interjections, repetitions, restarts, or corrections), which simply break the continuity of a sentence, or more complex semantic disfluencies, in which the underlying meaning of a phrase changes.  In addition, understanding a conversation also often requires knowledge of temporal relationships, like whether an event precedes or follows another. However, conversational agents built on today’s NLP models often struggle when confronted with temporal relationships or with disfluencies, and progress on improving their performance has been slow. This is due, in part, to a lack of datasets that involve such interesting conversational and speech phenomena.  </p><p>To stir interest in this direction within the research community, we are excited to introduce <a href=\"https://arxiv.org/abs/2106.04571\">TimeDial</a>, for temporal commonsense reasoning in dialog, and <a href=\"https://arxiv.org/abs/2106.04016\">Disfl-QA</a>, which focuses on contextual disfluencies. TimeDial presents a new multiple choice span filling task targeted for temporal understanding, with an annotated test set of over ~1.1k dialogs.  Disfl-QA is the first dataset containing contextual disfluencies in an information seeking setting, namely question answering over Wikipedia passages, with ~12k human annotated disfluent questions. These benchmark datasets are the first of their kind and show a significant gap between human performance and current state of the art NLP models. </p><p><b>TimeDial</b><br>While people can effortlessly reason about everyday temporal concepts, such as duration, frequency, or relative ordering of events in a dialog, such tasks can be challenging for conversational agents. For example, current NLP models often make a poor selection when tasked with filling in a blank (as shown below) that assumes a basic level of world knowledge for reasoning, or that requires understanding explicit and implicit inter-dependencies between temporal concepts across conversational turns. </p><div class=\"separator\"><a href=\"https://1.bp.blogspot.com/-OrwOHtczNVE/YQrmg0sW9UI/AAAAAAAAH_M/15lypkBJvt0nGRP_1C6OVjHvAxhzduF3ACLcBGAsYHQ/s688/Google%2BAI%2BBlog%2BPost%2Bfor%2BDisfl-QA%2Band%2BTimeDial%2B%25281%2529.jpg\"><img border=\"0\" src=\"https://1.bp.blogspot.com/-OrwOHtczNVE/YQrmg0sW9UI/AAAAAAAAH_M/15lypkBJvt0nGRP_1C6OVjHvAxhzduF3ACLcBGAsYHQ/s16000/Google%2BAI%2BBlog%2BPost%2Bfor%2BDisfl-QA%2Band%2BTimeDial%2B%25281%2529.jpg\"></a></div><p>It is easy for a person to judge that “half past one” and “quarter to two” are more plausible options to fill in the blank than “half past three” and “half past nine”. However, performing such temporal reasoning in the context of a dialog is not trivial for NLP models, as it requires appealing to world knowledge (i.e., knowing that the participants are not yet late for the meeting) and understanding the temporal relationship between events (“half past one” is before “three o’clock”, while “half past three” is after it). Indeed, current state-of-the-art models like <a href=\"https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html\">T5</a> and <a href=\"https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html\">BERT</a> end up picking the wrong answers — “half past three” (T5) and “half past nine” (BERT).</p><p>The TimeDial benchmark dataset (derived from the <a href=\"https://arxiv.org/abs/1710.03957\">DailyDialog</a> multi-turn dialog corpus) measures models’ temporal commonsense reasoning abilities within a dialog context. Each of the ~1.5k dialogs in the dataset  is presented in a multiple choice setup, in which one temporal span is masked out and the model is asked to find all  correct answers from a list of four options to fill in the blank. </p><p>In our experiments we found that while people can easily answer these multiple choice questions (at 97.8% accuracy), state-of-the-art pre-trained language models still struggle on this challenge set.  We experiment across three different modeling paradigms: (i) classification over the provided 4 options using BERT, (ii) mask filling for the masked span in the dialog using BERT-MLM, (iii) generative methods using T5. We observe that all the models struggle on this challenge set, with the best variant only scoring 73%.  </p><table cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\">  <colgroup>   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt; </colgroup>  <tbody><tr>    <td><b>Model</b>   </td>    <td> </td>   <td><b>2-best Accuracy</b>   </td>  </tr>  <tr>   <td>Human    </td>    <td> </td>   <td>97.8%    </td>  </tr>  <tr>   <td>BERT - Classification    </td>   <td> </td>   <td>50.0%    </td>  </tr>  <tr>   <td>BERT - Mask Filling    </td>   <td> </td>   <td>68.5%    </td>  </tr>  <tr>   <td>T5 - Generation    </td>   <td> </td>   <td>73.0%    </td>  </tr></tbody></table><p><a href=\"https://arxiv.org/pdf/2106.04571.pdf\">Qualitative error analyses show</a> that the pre-trained language models often rely on shallow, spurious features (particularly text matching), instead of truly doing reasoning over the context. It is likely that building NLP models capable of performing the kind of temporal commonsense reasoning needed for TimeDial requires rethinking how temporal objects are represented within general text representations. </p><p><b>Disfl-QA</b><br>As disfluency is inherently a speech phenomenon, it is most commonly found in text output from speech recognition systems. Understanding such disfluent text is key to building conversational agents that understand human speech. Unfortunately, research  in the NLP  and  speech community has been impeded by the lack of curated datasets containing  such  disfluencies, and the datasets that are available, like <a href=\"https://ieeexplore.ieee.org/document/225858\">Switchboard</a>, are limited in scale and complexity. As a result, it’s difficult to stress test NLP models in the presence of disfluencies.  </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\">    <colgroup>   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt; </colgroup>  <tbody><tr>   <td><b>Disfluency</b>   </td>   <td> </td>   <td><b>Example</b>   </td>  </tr>  <tr>   <td>Interjection    </td>    <td> </td>   <td>“<i>When is, <span>uh</span>, Easter this year?</i>”    </td>  </tr>  <tr>   <td>Repetition    </td>    <td> </td>   <td>“<i>When is <span>Eas</span> … <span>Easter</span> this year?</i>”    </td>  </tr>  <tr>   <td>Correction    </td>    <td> </td>   <td>“<i>When is <span>Lent</span>, <span>I mean</span> <span>Easter</span>, this year?</i>”</td>  </tr>  <tr>   <td>Restart    </td>    <td> </td>   <td>“<i><span>How much</span>, <span>no wait</span>, <span>when is</span> Easter this year?</i>”    </td>  </tr>  </tbody></table><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\">  <tbody>    <tr><td class=\"tr-caption\">Different kinds of disfluencies. The reparandum (words intended to be corrected or ignored; in <span>red</span>), interregnum (optional discourse cues; in <span>grey</span>) and repair (the corrected words; in <span>blue</span>).</td></tr></tbody></table><p>Disfl-QA is the first dataset containing contextual disfluencies in an information  seeking  setting,  namely  <a href=\"https://en.wikipedia.org/wiki/Question_answering\">question  answering</a> over Wikipedia passages from <a href=\"https://arxiv.org/abs/1806.03822\">SQuAD</a>. Disfl-QA is a <em>targeted</em> dataset for disfluencies, in which all questions (~12k) contain disfluencies, making for a much larger disfluent test set than prior datasets. Over 90% of the disfluencies in Disfl-QA are corrections or restarts, making it a much more difficult test set for disfluency correction. In addition, compared to earlier disfluency datasets, it contains a wider variety of semantic distractors, i.e., distractors that carry semantic meaning as opposed to simpler speech disfluencies. </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\"><tbody><tr><td><b>Passage:</b> <em>…The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (&quot;Norman&quot; comes from &quot;Norseman&quot;) raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, … </em></td></tr><tr><td class=\"tr-caption\"/></tr></tbody></table><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\">    <colgroup>   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt; </colgroup>  <tbody><tr>    <td><b>Q<sub>1</sub>:</b>  </td> <td>In what country is Normandy located?</td><td> </td><td><span><b>France ✓</b></span></td>  </tr>  <tr>    <td><b>DQ<sub>1</sub>:</b>  </td> <td>In what country is <span>Norse</span> found <span>no wait</span> <span>Normandy not Norse</span>?</td><td> </td><td><span><b>Denmark X</b></span></td>  </tr>  <tr>    <td><b>Q<sub>2</sub>:</b>  </td> <td>When were the Normans in Normandy?</td><td> </td><td><span><b>10th and 11th centuries ✓</b></span></td>  </tr>  <tr>    <td><b>DQ<sub>2</sub>:</b>  </td> <td><span>From which countries</span> <span>no tell me</span> <span>when were the Normans in Normandy?</span></td><td> </td><td><b><span>Denmark, Iceland and Norway X</span></b></td>  </tr></tbody></table><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\"><tbody>  <tr><td class=\"tr-caption\">A passage and questions (Q<sub>i</sub>) from <a href=\"https://arxiv.org/abs/1806.03822\">SQuAD</a> dataset, along with their disfluent versions (DQ<sub>i</sub>), consisting of semantic distractors (like “Norse” and “from which countries”) and predictions from a T5 model.</td></tr></tbody></table><p>Here, the first question (Q<sub>1</sub>) is seeking an answer about the location of <em>Normandy</em>. In the disfluent version (DQ<sub>1</sub>) <em>Norse</em> is mentioned before the question is corrected. The presence of this correctional disfluency confuses the QA model, which tends to rely on shallow textual cues from the question for making predictions. </p><p>Disfl-QA also includes newer phenomena, such as <a href=\"https://nlp.stanford.edu/projects/coref.shtml#:~:text=Coreference%20resolution%20is%20the%20task,question%20answering%2C%20and%20information%20extraction.\">coreference</a> (expression referring to the same entity) between the <em>reparandum</em> and the <em>repair</em>.</p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\">    <colgroup>   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt; </colgroup><tbody>  <tr><td><b>SQuAD</b></td><td>  </td><td><b>Disfl-QA</b></td></tr>  <tr><td>Who does BSkyB have an operating license from?</td><td>  </td><td><span>Who removed [BSkyB’s] operating license</span>, <span>no scratch that</span>, <span>who do [they] have [their] operating license from?</span></td></tr></tbody></table><p>Experiments show that the performance of existing state-of-the-art language model–based question answering systems degrades significantly when tested on Disfl-QA and heuristic disfluencies (presented in the paper) in a zero-shot setting.  </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\">    <colgroup>   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt;   <col span=\"1\">&lt;col&gt; </colgroup>  <tbody><tr>   <td><b>Dataset</b>   </td>    <td> </td>   <td><b>F1</b>   </td>  </tr>  <tr>   <td><a href=\"https://arxiv.org/abs/1806.03822\">SQuAD</a>   </td>    <td> </td>   <td>89.59    </td>  </tr>  <tr>   <td>Heuristics    </td>    <td> </td>   <td>65.27 (-24.32)    </td>  </tr>  <tr>   <td>Disfl-QA     </td>    <td> </td>   <td>61.64 (-27.95)    </td>  </tr></tbody></table><p>We <a href=\"https://arxiv.org/abs/2106.04016\">show</a> that data augmentation methods partially recover the loss in performance and also demonstrate the efficacy of using human-annotated training data for fine-tuning. We argue that researchers need large-scale disfluency datasets in order for NLP models to be robust to disfluencies. </p><p><b>Conclusion</b><br>Understanding  language phenomena that are unique to human speech,  like disfluencies and temporal reasoning, among others, is a key ingredient for enabling more natural human–machine communication in the near future. With TimeDial and Disfl-QA, we aim to fill a major research gap by providing these datasets as testbeds for NLP models, in order to evaluate their robustness to ubiquitous phenomena across different tasks. It is our hope that the broader NLP community will devise generalized few-shot or zero-shot approaches to effectively handle these phenomena, without requiring task-specific human-annotated training datasets, constructed specifically for these challenges. </p><p><b>Acknowledgments</b><br><em>The TimeDial work has been a team effort involving Lianhui Qi, Luheng He, Yenjin Choi, Manaal Faruqui and the authors. The Disfl-QA work has been a collaboration involving Jiacheng Xu, Diyi Yang, Manaal Faruqui.</em></p><div class=\"feedflare\">\r\n<a href=\"http://feeds.feedburner.com/~ff/blogspot/gJZg?a=QizNs26Pduw:TDKjXKDo2kw:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/blogspot/gJZg?d=yIl2AUoC8zA\" border=\"0\">&lt;img&gt;</a>\r\n</div><img src=\"http://feeds.feedburner.com/~r/blogspot/gJZg/~4/QizNs26Pduw\" height=\"1\" width=\"1\" alt=\"\">"
}