{
  "title":"Daily ICFP: Day 5",
  "date":"2021-08-29T17:00:00.000000-07:00",
  "author":null,
  "id":"https://tweag.io/blog/2021-08-30-icfp5/",
  "link":"https://tweag.io/blog/2021-08-30-icfp5/",
  "content":"Daily ICFP\nSeveral Tweagers all agreed to gather notes here about our\nICFP (International Conference on Functional\nProgramming) experiences.\nOther posts in this series:\n\nICFP - Day 0\nICFP - Day 1\nICFP - Day 2\nICFP - Day 3\nICFP - Day 4\n\nDay 5 - Friday\nThese notes follow Arnaud, Noon and Richard through their day at ICFP,\nroughly in order. (The talks are not publicly posted at the time\nof publication of this post, but we expect they will be over the\ncoming weeks.)\nArnaud — Parafuzz: Coverage-guided Property Fuzzing for Multicore OCaml programs: this is in the context of multicore OCaml (multicore OCaml has algebraic effects). The authors use algebraic effects to abstract over concurrency primitives, so that they can test concurrency property with the AFL fuzzer (AFL tries generate random inputs, here random schedules, while trying very hard to trigger code paths that were not covered by previous runs).\nArnaud — Wibbily Wobbly Timey Camly: an OCaml library to deal with time, timezones, time intervals, etc… The talk focused a lot on finding out whether a particular date belong to a set of dates. These sets are built by assembling constraints. It’s an unusual, but very convincing design.\nNoon — FARM starts today! I’m so excited; I’ve wanted to attend FARM\nfor years, and this is my first opportunity!\nNoon — mimium: a self-extensible programming language for sound and music\n\nNice language that has scheduling and state.\nHas a focus on composition over live-coding (c.f. extempore, say.)\n\nNoon — Unfortunately, the next speaker wasn’t able to make it, so there was no talk.\nNoon — Bit disappointed that FARM and Haskell Symposium are on at the same time, I’ve\nended up attending Haskell, and I’ll hope to watch FARM at a later point.\nPractical Normalization by Evaluation for EDSLs, by Nachiappan Villiappan, Alejandro Russo, and Sam Lindley\nNoon\n\nPrefer shallow over deep embedding to piggy-back features from the host language.\nDownside is we’ve lost syntax for the operations.\nMaybe one way is to interconvert between expression representation and host (?) representation\nDoesn’t always work; sometimes there’s no unique choice.\n\nRichard\nI had heard the term “normalization by evaluation” a number of times in the\nliterature, but I never really understood it until watching this talk: the\nidea is to take a bit of syntax, interpret it into a semantic domain (that is,\nreinterpret it as an expression in the host language) and then inject the\nresult back into the encoding of the syntax of the object language. The only\nproblem is, now that I’ve described it thusly, it feels vacuous once again:\nwhat is the difference between “normalization by evaluation” and just\nevaluating terms in your object language? The term keeps cropping up, but I\ndon’t really get it.\nLet me think a bit more about what the words mean: normalization is the\nprocess of finding a normal form, where a normal form is (generally) a\ndistinguished member of an equivalence class, useful for checking membership\nin the equivalence class. That is, if we want to identify all semantically\nequal expressions, we want to notice that 1 + 1 and 2 are semantically\nequal; thus, they are in the same equivalence class. A good way to notice this\nis to choose one distinguished member of each equivalence class: this is the\nnormal form. For 1 + 1 and 2, 2 will be this normal form. Evaluation is\na separate process by which we take an expression and simplify it according to\nwell-established rules of evaluation.\nPutting this together, we might surmise that “normalization by evaluation” is\nan approach for checking semantic equality of expressions, using this recipe:\n\nTo determine whether e1 and e2 are equal:\n\n\n\nEvaluate e1 to yield value v1.\nEvaluate e2 to yield value v2.\nDeclare that e1 is semantically equal to e2 iff v1 is syntactically equal to v2.\n\n\nThis process does not really care what v1 and v2 are — just whether\nthey’re syntactically equal. So maybe that really is the essence of\nnormalization by evaluation. And I’ve probably struggled to understand this\nbecause this process seems “obvious” to me, and so I cannot really imagine\nanother way of checking semantic equality of expressions.\nIn the end, I’m not sure whether this definition of\nnormalization-by-evaluation is correct, and I’m afraid I got stuck on this\nduring the talk and did not extract other useful bits.\nNoon — Safe Mutation with Algebraic Effects\n\nConcurrency is frustrating; we don’t want non-determinism!\nMaybe algebraic effects can help?\nIdea: Annotate the resources and modify these to control what can be done.\nIt all works!\n\nRichard — Seeking Stability by being Lazy and Shallow: Lazy and shallow instantiation is user friendly, by Gert-Jan Bottu and Richard A. Eisenberg.\nI will not comment further on this talk other than to include this shameless\nplug, and to publicly state how much I enjoyed working with former Tweag\nintern Gert-Jan on developing this paper. I do hope to submit a proposal\nrequesting lazy instantiation in future versions of GHC.\nNoon — I had wanted to watch the Linear Haskell, Today and Tomorrow\ntalk, but it was scheduled alongside ShutdownPL (and FARM); I really want to support\nICFPs efforts for more DEI (diversity, equity, and inclusion) content so I feel compelled to attend ShutdownPL; I’ll have\nto catch the other talks at a later time.\nRichard — Linear Haskell, Today and Tomorrow, keynote by former Tweager Jean-Philippe Bernardy\nThis is a fine keynote describing the state of linear types in Haskell today\nand sketching out how we can extract more from them in the future. In\nparticular, it describes the long-term plan for supporting pure\nmutable-in-place structures, as long as we can verify statically (via linear\ntypes) that there are never two live copies of the structures.\nNoon — ShutdownPL - Seeking Good Trouble Before It Goes Bad: Anti-Jerk Systems in STEM\n\nThis was a bold and strong talk. The main discussion was around the need to\naddress problematic people at the end of the so-called “pipeline problem” in\nSTEM; i.e. there’s no point bringing people in to a community if they are just\ngoing to leave because they are not welcomed.\nSo, one of the key ideas I got from this talk was to consider why people\nleave. I think this is a very powerful concept and often quite hard to do.\nAnother key idea from this talk was highlighting the damage done to\ncommunities by supporting, publicly, people known to be engaging in\nproblematic behaviour. While I think it’s perhaps very obvious, it also can\nbe quite subtle; the talk goes into a discussion of legal issues some of the\ncommunity leaders, in the specific example, were facing, and the cost\nof speaking up; which is often very high; especially high if you are not in a\nprivileged position.\nOne of the most practical ideas that I came out of this talk with, is this:\nSurvey people who are in/leaving your community, and find out what they are\nthinking. It doesn’t have to be entirely negative; it could also solicit\ncomments on things that are going well, or new ideas, etc. But one idea that\ncame up, in discussions with my partner afterwards, was the idea of what I’m\ncalling a “Living Code of Conduct”: It’s a mechanism for flagging behaviour\n(good or bad!) and aligning it to a specific code-of-conduct item managed by\nthe community. It’s probably best done anonymously; but doesn’t have to be;\nthere could be lots of variants. In any case, if you’re at all interested in\nthis idea, do reach out to me; I’d love to chat more about it!\n\nNoon — Deadlock-Free Session Types in Linear Haskell\n\nReally enjoying the presentations by Wen; she has a very engaging style.\nFirst time I’ve heard about Session types, but I think I got a good feeling.\nOverall I really enjoyed it!\n\nNoon — Evaluating Linear Functions to Symmetric Monoidal Categories\n\nBox and wire diagrams.\nSymmetric Monoidal Categories (SMCs).\nIssue with Arrows is that they don’t represent these box-and-write diagrams very well; and in particular fail at the parallelisation.\nIdea is to use arrows to implement the an SMC, so that they are easier to work with.\nPerhaps has applications to quantum computing!\nSo of course I’m interested, and will try and do a bit more reading.\n\nSummary\nNoon —\n\nOverall, my experience at ICFP has been great.\nI feel very full of FP/Type theory knowledge! I feel like I learned a lot\nof new words and concepts that I will inevitably have to google again, but\nnow they’ll spark a pleasant memory in my mind :)\nI met several very friendly people, and also watched many lovely talks\nthat I enjoyed; hopefully some friendly faces from ICFP will be appearing on\nthe Compositional podcast in the next few months!\nThanks to the organisers and all the speakers for their hard work!\n\n    "
}