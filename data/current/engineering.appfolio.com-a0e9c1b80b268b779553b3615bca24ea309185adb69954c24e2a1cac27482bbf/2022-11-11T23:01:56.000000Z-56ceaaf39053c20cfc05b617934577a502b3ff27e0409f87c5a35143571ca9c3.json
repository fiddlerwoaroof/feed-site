{
  "title":"Understanding Invoices with Document AI",
  "date":"2022-11-11T23:01:56.000000Z",
  "author":null,
  "id":"562ea223e4b0e0b9dab0b930:564c01e8e4b09fc032ff180b:636ecc07d3bd9b0db6288039",
  "link":"https://engineering.appfolio.com/appfolio-engineering/2022/11/11/understanding-invoices-with-document-ai",
  "content":"<p class=\"\">At AppFolio, we specialize in helping Property Management Companies to automate their most repetitive, time-consuming, and tedious processes. Accounting-related tasks often check all of these boxes – and one of them is to maintain an accurate system of record for accounts payable and accounts receivable. This is a critical task due to strict federal and state regulations, and to ensure it is carried out accurately our customers use AppFolio’s Property Management (APM) software to enter invoices. However, these bills must be manually entered –  a time-consuming and error-prone process.</p><p class=\"\">To help, we created <strong><em>Smart Bill Entry</em></strong>, a tool powered by state-of-the-art Machine Learning (ML) based models and our Document AI technology. Smart Bill Entry automatically extracts the most important information from the multitude of invoices a Property Manager receives in a given month - and in 2022 alone, we processed over 10 Million invoices. Here we will explore the tools enabling this technology and explain how it works behind the scenes.</p><h2><strong>Smart Bill Entry</strong></h2><p class=\"\">Smart Bill Entry enables Property Managers to upload invoices in PDF format to APM directly via drag and drop, or by forwarding an email to a specific inbox. Once the invoice is uploaded, our ML models automatically extract key information, such as the amount, vendor name, the property’s address, and the invoice number associated with the bill.</p><p class=\"\">We know Property Managers place a heavy emphasis on accuracy to ensure that bills get paid correctly. Based on our estimations, we have found that when manually entering invoices humans are roughly 95-99% accurate, depending on the field. Our model is designed to mirror this accuracy, and we compute calibrated <em>confidence scores</em> for each field to get our models to a state where they are as close to human accuracy as possible.</p><p class=\"\">The model outputs a number between 0 and 1, where a score closer to 1 indicates that the model is confident that the class is correct. However, ML models tend to be over- or under-confident in their predictions, meaning that a given score doesn’t correspond to the <em>probability</em> that the prediction is correct - as demonstrated by the diagram below.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n              <img class=\"thumb-image\" alt=\"\" src=\"https://images.squarespace-cdn.com/content/v1/562ea223e4b0e0b9dab0b930/2270e9a2-f02d-4efa-ad71-14a379eb5807/Frame+4+%281%29.png?format=1000w\">\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">ML models tend to be over or underconfident, such that their confidence scores don’t exactly correspond to the <em>probability</em> that the prediction is correct. we fit additional calibration models To account for this, such that we can make consistent decisions of whether or not to show predictions. Image credit <a href=\"https://arxiv.org/pdf/1706.04599.pdf\">“On Calibration of Modern Neural Networks”</a>. </p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n<p class=\"\">Calibration is the process of transforming the confidence score predicted by the model into a reliable probability that can be used to make decisions, like showing or not showing the prediction to the user. We do this as an added layer of precision. If our calibrated model is returning a confidence score of 0.95 for the “Bill Amount” field, we can expect that the model will be correct 95 times out of 100 predictions.</p><h2><strong>Document AI</strong></h2><p class=\"\">The technology driving Smart Bill Entry’s ability to extract information from PDFs is <strong><em>Document AI</em></strong>. Document AI is a set of Machine Learning tools that are specifically designed for extracting information from a PDF, independent of the layout. The input data used to train our Document AI models includes two types of information: </p><ol><li><p class=\"\">The Optical Character Recognition (OCR) information of the documents. This is the typed or written text on a document converted into machine-encoded text. Since we are only interested in fields that are critical to the invoice, we use datasets that zero in on this information.</p></li><li><p class=\"\">The bounding box coordinates and content of the target fields we are looking to extract from the documents. We derive <em>labels</em><strong><em> </em></strong>from these coordinates. To get the labels (e.g. “Vendor Name”, “Property Name”, etc.) for the content of each bounding box, human supervision is necessary - and the operators who assess the content of the invoices assign the appropriate label.</p></li></ol><p class=\"\">The image below is a visual representation of an invoice, the OCR information identified by the model for that invoice, and what labels would be generated for each object that is present on the invoice. </p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n              <img class=\"thumb-image\" alt=\"\" src=\"https://images.squarespace-cdn.com/content/v1/562ea223e4b0e0b9dab0b930/c3f914ac-9b9f-49e5-93ce-58f8c83870dd/Frame+1+%281%29.png?format=1000w\">\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Original Invoice vs OCR Information vs Labels</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n<p class=\"\">After collecting the OCR and bounding box dataset, we then apply different techniques that combine Computer Vision, Natural Language Processing, and Tabular Features. In the next section, we’ll discuss two of our approaches to extracting the above information, depending on our customer’s specific needs.  </p><h2><strong>Traditional vs Deep Learning</strong></h2><p class=\"\">Smart Bill Entry combines two approaches to extracting information from invoices: traditional Machine Learning solutions and advanced Deep Learning solutions. For example, when extracting the ”Property Address” and the “Vendor Name” fields, we are using tree-based  models customized for each Property Manager. When we extract generic fields, such as the “Amount” and “Invoice Number” we use powerful DL models that can take advantage of layout and text using state-of-the-art <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformer</a> architectures.</p><h3><strong>Traditional Machine Learning </strong></h3><p class=\"\">We extract the “Property Address” and “Vendor Name” fields from an invoice using traditional ML models. The input data for training the model is a simple <a href=\"https://en.wikipedia.org/wiki/Bag-of-words_model\"><span><em>Bag-of-words</em></span></a> representation of the invoices, together with other engineered features relating to the layout. After extensive benchmarking we landed on a multi-class <em>Random Forest Classifier</em> as our base estimator<em>.</em> It fits several decision tree classifiers on various sub-samples of the dataset and uses averaging to improve predictive accuracy and prevent over-fitting.</p><p class=\"\">Because AppFolio is a Property Management software used by thousands of companies (each with a large number of vendors and properties in their database), training only one multi-class Random Forest Classifier for all the vendors and properties in our database is a very challenging feat due to the high cardinality in the target variable and the challenge of deduplicating entities.</p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n              <img class=\"thumb-image\" alt=\"\" src=\"https://images.squarespace-cdn.com/content/v1/562ea223e4b0e0b9dab0b930/29f2cd56-bd4a-4fb1-9bc1-c15eb8ea6de9/Frame+2+%281%29.png?format=1000w\">\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">We train separate Random Forest ClassifierS for fields that have a unique set of target classes for each customer.</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n<p class=\"\">To tackle this, we decided to train one model per Property Management company. Not surprisingly, the drawback of this approach is that it requires a comprehensive and robust ML infrastructure to efficiently maintain and deploy thousands of models to production, as well as a short cold start phase to learn how to correctly map to specific vendor and property entities. It also means that each individual model needs to be relatively light weight and fast to train.<br>At AppFolio, we combined in-house solutions with third-party <a href=\"https://en.wikipedia.org/wiki/MLOps\"><span>MLOps</span></a> solutions, to create a state-of-the-art ML infrastructure that helps every team quickly train, deploy and monitor ML models at scale in production. We will talk more about our infrastructure in future posts in this blog.   </p><h3><strong>Deep Learning</strong></h3><p class=\"\">For fields that have well defined labels across all customers such as the “Amount” and “Invoice Number”, we opted for a solution that implements a single Deep Learning model across <em>all</em> Property Management companies as opposed to one model per company. This approach generalizes well to unseen layouts and eliminates cold start issues.</p><p class=\"\">Due to its very high learning capacity we were able to leverage almost all available training data in our database - which lends to our solution producing much more accurate predictions than traditional ML models. We also benchmarked against off the shelf Document AI solutions and found that our models significantly outperform them when evaluated on <em>our</em> holdout data.</p><h3><strong>Deep Learning Architecture</strong></h3><p class=\"\">When deciding which DL architecture to implement for our model, we tried numerous approaches including: </p><ul><li><p class=\"\">Computer Vision models that use the image of an invoice as their input and output a bounding box for each class</p></li><li><p class=\"\">Natural Language Processing models that start from the OCR and classify each bounding box according to one of the given classes, and</p></li><li><p class=\"\">Multimodal models that use as input both the OCR and the image of the invoice. </p></li></ul><p class=\"\">We implemented our models in such a way that we can exchange the architecture without modifying the input data and output format. In the image below, we show how different architectures (the yellow boxes in the diagram) can be exchanged without affecting the first and last layers of the model. This gives us the flexibility and agility to test different solutions and optimize our metrics. </p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n              <img class=\"thumb-image\" alt=\"\" src=\"https://images.squarespace-cdn.com/content/v1/562ea223e4b0e0b9dab0b930/7e7fde1e-c572-4823-9aa0-33ca74cbcc84/Frame+3+%282%29.png?format=1000w\">\n            \n          \n        \n          \n        \n\n        \n          \n          <figcaption class=\"image-caption-wrapper\">\n            <p class=\"\">Keeping the input and output fixed we can easily switch between Deep learning architectures to optimize metrics such as accuracy, training and inference time. This also gives us the flexibility to quickly try out new approaches as the field advances.</p>\n          </figcaption>\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n<p class=\"\">When considering which architecture to deploy to production, we chose the solution that best balances accuracy with training time and inference speed. We used two processes to evaluate the performance of each model:</p><p class=\"\">1. <em>Offline</em> Evaluation<br>After training a new model, we compare its performance against a frozen and static dataset that we use as a benchmark.</p><p class=\"\">2. <em>Online</em> Evaluation<br>After training a new model, we deploy it in shadow-mode, where we do not show the predictions to the user, but rather just record them and compare metrics. </p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n    \n  \n    \n\n      \n\n      \n        <figure class=\"\n              sqs-block-image-figure\n              intrinsic\n            \">\n          \n        \n        \n\n        \n          \n            \n          \n            \n              <img class=\"thumb-image\" alt=\"\" src=\"https://images.squarespace-cdn.com/content/v1/562ea223e4b0e0b9dab0b930/3177a7df-cd4c-42ae-872f-d83ee568efc2/Smart+Bill+Entry+and+Document+AI+%40+AppFolio.png?format=1000w\">\n            \n          \n        \n          \n        \n\n        \n      \n        </figure>\n      \n\n    \n  \n\n\n  \n\n\n\n\n<p class=\"\">Stay tuned for a future blog post where we will discuss the details of our ML infrastructure, and how we train, evaluate, deploy and monitor each model!</p>\n\n\n\n\n<p class=\"\">Authors and contributors: Ezequiel Esposito, Ari Polakof, Christfried Focke, Tony Froccaro</p>"
}